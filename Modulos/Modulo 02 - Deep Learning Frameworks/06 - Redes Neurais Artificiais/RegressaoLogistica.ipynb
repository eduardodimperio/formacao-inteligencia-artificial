{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('IA': conda)"
  },
  "interpreter": {
   "hash": "cd33b1ad81c559069350aab209dba1ac81a1a78823a0538f4b422d164d6af523"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Regressão Logística\n",
    "\n",
    "Com Regressão logística, buscamos uma função que nos diga qual é a probabilidade de um elemento pertencer a uma classe. \n",
    "A aprendizagem supervisionada é configurada como um processo iterativo de otimização dos pesos. Estes são então modificados com base no desempenho do modelo.\n",
    "\n",
    "De fato, o objetivo é minimizar a função de perda, que indica o grau em que o comportamento do modelo se desvia do desejado. \n",
    "O desempenho do modelo é então verificado em um conjunto de teste, consistindo em imagens diferentes das de treinamento.\n",
    "\n",
    "Os passos básicos do treinamento que vamos implementar são os seguintes: \n",
    "\n",
    "1. Os pesos são inicializados com valores aleatórios seguindo uma distribuição normal.\n",
    "\n",
    "2. Para cada elemento do conjunto de treino é calculado o erro, ou seja, a diferença entre a saída prevista e a saída real. Este erro é usado para ajustar os pesos. \n",
    "\n",
    "3. O processo é repetido em todos os exemplos do conjunto de treinamento até que o erro em todo o conjunto de treinamento não seja inferior a um certo limite, ou até que o número máximo de iterações seja atingido.\n",
    "\n",
    "Nosso objetivo é a classificação de imagens de peças de vestuário.\n",
    "Classes do dataset fashion_mnist - ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset \n",
    "(x_treino, y_treino), (x_teste, y_teste) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as imagens\n",
    "x_treino, x_teste = x_treino/255., x_teste/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o shape de x de 28x28 para 784\n",
    "x_treino = tf.reshape(x_treino, shape = (-1, 784))\n",
    "x_teste  = tf.reshape(x_teste, shape = (-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 784), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "x_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os pesos, variáveis W e b\n",
    "# Inicializando os Coeficientes de Forma Randômica com Distribuição Normal\n",
    "pesos = tf.Variable(tf.random.normal(shape = (784, 10), dtype = tf.float64))\n",
    "vieses  = tf.Variable(tf.random.normal(shape = (10,), dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o cálculo do resultado da regressão logísitica\n",
    "# g(y) = β(x) + βo  \n",
    "def logistic_regression(x):\n",
    "    lr = tf.add(tf.matmul(x, pesos), vieses)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizando o erro usando cross entropy (Função de Custo).\n",
    "# A fim de treinar nosso modelo, devemos definir como identificar a precisão. \n",
    "# Nosso objetivo é tentar obter valores de parâmetros W e b que minimizem o valor da métrica que indica quão ruim é o modelo.\n",
    "# Diferentes métricas calculam o grau de erro entre a saída desejada e as saídas de dados de treinamento. \n",
    "# Uma medida comum de erro é o erro quadrático médio ou a Distância Euclidiana Quadrada. No entanto, existem algumas descobertas de pesquisa que sugerem usar outras \n",
    "# métricas para uma rede neural. Neste exemplo, usamos a chamada função de erro de entropia cruzada.\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    y_true = tf.one_hot(y_true, 10)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizando a Cost Function\n",
    "# Em seguida, devemos minimizá-lo usando o algoritmo de otimização de descida de gradiente:\n",
    "def grad(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = logistic_regression(x)\n",
    "        loss_val = cross_entropy(y, y_pred)\n",
    "    return tape.gradient(loss_val, [pesos, vieses])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "n_batches = 10000\n",
    "learning_rate = 0.01\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o otimizador usando SGD (Stochastic Gradient Descent)\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o cálculo da Acurácia\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype = tf.int32)\n",
    "    preds = tf.cast(tf.argmax(y_pred, axis = 1), dtype = tf.int32)\n",
    "    preds = tf.equal(y_true, preds)\n",
    "    return tf.reduce_mean(tf.cast(preds, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando batches de dados de treino\n",
    "dataset_treino = tf.data.Dataset.from_tensor_slices((x_treino, y_treino))\n",
    "dataset_treino = dataset_treino.repeat().shuffle(x_treino.shape[0]).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "726562\n",
      "Número do Batch: 9745, Erro do Modelo: 1.352096, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9746, Erro do Modelo: 1.489076, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9747, Erro do Modelo: 1.269806, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9748, Erro do Modelo: 1.433927, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9749, Erro do Modelo: 1.226748, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9750, Erro do Modelo: 1.220497, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9751, Erro do Modelo: 1.289690, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9752, Erro do Modelo: 1.173494, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9753, Erro do Modelo: 1.666670, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9754, Erro do Modelo: 1.002379, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9755, Erro do Modelo: 1.601519, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9756, Erro do Modelo: 1.257814, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9757, Erro do Modelo: 1.184948, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9758, Erro do Modelo: 1.379732, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9759, Erro do Modelo: 1.197547, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9760, Erro do Modelo: 1.584443, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9761, Erro do Modelo: 1.275286, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9762, Erro do Modelo: 1.100174, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9763, Erro do Modelo: 1.445784, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9764, Erro do Modelo: 1.500813, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9765, Erro do Modelo: 0.889800, Acurácia em Treino: 0.828125\n",
      "Número do Batch: 9766, Erro do Modelo: 0.859913, Acurácia em Treino: 0.781250\n",
      "Número do Batch: 9767, Erro do Modelo: 1.288238, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9768, Erro do Modelo: 1.456510, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9769, Erro do Modelo: 1.477547, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9770, Erro do Modelo: 1.307027, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9771, Erro do Modelo: 1.110948, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9772, Erro do Modelo: 1.058605, Acurácia em Treino: 0.789062\n",
      "Número do Batch: 9773, Erro do Modelo: 1.709143, Acurácia em Treino: 0.625000\n",
      "Número do Batch: 9774, Erro do Modelo: 1.229953, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9775, Erro do Modelo: 1.036700, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9776, Erro do Modelo: 0.868430, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9777, Erro do Modelo: 0.881836, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9778, Erro do Modelo: 1.288753, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9779, Erro do Modelo: 0.919863, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9780, Erro do Modelo: 0.901775, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9781, Erro do Modelo: 1.569567, Acurácia em Treino: 0.617188\n",
      "Número do Batch: 9782, Erro do Modelo: 1.320752, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9783, Erro do Modelo: 1.899997, Acurácia em Treino: 0.632812\n",
      "Número do Batch: 9784, Erro do Modelo: 1.222859, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9785, Erro do Modelo: 1.189156, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9786, Erro do Modelo: 1.258922, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9787, Erro do Modelo: 1.205837, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9788, Erro do Modelo: 1.107630, Acurácia em Treino: 0.773438\n",
      "Número do Batch: 9789, Erro do Modelo: 1.430270, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9790, Erro do Modelo: 1.922406, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9791, Erro do Modelo: 1.127322, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9792, Erro do Modelo: 0.937890, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9793, Erro do Modelo: 1.570738, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9794, Erro do Modelo: 1.433341, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9795, Erro do Modelo: 1.165769, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9796, Erro do Modelo: 1.717385, Acurácia em Treino: 0.640625\n",
      "Número do Batch: 9797, Erro do Modelo: 1.498963, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9798, Erro do Modelo: 0.956177, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9799, Erro do Modelo: 1.042581, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9800, Erro do Modelo: 1.455842, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9801, Erro do Modelo: 1.270310, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9802, Erro do Modelo: 1.511979, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9803, Erro do Modelo: 1.353107, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9804, Erro do Modelo: 1.098453, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9805, Erro do Modelo: 1.168567, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9806, Erro do Modelo: 1.454938, Acurácia em Treino: 0.648438\n",
      "Número do Batch: 9807, Erro do Modelo: 0.620950, Acurácia em Treino: 0.812500\n",
      "Número do Batch: 9808, Erro do Modelo: 1.323681, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9809, Erro do Modelo: 1.407583, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9810, Erro do Modelo: 1.400290, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9811, Erro do Modelo: 1.371773, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9812, Erro do Modelo: 1.687340, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9813, Erro do Modelo: 1.232617, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9814, Erro do Modelo: 1.410379, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9815, Erro do Modelo: 1.208246, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9816, Erro do Modelo: 1.413092, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9817, Erro do Modelo: 1.151646, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9818, Erro do Modelo: 1.671974, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9819, Erro do Modelo: 1.467829, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9820, Erro do Modelo: 1.464784, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9821, Erro do Modelo: 1.491227, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9822, Erro do Modelo: 1.267169, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9823, Erro do Modelo: 1.665962, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9824, Erro do Modelo: 1.234136, Acurácia em Treino: 0.648438\n",
      "Número do Batch: 9825, Erro do Modelo: 0.934305, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9826, Erro do Modelo: 1.428013, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9827, Erro do Modelo: 0.998773, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9828, Erro do Modelo: 1.441285, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9829, Erro do Modelo: 1.051638, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9830, Erro do Modelo: 0.909730, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9831, Erro do Modelo: 1.616326, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9832, Erro do Modelo: 1.221686, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9833, Erro do Modelo: 1.406440, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9834, Erro do Modelo: 1.382342, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9835, Erro do Modelo: 0.836074, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9836, Erro do Modelo: 0.838909, Acurácia em Treino: 0.789062\n",
      "Número do Batch: 9837, Erro do Modelo: 1.766221, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9838, Erro do Modelo: 1.192865, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9839, Erro do Modelo: 1.255975, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9840, Erro do Modelo: 1.363563, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9841, Erro do Modelo: 1.001046, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9842, Erro do Modelo: 1.166040, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9843, Erro do Modelo: 1.236092, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9844, Erro do Modelo: 1.019160, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9845, Erro do Modelo: 1.360423, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9846, Erro do Modelo: 1.101813, Acurácia em Treino: 0.796875\n",
      "Número do Batch: 9847, Erro do Modelo: 1.046927, Acurácia em Treino: 0.773438\n",
      "Número do Batch: 9848, Erro do Modelo: 1.388125, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9849, Erro do Modelo: 1.693195, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9850, Erro do Modelo: 1.611982, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9851, Erro do Modelo: 1.114581, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9852, Erro do Modelo: 1.283546, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9853, Erro do Modelo: 1.094453, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9854, Erro do Modelo: 1.459538, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9855, Erro do Modelo: 1.106000, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9856, Erro do Modelo: 1.124120, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9857, Erro do Modelo: 1.230725, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9858, Erro do Modelo: 1.312888, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9859, Erro do Modelo: 1.855621, Acurácia em Treino: 0.617188\n",
      "Número do Batch: 9860, Erro do Modelo: 1.042879, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9861, Erro do Modelo: 0.888341, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9862, Erro do Modelo: 1.339225, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9863, Erro do Modelo: 1.497295, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9864, Erro do Modelo: 1.095290, Acurácia em Treino: 0.781250\n",
      "Número do Batch: 9865, Erro do Modelo: 1.222329, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9866, Erro do Modelo: 1.301909, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9867, Erro do Modelo: 1.134514, Acurácia em Treino: 0.773438\n",
      "Número do Batch: 9868, Erro do Modelo: 1.146577, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9869, Erro do Modelo: 1.799068, Acurácia em Treino: 0.640625\n",
      "Número do Batch: 9870, Erro do Modelo: 1.074691, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9871, Erro do Modelo: 1.391150, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9872, Erro do Modelo: 1.361878, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9873, Erro do Modelo: 1.296575, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9874, Erro do Modelo: 1.299512, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9875, Erro do Modelo: 1.242519, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9876, Erro do Modelo: 0.892841, Acurácia em Treino: 0.773438\n",
      "Número do Batch: 9877, Erro do Modelo: 1.185351, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9878, Erro do Modelo: 1.056338, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9879, Erro do Modelo: 1.109601, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9880, Erro do Modelo: 1.435213, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9881, Erro do Modelo: 1.015793, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9882, Erro do Modelo: 1.122916, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9883, Erro do Modelo: 1.358588, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9884, Erro do Modelo: 1.523029, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9885, Erro do Modelo: 1.194128, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9886, Erro do Modelo: 1.117477, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9887, Erro do Modelo: 1.327369, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9888, Erro do Modelo: 1.353512, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9889, Erro do Modelo: 1.788472, Acurácia em Treino: 0.640625\n",
      "Número do Batch: 9890, Erro do Modelo: 1.204936, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9891, Erro do Modelo: 1.558005, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9892, Erro do Modelo: 1.138901, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9893, Erro do Modelo: 1.131981, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9894, Erro do Modelo: 1.122255, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9895, Erro do Modelo: 1.138643, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9896, Erro do Modelo: 0.948075, Acurácia em Treino: 0.812500\n",
      "Número do Batch: 9897, Erro do Modelo: 1.411146, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9898, Erro do Modelo: 1.215777, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9899, Erro do Modelo: 1.162561, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9900, Erro do Modelo: 1.660958, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9901, Erro do Modelo: 1.232514, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9902, Erro do Modelo: 1.213961, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9903, Erro do Modelo: 0.954711, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9904, Erro do Modelo: 1.255496, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9905, Erro do Modelo: 1.668606, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9906, Erro do Modelo: 1.080205, Acurácia em Treino: 0.757812\n",
      "Número do Batch: 9907, Erro do Modelo: 1.349173, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9908, Erro do Modelo: 1.210298, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9909, Erro do Modelo: 0.775065, Acurácia em Treino: 0.781250\n",
      "Número do Batch: 9910, Erro do Modelo: 0.770580, Acurácia em Treino: 0.773438\n",
      "Número do Batch: 9911, Erro do Modelo: 1.346283, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9912, Erro do Modelo: 1.099401, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9913, Erro do Modelo: 1.338954, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9914, Erro do Modelo: 1.119382, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9915, Erro do Modelo: 1.127371, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9916, Erro do Modelo: 1.221996, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9917, Erro do Modelo: 1.148027, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9918, Erro do Modelo: 1.660969, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9919, Erro do Modelo: 1.207461, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9920, Erro do Modelo: 1.153044, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9921, Erro do Modelo: 1.763915, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9922, Erro do Modelo: 1.500216, Acurácia em Treino: 0.617188\n",
      "Número do Batch: 9923, Erro do Modelo: 1.611023, Acurácia em Treino: 0.585938\n",
      "Número do Batch: 9924, Erro do Modelo: 1.337989, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9925, Erro do Modelo: 0.965561, Acurácia em Treino: 0.812500\n",
      "Número do Batch: 9926, Erro do Modelo: 1.095103, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9927, Erro do Modelo: 1.545703, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9928, Erro do Modelo: 1.895831, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9929, Erro do Modelo: 1.222106, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9930, Erro do Modelo: 1.305427, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9931, Erro do Modelo: 0.991547, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9932, Erro do Modelo: 1.044924, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9933, Erro do Modelo: 1.203638, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9934, Erro do Modelo: 1.325933, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9935, Erro do Modelo: 0.979958, Acurácia em Treino: 0.804688\n",
      "Número do Batch: 9936, Erro do Modelo: 1.364262, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9937, Erro do Modelo: 1.171432, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9938, Erro do Modelo: 1.554812, Acurácia em Treino: 0.632812\n",
      "Número do Batch: 9939, Erro do Modelo: 1.791979, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9940, Erro do Modelo: 1.099987, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9941, Erro do Modelo: 1.572086, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9942, Erro do Modelo: 0.863844, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9943, Erro do Modelo: 1.155709, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9944, Erro do Modelo: 1.451285, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9945, Erro do Modelo: 1.685588, Acurácia em Treino: 0.625000\n",
      "Número do Batch: 9946, Erro do Modelo: 1.280843, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9947, Erro do Modelo: 0.784056, Acurácia em Treino: 0.781250\n",
      "Número do Batch: 9948, Erro do Modelo: 1.437048, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9949, Erro do Modelo: 1.224464, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9950, Erro do Modelo: 1.265832, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9951, Erro do Modelo: 1.251407, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9952, Erro do Modelo: 1.600786, Acurácia em Treino: 0.609375\n",
      "Número do Batch: 9953, Erro do Modelo: 0.989202, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9954, Erro do Modelo: 1.193133, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9955, Erro do Modelo: 1.211669, Acurácia em Treino: 0.789062\n",
      "Número do Batch: 9956, Erro do Modelo: 1.226569, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9957, Erro do Modelo: 1.750511, Acurácia em Treino: 0.671875\n",
      "Número do Batch: 9958, Erro do Modelo: 1.398812, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9959, Erro do Modelo: 1.098884, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9960, Erro do Modelo: 1.365770, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9961, Erro do Modelo: 1.367552, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9962, Erro do Modelo: 1.122236, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9963, Erro do Modelo: 1.774237, Acurácia em Treino: 0.625000\n",
      "Número do Batch: 9964, Erro do Modelo: 0.956471, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9965, Erro do Modelo: 1.872870, Acurácia em Treino: 0.632812\n",
      "Número do Batch: 9966, Erro do Modelo: 1.308912, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9967, Erro do Modelo: 1.251545, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9968, Erro do Modelo: 1.123813, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9969, Erro do Modelo: 1.008832, Acurácia em Treino: 0.796875\n",
      "Número do Batch: 9970, Erro do Modelo: 1.192915, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9971, Erro do Modelo: 1.011815, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9972, Erro do Modelo: 1.329675, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9973, Erro do Modelo: 1.665188, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9974, Erro do Modelo: 1.186963, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9975, Erro do Modelo: 1.702283, Acurácia em Treino: 0.679688\n",
      "Número do Batch: 9976, Erro do Modelo: 1.171120, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9977, Erro do Modelo: 1.213476, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9978, Erro do Modelo: 0.789717, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9979, Erro do Modelo: 1.339660, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9980, Erro do Modelo: 1.128202, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9981, Erro do Modelo: 1.106403, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9982, Erro do Modelo: 1.317779, Acurácia em Treino: 0.718750\n",
      "Número do Batch: 9983, Erro do Modelo: 1.487675, Acurácia em Treino: 0.664062\n",
      "Número do Batch: 9984, Erro do Modelo: 1.229971, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9985, Erro do Modelo: 1.031485, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9986, Erro do Modelo: 1.081814, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 9987, Erro do Modelo: 1.148102, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9988, Erro do Modelo: 1.091721, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9989, Erro do Modelo: 0.979396, Acurácia em Treino: 0.781250\n",
      "Número do Batch: 9990, Erro do Modelo: 1.403291, Acurácia em Treino: 0.703125\n",
      "Número do Batch: 9991, Erro do Modelo: 1.119675, Acurácia em Treino: 0.742188\n",
      "Número do Batch: 9992, Erro do Modelo: 1.157392, Acurácia em Treino: 0.765625\n",
      "Número do Batch: 9993, Erro do Modelo: 1.399805, Acurácia em Treino: 0.656250\n",
      "Número do Batch: 9994, Erro do Modelo: 1.204325, Acurácia em Treino: 0.726562\n",
      "Número do Batch: 9995, Erro do Modelo: 1.596332, Acurácia em Treino: 0.687500\n",
      "Número do Batch: 9996, Erro do Modelo: 1.126700, Acurácia em Treino: 0.734375\n",
      "Número do Batch: 9997, Erro do Modelo: 1.266495, Acurácia em Treino: 0.750000\n",
      "Número do Batch: 9998, Erro do Modelo: 1.433918, Acurácia em Treino: 0.695312\n",
      "Número do Batch: 9999, Erro do Modelo: 1.511307, Acurácia em Treino: 0.710938\n",
      "Número do Batch: 10000, Erro do Modelo: 1.367511, Acurácia em Treino: 0.703125\n",
      "\n",
      "Treinamento concluído!\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nIniciando o Treinamento!\")\n",
    "\n",
    "# Ciclo de treinamento\n",
    "for batch_numb, (batch_xs_treino, batch_ys_treino) in enumerate(dataset_treino.take(n_batches), 1):\n",
    "\n",
    "    # Calcula os gradientes\n",
    "    gradientes = grad(batch_xs_treino, batch_ys_treino)\n",
    "\n",
    "    # Otimiza os pesos com o valor do gradiente\n",
    "    optimizer.apply_gradients(zip(gradientes, [pesos, vieses]))\n",
    "\n",
    "    # Faz uma previsão\n",
    "    y_pred = logistic_regression(batch_xs_treino)\n",
    "\n",
    "    # Calcula o erro\n",
    "    loss = cross_entropy(batch_ys_treino, y_pred)\n",
    "\n",
    "    # Calcula a acurácia\n",
    "    acc = accuracy(batch_ys_treino, y_pred)\n",
    "\n",
    "    # Print\n",
    "    print(\"Número do Batch: %i, Erro do Modelo: %f, Acurácia em Treino: %f\" % (batch_numb, loss, acc))\n",
    "\n",
    "print (\"\\nTreinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Iniciando a Avaliação com Dados de Teste. Por favor aguarde!\n",
      "\n",
      "Acurácia em Teste: 0.742188\n"
     ]
    }
   ],
   "source": [
    "# Testando o Modelo\n",
    "\n",
    "# Preparando os dados de teste\n",
    "dataset_teste = tf.data.Dataset.from_tensor_slices((x_teste, y_teste))\n",
    "dataset_teste = dataset_teste.repeat().shuffle(x_teste.shape[0]).batch(batch_size)\n",
    "\n",
    "print (\"\\nIniciando a Avaliação com Dados de Teste. Por favor aguarde!\")\n",
    "\n",
    "# Loop pelos dados de teste, previsões e cálculo da acurácia\n",
    "for batch_numb, (batch_xs_teste, batch_ys_teste) in enumerate(dataset_teste.take(n_batches), 1):\n",
    "    y_pred = logistic_regression(batch_xs_teste)\n",
    "    acc = accuracy(batch_ys_teste, y_pred)\n",
    "    acuracia = tf.reduce_mean(tf.cast(acc, tf.float64))\n",
    "\n",
    "print(\"\\nAcurácia em Teste: %f\" % acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nFazendo Previsão de Uma Imagem:\n\nClasse Real: tf.Tensor([3], shape=(1,), dtype=uint8)\nClasse Prevista: tf.Tensor([6], shape=(1,), dtype=int64)\n\nExemplo de Peso e Viés Aprendidos:\ntf.Tensor(0.1540693315538873, shape=(), dtype=float64)\ntf.Tensor(-1.4337378357464874, shape=(), dtype=float64)\n\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFazendo Previsão de Uma Imagem:\")\n",
    "\n",
    "# Obtendo os dados de algumas imagens\n",
    "dataset_teste = tf.data.Dataset.from_tensor_slices((x_teste, y_teste))\n",
    "dataset_teste = dataset_teste.repeat().shuffle(x_teste.shape[0]).batch(1)\n",
    "\n",
    "# Fazendo previsões\n",
    "for batch_numb, (batch_xs, batch_ys) in enumerate(dataset_teste.take(1), 1):\n",
    "    # print(\"\\nImagem:\", batch_xs)\n",
    "    print(\"\\nClasse Real:\", batch_ys)\n",
    "    y_pred = tf.math.argmax(logistic_regression(batch_xs), axis = 1)\n",
    "    #y_pred = logistic_regression(batch_xs)\n",
    "    print(\"Classe Prevista:\", y_pred)\n",
    "\n",
    "print(\"\\nExemplo de Peso e Viés Aprendidos:\")\n",
    "print(pesos[2,9])\n",
    "print(vieses[2])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}