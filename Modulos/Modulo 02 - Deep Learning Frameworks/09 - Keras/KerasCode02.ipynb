{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning Frameworks</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras - Multilayer Perceptron"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Historicamente, Perceptron foi o nome dado a um modelo de rede neural com uma única camada linear. Se o modelo tem múltiplas camadas, chamamos de Perceptron Multicamada (MLP). Cada nó na primeira camada recebe uma entrada e dispara de acordo com os limites de decisão locais predefinidos (threesholds). Em seguida, a saída da primeira camada é passada para a segunda camada, cujos resultados são passados para a camada de saída final consistindo de um único neurônio. \n",
    "\n",
    "A rede pode ser densa, o que significa que cada neurônio em uma camada está conectado a todos os neurônios localizados na camada anterior e a todos os neurônios na camada seguinte."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando Redes Neurais com Keras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos considerar um único neurônio. Quais são as melhores escolhas para o peso w e o bias b? Idealmente, gostaríamos de fornecer um conjunto de exemplos de treinamento e deixar o computador ajustar o peso e o bias de tal forma que os erros produzidos na saída sejam minimizados. A fim de tornar isso um pouco mais concreto, vamos supor que temos um conjunto de imagens de gatos e outro conjunto separado de imagens que não contenham gatos. Por uma questão de simplicidade, suponha que cada neurônio olhe para um único valor de pixel de entrada. Enquanto o computador processa essas imagens, gostaríamos que nosso neurônio ajustasse seus pesos e bias para que tenhamos menos e menos imagens erroneamente reconhecidas como não-gatos. Essa abordagem parece muito intuitiva, mas exige que uma pequena alteração nos pesos (e/ou bias) cause apenas uma pequena mudança nas saídas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se tivermos um grande salto de saída, não podemos aprender progressivamente. Afinal, as crianças aprendem pouco a pouco. Infelizmente, o perceptron não mostra esse comportamento \"pouco a pouco\". Um perceptron é 0 ou 1 e isso é um grande salto e não vai ajudá-lo a aprender. Precisamos de algo diferente, mais suave. Precisamos de uma função que mude progressivamente de 0 para 1 sem descontinuidade. Matematicamente, isso significa que precisamos de uma função contínua que nos permita calcular a derivada."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cada neurônio pode ser inicializado com pesos específicos. Keras oferece algumas opções, a mais comum das quais são listadas da seguinte forma:\n",
    "\n",
    "Random_uniform: Os pesos são inicializados com valores uniformemente pequenos e aleatórios em (-0,05, 0,05). \n",
    "\n",
    "Random_normal: Os pesos são inicializados de acordo com uma distribuição Gaussiana, com média zero e pequeno desvio padrão de 0,05. \n",
    "\n",
    "Zero: Todos os pesos são inicializados para zero."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicializadores em Keras: https://keras.io/initializers/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funções de Ativação"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://keras.io/activations/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Função Sigmóide"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A função sigmóide é uma função matemática de amplo uso em campos como a economia e a computação. O nome \"sigmóide\" vem da forma em S do seu gráfico."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Um neurônio pode usar o sigmóide para calcular a função não-linear. Um neurônio com ativação sigmóide tem um comportamento semelhante ao perceptron, mas as mudanças são graduais e os valores de saída, como 0.3537 ou 0.147191, são perfeitamente legítimos. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A função de ativação sigmóide é comumente utilizada por redes neurais com propagação positiva (Feedforward) que precisam ter como saída apenas números positivos, em redes neurais multicamadas e em outras redes com sinais contínuos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Função ReLu"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O sigmóide não é o único tipo de função de ativação suave usada para redes neurais. Recentemente, uma função muito simples chamada unidade linear rectificada (ReLU) tornou-se muito popular porque gera resultados experimentais muito bons. Uma ReLU é simplesmente definida como uma função não-linear e a função é zero para valores negativos e cresce linearmente para valores positivos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sigmoid e ReLU são geralmente chamados funções de ativação das redes neurais. Essas mudanças graduais, típicas das funções Sigmóide e ReLU, são os blocos básicos para o desenvolvimento de um algoritmo de aprendizado que se adapta pouco a pouco, reduzindo progressivamente os erros cometidos pelas redes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reconhecimento de Dígitos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos construir uma rede que pode reconhecer números manuscritos. Para alcançar esse objetivo, usamos o MNIST (http://yann.lecun.com/exdb/mnist), um banco de dados de dígitos manuscritos composto por um conjunto de treinamento de 60.000 exemplos e um conjunto de testes de 10.000 exemplares. Os exemplos de treinamento são anotados por humanos com a resposta correta. Por exemplo, se o dígito manuscrito for o número três, então três é simplesmente o rótulo associado a esse exemplo. Cada imagem MNIST está na escala de cinza (gray scale), e consiste em 28 x 28 pixels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-Hot Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em muitas aplicações, é conveniente transformar features categóricas (não-numéricas) em variáveis numéricas. Por exemplo, o dígito de feature categórica com o valor d em [0-9] pode ser codificado em um vetor binário com 10 posições, que sempre tem valor 0, exceto a d-ésima posição onde um 1 está presente. Este tipo de representação é chamado de One-Hot Encoding (OHE) e é muito comum na mineração de dados quando o algoritmo de aprendizagem é especializado para lidar com funções numéricas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer Perceptron - Versão 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rede neural com apenas uma camada oculta"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import keras\r\n",
    "print (keras.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow\r\n",
    "print (tensorflow.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Import dos Pacotes\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.core import Dense, Activation\r\n",
    "from keras.optimizers import SGD\r\n",
    "from keras.utils import np_utils\r\n",
    "\r\n",
    "# Garantindo que o resultado pode ser reproduzido\r\n",
    "np.random.seed(1671)  \r\n",
    "\r\n",
    "# Parâmetros da rede e do treinamento\r\n",
    "NB_EPOCH = 200\r\n",
    "BATCH_SIZE = 128\r\n",
    "VERBOSE = 1\r\n",
    "NB_CLASSES = 10   # número de outputs = número de dígitos\r\n",
    "OPTIMIZER = SGD() # otimizador SGD\r\n",
    "N_HIDDEN = 128  # número de neurônios ocultos\r\n",
    "VALIDATION_SPLIT = 0.2 # quanto é reservado para validação\r\n",
    "\r\n",
    "# Gerando datasets de treino e e teste\r\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
    "\r\n",
    "# X_train possui 60000 linhas de valores 28x28 --> reshape para 60000 x 784\r\n",
    "# Gera versão final dos datasetes de treino e de teste\r\n",
    "RESHAPED = 784\r\n",
    "X_train = X_train.reshape(60000, RESHAPED)\r\n",
    "X_test = X_test.reshape(10000, RESHAPED)\r\n",
    "X_train = X_train.astype('float32')\r\n",
    "X_test = X_test.astype('float32')\r\n",
    "\r\n",
    "# Normalizando os dados\r\n",
    "# Tipicamente, os valores associados a cada pixel são normalizados na faixa [0, 1] \r\n",
    "# (o que significa que a intensidade de cada pixel é dividida por 255, o valor de intensidade máxima). \r\n",
    "# A saída é 10 classes, uma para cada dígito.\r\n",
    "X_train /= 255\r\n",
    "X_test /= 255\r\n",
    "print(X_train.shape[0], 'exemplos de treino')\r\n",
    "print(X_test.shape[0], 'exemplos de teste')\r\n",
    "\r\n",
    "# Converte os vetores da class para matrizes binárias das classes\r\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\r\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\r\n",
    "\r\n",
    "# Cria as camadas\r\n",
    "# A camada final usa a função de ativação softmax, que é uma generalização da função sigmóide. \r\n",
    "# Softmax transforma um vetor k-dimensional de valores reais arbitrários em um vetor k-dimensional de valores reais no \r\n",
    "# intervalo (0, 1). No nosso caso, agrega 10 respostas fornecidas pela camada anterior com 10 neurônios.\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(NB_CLASSES, input_shape = (RESHAPED,)))\r\n",
    "model.add(Activation('softmax'))\r\n",
    "\r\n",
    "# Sumário\r\n",
    "model.summary()\r\n",
    "\r\n",
    "# Compila o modelo\r\n",
    "# Precisamos selecionar o otimizador que é o algoritmo específico usado para atualizar pesos enquanto \r\n",
    "# treinamos nosso modelo.\r\n",
    "# Precisamos selecionar também a função objetivo que é usada pelo otimizador para navegar no espaço de pesos \r\n",
    "# (frequentemente, as funções objetivo são chamadas de função de perda (loss) e o processo de otimização é definido \r\n",
    "# como um processo de minimização de perdas).\r\n",
    "# Outras funções aqui: https://keras.io/losses/\r\n",
    "# A função objetivo \"categorical_crossentropy\" é a função objetivo adequada para predições de rótulos multiclass. \r\n",
    "# É também a escolha padrão em associação com a ativação softmax.\r\n",
    "# A métrica é usada para medir a performance do modelo. Outras métricas: https://keras.io/metrics/\r\n",
    "# As métricas são semelhantes às funções objetivo, com a única diferença de que elas não são usadas para \r\n",
    "# treinar um modelo, mas apenas para avaliar um modelo. \r\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = OPTIMIZER, metrics = ['accuracy'])\r\n",
    "\r\n",
    "# Treina o modelo\r\n",
    "# Epochs: Este é o número de vezes que o modelo é exposto ao conjunto de treinamento. Em cada iteração, \r\n",
    "# o otimizador tenta ajustar os pesos para que a função objetivo seja minimizada. \r\n",
    "# Batch_size: Esse é o número de instâncias de treinamento observadas antes que o otimizador execute uma \r\n",
    "# atualização de peso.\r\n",
    "# Reservamos parte do conjunto de treinamento para validação. A idéia chave é que reservamos uma parte dos \r\n",
    "# dados de treinamento para medir o desempenho na validação durante o treinamento. \r\n",
    "# Esta é uma boa prática para qualquer tarefa de aprendizagem da máquina, que vamos adotar em todos os nossos exemplos.\r\n",
    "modelo_v1 = model.fit(X_train, Y_train,\r\n",
    "                      batch_size = BATCH_SIZE, \r\n",
    "                      epochs = NB_EPOCH,\r\n",
    "                      verbose = VERBOSE, \r\n",
    "                      validation_split = VALIDATION_SPLIT)\r\n",
    "\r\n",
    "# Avalia o modelo com os dados de teste\r\n",
    "# Uma vez treinado o modelo, podemos avaliá-lo no conjunto de testes que contém novos exemplos não vistos. \r\n",
    "# Desta forma, podemos obter o valor mínimo alcançado pela função objetivo e o melhor valor alcançado pela métrica \r\n",
    "# de avaliação. Note-se que o conjunto de treinamento e o conjunto de teste são rigorosamente separados. \r\n",
    "# Não vale a pena avaliar um modelo em um exemplo que já foi usado para treinamento. \r\n",
    "# A aprendizagem é essencialmente um processo destinado a generalizar observações invisíveis e não a memorizar \r\n",
    "# o que já é conhecido.\r\n",
    "score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\r\n",
    "\r\n",
    "# Imprime a perda e a acurácia\r\n",
    "print(\"\\nTest score:\", score[0])\r\n",
    "print('Test accuracy:', score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000 exemplos de treino\n",
      "10000 exemplos de teste\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7668 - accuracy: 0.4854 - val_loss: 0.8982 - val_accuracy: 0.8268\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8527 - accuracy: 0.8222 - val_loss: 0.6574 - val_accuracy: 0.8584\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6631 - accuracy: 0.8482 - val_loss: 0.5615 - val_accuracy: 0.8699\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5823 - accuracy: 0.8604 - val_loss: 0.5085 - val_accuracy: 0.8771\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.8694 - val_loss: 0.4747 - val_accuracy: 0.8815\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.8722 - val_loss: 0.4505 - val_accuracy: 0.8848\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.8777 - val_loss: 0.4325 - val_accuracy: 0.8885\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8815 - val_loss: 0.4183 - val_accuracy: 0.8910\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8854 - val_loss: 0.4068 - val_accuracy: 0.8940\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4297 - accuracy: 0.8862 - val_loss: 0.3974 - val_accuracy: 0.8947\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4263 - accuracy: 0.8852 - val_loss: 0.3893 - val_accuracy: 0.8970\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8889 - val_loss: 0.3824 - val_accuracy: 0.8982\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4019 - accuracy: 0.8895 - val_loss: 0.3765 - val_accuracy: 0.8997\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4015 - accuracy: 0.8907 - val_loss: 0.3710 - val_accuracy: 0.8994\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8931 - val_loss: 0.3664 - val_accuracy: 0.9015\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3868 - accuracy: 0.8933 - val_loss: 0.3620 - val_accuracy: 0.9038\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3906 - accuracy: 0.8917 - val_loss: 0.3581 - val_accuracy: 0.9038\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8945 - val_loss: 0.3545 - val_accuracy: 0.9044\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8974 - val_loss: 0.3514 - val_accuracy: 0.9052\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3791 - accuracy: 0.8959 - val_loss: 0.3484 - val_accuracy: 0.9049\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.9013 - val_loss: 0.3457 - val_accuracy: 0.9057\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3697 - accuracy: 0.8969 - val_loss: 0.3433 - val_accuracy: 0.9063\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.9013 - val_loss: 0.3408 - val_accuracy: 0.9064\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.9007 - val_loss: 0.3385 - val_accuracy: 0.9069\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.9001 - val_loss: 0.3365 - val_accuracy: 0.9077\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.9045 - val_loss: 0.3346 - val_accuracy: 0.9078\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.9014 - val_loss: 0.3328 - val_accuracy: 0.9082\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.9004 - val_loss: 0.3311 - val_accuracy: 0.9089\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.9040 - val_loss: 0.3295 - val_accuracy: 0.9097\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.9043 - val_loss: 0.3278 - val_accuracy: 0.9100\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.9028 - val_loss: 0.3264 - val_accuracy: 0.9102\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.9038 - val_loss: 0.3250 - val_accuracy: 0.9105\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.9051 - val_loss: 0.3235 - val_accuracy: 0.9109\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.9038 - val_loss: 0.3223 - val_accuracy: 0.9114\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.9042 - val_loss: 0.3212 - val_accuracy: 0.9117\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.9060 - val_loss: 0.3200 - val_accuracy: 0.9118\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.9055 - val_loss: 0.3188 - val_accuracy: 0.9122\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.9060 - val_loss: 0.3178 - val_accuracy: 0.9128\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.9104 - val_loss: 0.3168 - val_accuracy: 0.9128\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.9063 - val_loss: 0.3158 - val_accuracy: 0.9128\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.9077 - val_loss: 0.3149 - val_accuracy: 0.9130\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.9073 - val_loss: 0.3140 - val_accuracy: 0.9136\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.9079 - val_loss: 0.3131 - val_accuracy: 0.9140\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.9103 - val_loss: 0.3123 - val_accuracy: 0.9128\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.9111 - val_loss: 0.3115 - val_accuracy: 0.9146\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.9078 - val_loss: 0.3106 - val_accuracy: 0.9139\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.9084 - val_loss: 0.3098 - val_accuracy: 0.9147\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.9088 - val_loss: 0.3091 - val_accuracy: 0.9148\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.9091 - val_loss: 0.3083 - val_accuracy: 0.9147\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.9121 - val_loss: 0.3077 - val_accuracy: 0.9147\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.9117 - val_loss: 0.3070 - val_accuracy: 0.9155\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.9107 - val_loss: 0.3064 - val_accuracy: 0.9154\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.9106 - val_loss: 0.3058 - val_accuracy: 0.9152\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.9121 - val_loss: 0.3052 - val_accuracy: 0.9162\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.9088 - val_loss: 0.3046 - val_accuracy: 0.9162\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.9161\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.9121 - val_loss: 0.3035 - val_accuracy: 0.9161\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9123 - val_loss: 0.3028 - val_accuracy: 0.9159\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.9145 - val_loss: 0.3023 - val_accuracy: 0.9167\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.9098 - val_loss: 0.3018 - val_accuracy: 0.9165\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.9137 - val_loss: 0.3013 - val_accuracy: 0.9159\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.9141 - val_loss: 0.3008 - val_accuracy: 0.9165\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.9154 - val_loss: 0.3004 - val_accuracy: 0.9164\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.9155 - val_loss: 0.2999 - val_accuracy: 0.9168\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.9139 - val_loss: 0.2994 - val_accuracy: 0.9172\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.9153 - val_loss: 0.2989 - val_accuracy: 0.9173\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.9132 - val_loss: 0.2985 - val_accuracy: 0.9175\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.9153 - val_loss: 0.2981 - val_accuracy: 0.9172\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.9153 - val_loss: 0.2977 - val_accuracy: 0.9172\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.9154 - val_loss: 0.2973 - val_accuracy: 0.9174\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.9140 - val_loss: 0.2969 - val_accuracy: 0.9180\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3118 - accuracy: 0.9127 - val_loss: 0.2966 - val_accuracy: 0.9177\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.9115 - val_loss: 0.2962 - val_accuracy: 0.9178\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.9165 - val_loss: 0.2958 - val_accuracy: 0.9180\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.9140 - val_loss: 0.2954 - val_accuracy: 0.9179\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.9163 - val_loss: 0.2950 - val_accuracy: 0.9180\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.9140 - val_loss: 0.2947 - val_accuracy: 0.9181\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.9144 - val_loss: 0.2943 - val_accuracy: 0.9178\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2973 - accuracy: 0.9170 - val_loss: 0.2940 - val_accuracy: 0.9182\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.9161 - val_loss: 0.2937 - val_accuracy: 0.9184\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3053 - accuracy: 0.9149 - val_loss: 0.2934 - val_accuracy: 0.9185\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3066 - accuracy: 0.9138 - val_loss: 0.2932 - val_accuracy: 0.9183\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.9158 - val_loss: 0.2927 - val_accuracy: 0.9186\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.9169 - val_loss: 0.2924 - val_accuracy: 0.9186\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.9139 - val_loss: 0.2922 - val_accuracy: 0.9191\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.9176 - val_loss: 0.2919 - val_accuracy: 0.9190\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.9147 - val_loss: 0.2916 - val_accuracy: 0.9194\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.9167 - val_loss: 0.2913 - val_accuracy: 0.9190\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3004 - accuracy: 0.9171 - val_loss: 0.2909 - val_accuracy: 0.9193\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.9155 - val_loss: 0.2908 - val_accuracy: 0.9193\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3017 - accuracy: 0.9160 - val_loss: 0.2905 - val_accuracy: 0.9193\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.9158 - val_loss: 0.2901 - val_accuracy: 0.9193\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.9175 - val_loss: 0.2899 - val_accuracy: 0.9193\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.9166 - val_loss: 0.2897 - val_accuracy: 0.9196\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2958 - accuracy: 0.9170 - val_loss: 0.2894 - val_accuracy: 0.9192\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.9184 - val_loss: 0.2893 - val_accuracy: 0.9191\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2883 - accuracy: 0.9195 - val_loss: 0.2890 - val_accuracy: 0.9192\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.9200 - val_loss: 0.2888 - val_accuracy: 0.9197\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2964 - accuracy: 0.9172 - val_loss: 0.2885 - val_accuracy: 0.9197\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.9160 - val_loss: 0.2883 - val_accuracy: 0.9197\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.9168 - val_loss: 0.2882 - val_accuracy: 0.9200\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.9195 - val_loss: 0.2879 - val_accuracy: 0.9197\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.9185 - val_loss: 0.2876 - val_accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2918 - accuracy: 0.9186 - val_loss: 0.2874 - val_accuracy: 0.9199\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.9164 - val_loss: 0.2872 - val_accuracy: 0.9201\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.9176 - val_loss: 0.2870 - val_accuracy: 0.9199\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.9174 - val_loss: 0.2868 - val_accuracy: 0.9203\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.9169 - val_loss: 0.2866 - val_accuracy: 0.9202\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.9165 - val_loss: 0.2864 - val_accuracy: 0.9202\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2903 - accuracy: 0.9206 - val_loss: 0.2862 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9187 - val_loss: 0.2861 - val_accuracy: 0.9202\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2921 - accuracy: 0.9177 - val_loss: 0.2859 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2912 - accuracy: 0.9185 - val_loss: 0.2856 - val_accuracy: 0.9204\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9184 - val_loss: 0.2855 - val_accuracy: 0.9207\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.9196 - val_loss: 0.2853 - val_accuracy: 0.9204\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.9200 - val_loss: 0.2851 - val_accuracy: 0.9203\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9206 - val_loss: 0.2849 - val_accuracy: 0.9203\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.9188 - val_loss: 0.2847 - val_accuracy: 0.9204\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.9196 - val_loss: 0.2845 - val_accuracy: 0.9202\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.9211 - val_loss: 0.2845 - val_accuracy: 0.9205\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.9188 - val_loss: 0.2842 - val_accuracy: 0.9203\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.9171 - val_loss: 0.2841 - val_accuracy: 0.9205\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2940 - accuracy: 0.9190 - val_loss: 0.2839 - val_accuracy: 0.9205\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.9194 - val_loss: 0.2837 - val_accuracy: 0.9206\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.9187 - val_loss: 0.2836 - val_accuracy: 0.9205\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2875 - accuracy: 0.9201 - val_loss: 0.2834 - val_accuracy: 0.9210\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.9208 - val_loss: 0.2834 - val_accuracy: 0.9207\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.9179 - val_loss: 0.2832 - val_accuracy: 0.9207\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.9186 - val_loss: 0.2830 - val_accuracy: 0.9208\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.9197 - val_loss: 0.2828 - val_accuracy: 0.9210\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.9208 - val_loss: 0.2828 - val_accuracy: 0.9208\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.9217 - val_loss: 0.2826 - val_accuracy: 0.9210\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9195 - val_loss: 0.2824 - val_accuracy: 0.9209\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.9205 - val_loss: 0.2823 - val_accuracy: 0.9212\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.9181 - val_loss: 0.2821 - val_accuracy: 0.9212\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9221 - val_loss: 0.2820 - val_accuracy: 0.9210\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.9196 - val_loss: 0.2819 - val_accuracy: 0.9212\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2844 - accuracy: 0.9196 - val_loss: 0.2817 - val_accuracy: 0.9213\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.9200 - val_loss: 0.2816 - val_accuracy: 0.9214\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.9203 - val_loss: 0.2814 - val_accuracy: 0.9214\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.9208 - val_loss: 0.2813 - val_accuracy: 0.9214\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.9209 - val_loss: 0.2812 - val_accuracy: 0.9216\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.9201 - val_loss: 0.2811 - val_accuracy: 0.9214\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.9221 - val_loss: 0.2810 - val_accuracy: 0.9218\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2893 - accuracy: 0.9202 - val_loss: 0.2808 - val_accuracy: 0.9212\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9215 - val_loss: 0.2807 - val_accuracy: 0.9216\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9202 - val_loss: 0.2806 - val_accuracy: 0.9216\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.9181 - val_loss: 0.2805 - val_accuracy: 0.9210\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.9199 - val_loss: 0.2804 - val_accuracy: 0.9208\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.9220 - val_loss: 0.2804 - val_accuracy: 0.9214\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2807 - accuracy: 0.9227 - val_loss: 0.2801 - val_accuracy: 0.9213\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.9199 - val_loss: 0.2800 - val_accuracy: 0.9216\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.9210 - val_loss: 0.2799 - val_accuracy: 0.9216\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.9200 - val_loss: 0.2798 - val_accuracy: 0.9219\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.9209 - val_loss: 0.2796 - val_accuracy: 0.9214\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9210 - val_loss: 0.2796 - val_accuracy: 0.9218\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9233 - val_loss: 0.2795 - val_accuracy: 0.9213\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9224 - val_loss: 0.2794 - val_accuracy: 0.9216\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.9212 - val_loss: 0.2793 - val_accuracy: 0.9216\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.9227 - val_loss: 0.2792 - val_accuracy: 0.9212\n",
      "Epoch 161/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.9227 - val_loss: 0.2792 - val_accuracy: 0.9214\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.9225 - val_loss: 0.2790 - val_accuracy: 0.9218\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9209 - val_loss: 0.2789 - val_accuracy: 0.9218\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.9226 - val_loss: 0.2788 - val_accuracy: 0.9220\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.9217 - val_loss: 0.2787 - val_accuracy: 0.9217\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9211 - val_loss: 0.2785 - val_accuracy: 0.9226\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2785 - accuracy: 0.9213 - val_loss: 0.2785 - val_accuracy: 0.9220\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.9210 - val_loss: 0.2783 - val_accuracy: 0.9226\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9228 - val_loss: 0.2783 - val_accuracy: 0.9218\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.9213 - val_loss: 0.2782 - val_accuracy: 0.9221\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.9216 - val_loss: 0.2781 - val_accuracy: 0.9218\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.9203 - val_loss: 0.2781 - val_accuracy: 0.9221\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9210 - val_loss: 0.2779 - val_accuracy: 0.9228\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.9241 - val_loss: 0.2778 - val_accuracy: 0.9221\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.9209 - val_loss: 0.2779 - val_accuracy: 0.9220\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.9232 - val_loss: 0.2777 - val_accuracy: 0.9223\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9226 - val_loss: 0.2777 - val_accuracy: 0.9224\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.9205 - val_loss: 0.2775 - val_accuracy: 0.9226\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2839 - accuracy: 0.9203 - val_loss: 0.2774 - val_accuracy: 0.9222\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2868 - accuracy: 0.9207 - val_loss: 0.2773 - val_accuracy: 0.9227\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.9232 - val_loss: 0.2773 - val_accuracy: 0.9223\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9233 - val_loss: 0.2772 - val_accuracy: 0.9224\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9224 - val_loss: 0.2771 - val_accuracy: 0.9228\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.9226 - val_loss: 0.2770 - val_accuracy: 0.9229\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9233 - val_loss: 0.2769 - val_accuracy: 0.9226\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.9223 - val_loss: 0.2768 - val_accuracy: 0.9226\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9224 - val_loss: 0.2768 - val_accuracy: 0.9225\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9239 - val_loss: 0.2767 - val_accuracy: 0.9236\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.9222 - val_loss: 0.2766 - val_accuracy: 0.9224\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.9231 - val_loss: 0.2766 - val_accuracy: 0.9227\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.9209 - val_loss: 0.2765 - val_accuracy: 0.9229\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.9221 - val_loss: 0.2764 - val_accuracy: 0.9229\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.9234 - val_loss: 0.2763 - val_accuracy: 0.9229\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.9242 - val_loss: 0.2762 - val_accuracy: 0.9228\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9228\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.9218 - val_loss: 0.2761 - val_accuracy: 0.9229\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9237 - val_loss: 0.2760 - val_accuracy: 0.9231\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9231 - val_loss: 0.2760 - val_accuracy: 0.9228\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9222 - val_loss: 0.2759 - val_accuracy: 0.9227\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.9225 - val_loss: 0.2759 - val_accuracy: 0.9232\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2774 - accuracy: 0.9218\n",
      "\n",
      "Test score: 0.27737781405448914\n",
      "Test accuracy: 0.9218000173568726\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer Perceptron - Versão 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adiciona 2 camadas ocultas, usando função de ativação ReLu"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Import dos Pacotes\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.core import Dense, Activation\r\n",
    "from keras.optimizers import SGD\r\n",
    "from keras.utils import np_utils\r\n",
    "from tensorflow import device\r\n",
    "\r\n",
    "# Garantindo que o resultado pode ser reproduzido\r\n",
    "np.random.seed(1671)  \r\n",
    "\r\n",
    "# Parâmetros da rede e do treinamento\r\n",
    "NB_EPOCH = 20\r\n",
    "BATCH_SIZE = 128\r\n",
    "VERBOSE = 1\r\n",
    "NB_CLASSES = 10   # número de outputs = número de dígitos\r\n",
    "OPTIMIZER = SGD() # otimizador SGD\r\n",
    "N_HIDDEN = 128\r\n",
    "VALIDATION_SPLIT = 0.2 # quanto é reservado para validação\r\n",
    "\r\n",
    "with device('/gpu:0'):\r\n",
    "\r\n",
    "    # Gerando datasets de treino e e teste\r\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
    "\r\n",
    "    # X_train possui 60000 linhas de valores 28x28 --> reshape para 60000 x 784\r\n",
    "    # Gera versão final dos datasetes de treino e de teste\r\n",
    "    RESHAPED = 784\r\n",
    "    X_train = X_train.reshape(60000, RESHAPED)\r\n",
    "    X_test = X_test.reshape(10000, RESHAPED)\r\n",
    "    X_train = X_train.astype('float32')\r\n",
    "    X_test = X_test.astype('float32')\r\n",
    "\r\n",
    "    # Normalizando os dados\r\n",
    "    # Tipicamente, os valores associados a cada pixel são normalizados na faixa [0, 1] \r\n",
    "    # (o que significa que a intensidade de cada pixel é dividida por 255, o valor de intensidade máxima). \r\n",
    "    # A saída é 10 classes, uma para cada dígito.\r\n",
    "    X_train /= 255\r\n",
    "    X_test /= 255\r\n",
    "    print(X_train.shape[0], 'exemplos de treino')\r\n",
    "    print(X_test.shape[0], 'exemplos de teste')\r\n",
    "\r\n",
    "    # Converte os vetores da class para matrizes binárias das classes\r\n",
    "    Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\r\n",
    "    Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\r\n",
    "\r\n",
    "    # Cria as camadas\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dense(N_HIDDEN))\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dense(NB_CLASSES))\r\n",
    "    model.add(Activation('softmax'))\r\n",
    "\r\n",
    "    # Sumário\r\n",
    "    model.summary()\r\n",
    "\r\n",
    "    # Compila o modelo\r\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = OPTIMIZER, metrics = ['accuracy'])\r\n",
    "\r\n",
    "    # Treina o modelo\r\n",
    "    modelo_v2 = model.fit(X_train, Y_train,\r\n",
    "                        batch_size = BATCH_SIZE, \r\n",
    "                        epochs = NB_EPOCH,\r\n",
    "                        verbose = VERBOSE, \r\n",
    "                        validation_split = VALIDATION_SPLIT)\r\n",
    "\r\n",
    "    # Avalia o modelo com os dados de teste\r\n",
    "    score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\r\n",
    "\r\n",
    "# Imprime a perda e a acurácia\r\n",
    "print(\"\\nTest score:\", score[0])\r\n",
    "print('Test accuracy:', score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000 exemplos de treino\n",
      "10000 exemplos de teste\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8272 - accuracy: 0.5027 - val_loss: 0.7027 - val_accuracy: 0.8465\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.8376 - val_loss: 0.4526 - val_accuracy: 0.8830\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.8755 - val_loss: 0.3765 - val_accuracy: 0.8970\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8885 - val_loss: 0.3390 - val_accuracy: 0.9038\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8989 - val_loss: 0.3155 - val_accuracy: 0.9078\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.9038 - val_loss: 0.2991 - val_accuracy: 0.9137\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.9140 - val_loss: 0.2830 - val_accuracy: 0.9181\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9176 - val_loss: 0.2720 - val_accuracy: 0.9208\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.9202 - val_loss: 0.2621 - val_accuracy: 0.9243\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.9213 - val_loss: 0.2537 - val_accuracy: 0.9262\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2569 - accuracy: 0.9276 - val_loss: 0.2446 - val_accuracy: 0.9293\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9288 - val_loss: 0.2376 - val_accuracy: 0.9308\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.9327 - val_loss: 0.2317 - val_accuracy: 0.9332\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9324 - val_loss: 0.2263 - val_accuracy: 0.9355\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9353 - val_loss: 0.2197 - val_accuracy: 0.9371\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9356 - val_loss: 0.2149 - val_accuracy: 0.9381\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.9371 - val_loss: 0.2086 - val_accuracy: 0.9402\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9377 - val_loss: 0.2038 - val_accuracy: 0.9411\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2080 - accuracy: 0.9413 - val_loss: 0.1993 - val_accuracy: 0.9446\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1938 - accuracy: 0.9429 - val_loss: 0.1956 - val_accuracy: 0.9452\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9435\n",
      "\n",
      "Test score: 0.1924012452363968\n",
      "Test accuracy: 0.9434999823570251\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer Perceptron - Versão 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adicionando Dropout nas camadas ocultas e aumentando o número de epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A segunda melhoria é muito simples. Decidimos retirar aleatoriamente, alguns dos valores propagados dentro das camadas  internas densas (camadas ocultas). Na aprendizagem de máquina, esta é uma forma bem conhecida de regularização. Surpreendentemente, esta ideia de descartar aleatoriamente alguns valores pode melhorar nosso desempenho."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropout é uma técnica onde os neurônios selecionados aleatoriamente são ignorados durante o treinamento. Eles são \"abandonados\" aleatoriamente. Isto significa que a sua contribuição para a ativação de neurónios é removida temporariamente na passagem para a frente e quaisquer atualizações de peso não são aplicadas ao neurônio na passagem para trás."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Você pode imaginar que, se os neurônios forem descartados aleatoriamente da rede durante o treinamento, outros neurônios terão de intervir e lidar com a representação necessária para fazer previsões para os neurônios ausentes. Acredita-se que isso resulte em múltiplas representações internas independentes sendo aprendidas pela rede.\n",
    "\n",
    "O efeito é que a rede se torna menos sensível aos pesos específicos dos neurônios. Isso, por sua vez resulta em uma rede que é capaz de melhorar a generalização e é menos sensível ao overfitting nos dados de treinamento."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O Dropout é facilmente implementado, por seleção aleatória de neurônios a abandonar, com uma dada probabilidade (por exemplo, 20%) a cada ciclo de atualização de peso. Dropout é usado somente durante o treinamento de um modelo e não é usado ao avaliar a habilidade do modelo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Geralmente, usamos valores de 20% - 50% de neurônios para Dropout, com 20% fornecendo um bom ponto de partida. Uma probabilidade muito baixa tem efeito mínimo e um valor muito alto resulta em sub-aprendizagem pela rede. É provável que você obtenha melhor desempenho quando o Dropout é usado em uma rede maior, dando ao modelo mais de uma oportunidade de aprender representações independentes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Import dos pacotes\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.core import Dense, Dropout, Activation\r\n",
    "from keras.optimizers import SGD\r\n",
    "from keras.utils import np_utils\r\n",
    "from tensorflow import device\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# Garantindo que o resultado pode ser reproduzido\r\n",
    "np.random.seed(1671)  \r\n",
    "\r\n",
    "# Parâmetros da rede e do treinamento\r\n",
    "NB_EPOCH = 250\r\n",
    "BATCH_SIZE = 128\r\n",
    "VERBOSE = 1\r\n",
    "NB_CLASSES = 10   # número de outputs = número de dígitos\r\n",
    "OPTIMIZER = SGD() # otimizador SGD\r\n",
    "N_HIDDEN = 128\r\n",
    "VALIDATION_SPLIT = 0.2 # quanto é reservado para validação\r\n",
    "DROPOUT = 0.3\r\n",
    "\r\n",
    "\r\n",
    "with device('/gpu:0'):\r\n",
    "    # Gerando datasets de treino e e teste\r\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
    "\r\n",
    "    # X_train possui 60000 linhas de valores 28x28 --> reshape para 60000 x 784\r\n",
    "    # Gera versão final dos datasetes de treino e de teste\r\n",
    "    RESHAPED = 784\r\n",
    "    X_train = X_train.reshape(60000, RESHAPED)\r\n",
    "    X_test = X_test.reshape(10000, RESHAPED)\r\n",
    "    X_train = X_train.astype('float32')\r\n",
    "    X_test = X_test.astype('float32')\r\n",
    "\r\n",
    "    # Normalizando os dados\r\n",
    "    # Tipicamente, os valores associados a cada pixel são normalizados na faixa [0, 1] \r\n",
    "    # (o que significa que a intensidade de cada pixel é dividida por 255, o valor de intensidade máxima). \r\n",
    "    # A saída é 10 classes, uma para cada dígito.\r\n",
    "    X_train /= 255\r\n",
    "    X_test /= 255\r\n",
    "    print(X_train.shape[0], 'exemplos de treino')\r\n",
    "    print(X_test.shape[0], 'exemplos de teste')\r\n",
    "\r\n",
    "    # Converte os vetores da class para matrizes binárias das classes\r\n",
    "    Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\r\n",
    "    Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\r\n",
    "\r\n",
    "    # Cria as camadas\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dropout(DROPOUT))\r\n",
    "    model.add(Dense(N_HIDDEN))\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dropout(DROPOUT))\r\n",
    "    model.add(Dense(NB_CLASSES))\r\n",
    "    model.add(Activation('softmax'))\r\n",
    "\r\n",
    "    # Sumário\r\n",
    "    model.summary()\r\n",
    "\r\n",
    "    # Compila o modelo\r\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = OPTIMIZER, metrics = ['accuracy'])\r\n",
    "\r\n",
    "    # Treina o modelo\r\n",
    "    modelo_v3 = model.fit(X_train, Y_train,\r\n",
    "                        batch_size = BATCH_SIZE, \r\n",
    "                        epochs = NB_EPOCH,\r\n",
    "                        verbose = VERBOSE, \r\n",
    "                        validation_split = VALIDATION_SPLIT)\r\n",
    "\r\n",
    "    # Avalia o modelo com os dados de teste\r\n",
    "    score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\r\n",
    "\r\n",
    "# Imprime a perda e a acurácia\r\n",
    "print(\"\\nTest score:\", score[0])\r\n",
    "print('Test accuracy:', score[1])\r\n",
    "\r\n",
    "# Imprime os dados\r\n",
    "print(modelo_v3.history.keys())\r\n",
    "\r\n",
    "# Sumariza o modelo para acurácia\r\n",
    "plt.plot(modelo_v3.history['accuracy'])\r\n",
    "plt.plot(modelo_v3.history['val_accuracy'])\r\n",
    "plt.title('Acurácia do Modelo')\r\n",
    "plt.ylabel('Acurácia')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend(['Treino', 'Teste'], loc = 'upper left')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Imprime a evolução de erro do modelo\r\n",
    "plt.plot(modelo_v3.history['loss'])\r\n",
    "plt.plot(modelo_v3.history['val_loss'])\r\n",
    "plt.title('Perda do Modelo')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend(['Treino', 'Teste'], loc = 'upper left')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000 exemplos de treino\n",
      "10000 exemplos de teste\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0706 - accuracy: 0.2889 - val_loss: 0.9602 - val_accuracy: 0.8084\n",
      "Epoch 2/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0473 - accuracy: 0.6845 - val_loss: 0.5397 - val_accuracy: 0.8705\n",
      "Epoch 3/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7318 - accuracy: 0.7782 - val_loss: 0.4231 - val_accuracy: 0.8893\n",
      "Epoch 4/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.8155 - val_loss: 0.3725 - val_accuracy: 0.8989\n",
      "Epoch 5/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.8388 - val_loss: 0.3408 - val_accuracy: 0.9055\n",
      "Epoch 6/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8522 - val_loss: 0.3161 - val_accuracy: 0.9111\n",
      "Epoch 7/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8623 - val_loss: 0.2978 - val_accuracy: 0.9148\n",
      "Epoch 8/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.8728 - val_loss: 0.2837 - val_accuracy: 0.9193\n",
      "Epoch 9/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - accuracy: 0.8771 - val_loss: 0.2723 - val_accuracy: 0.9214\n",
      "Epoch 10/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8848 - val_loss: 0.2602 - val_accuracy: 0.9251\n",
      "Epoch 11/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8898 - val_loss: 0.2503 - val_accuracy: 0.9277\n",
      "Epoch 12/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8938 - val_loss: 0.2426 - val_accuracy: 0.9298\n",
      "Epoch 13/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8980 - val_loss: 0.2351 - val_accuracy: 0.9321\n",
      "Epoch 14/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.9023 - val_loss: 0.2277 - val_accuracy: 0.9343\n",
      "Epoch 15/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.9029 - val_loss: 0.2203 - val_accuracy: 0.9358\n",
      "Epoch 16/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.9059 - val_loss: 0.2144 - val_accuracy: 0.9373\n",
      "Epoch 17/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9067 - val_loss: 0.2087 - val_accuracy: 0.9391\n",
      "Epoch 18/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.9090 - val_loss: 0.2037 - val_accuracy: 0.9407\n",
      "Epoch 19/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2998 - accuracy: 0.9129 - val_loss: 0.1997 - val_accuracy: 0.9412\n",
      "Epoch 20/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9138 - val_loss: 0.1953 - val_accuracy: 0.9433\n",
      "Epoch 21/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9155 - val_loss: 0.1896 - val_accuracy: 0.9452\n",
      "Epoch 22/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.9179 - val_loss: 0.1863 - val_accuracy: 0.9463\n",
      "Epoch 23/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.9202 - val_loss: 0.1826 - val_accuracy: 0.9475\n",
      "Epoch 24/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.9202 - val_loss: 0.1797 - val_accuracy: 0.9469\n",
      "Epoch 25/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9223 - val_loss: 0.1745 - val_accuracy: 0.9490\n",
      "Epoch 26/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2556 - accuracy: 0.9229 - val_loss: 0.1720 - val_accuracy: 0.9493\n",
      "Epoch 27/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2546 - accuracy: 0.9253 - val_loss: 0.1697 - val_accuracy: 0.9499\n",
      "Epoch 28/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2465 - accuracy: 0.9273 - val_loss: 0.1664 - val_accuracy: 0.9512\n",
      "Epoch 29/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9272 - val_loss: 0.1640 - val_accuracy: 0.9520\n",
      "Epoch 30/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.9282 - val_loss: 0.1619 - val_accuracy: 0.9528\n",
      "Epoch 31/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.9305 - val_loss: 0.1590 - val_accuracy: 0.9534\n",
      "Epoch 32/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9324 - val_loss: 0.1554 - val_accuracy: 0.9552\n",
      "Epoch 33/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2228 - accuracy: 0.9341 - val_loss: 0.1539 - val_accuracy: 0.9555\n",
      "Epoch 34/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2299 - accuracy: 0.9329 - val_loss: 0.1526 - val_accuracy: 0.9552\n",
      "Epoch 35/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2256 - accuracy: 0.9319 - val_loss: 0.1492 - val_accuracy: 0.9566\n",
      "Epoch 36/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.9365 - val_loss: 0.1473 - val_accuracy: 0.9578\n",
      "Epoch 37/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2146 - accuracy: 0.9366 - val_loss: 0.1453 - val_accuracy: 0.9578\n",
      "Epoch 38/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2055 - accuracy: 0.9383 - val_loss: 0.1433 - val_accuracy: 0.9585\n",
      "Epoch 39/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2106 - accuracy: 0.9371 - val_loss: 0.1416 - val_accuracy: 0.9587\n",
      "Epoch 40/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2113 - accuracy: 0.9393 - val_loss: 0.1393 - val_accuracy: 0.9592\n",
      "Epoch 41/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9426 - val_loss: 0.1386 - val_accuracy: 0.9593\n",
      "Epoch 42/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9414 - val_loss: 0.1362 - val_accuracy: 0.9600\n",
      "Epoch 43/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.9432 - val_loss: 0.1350 - val_accuracy: 0.9599\n",
      "Epoch 44/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1977 - accuracy: 0.9418 - val_loss: 0.1327 - val_accuracy: 0.9610\n",
      "Epoch 45/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1932 - accuracy: 0.9440 - val_loss: 0.1317 - val_accuracy: 0.9613\n",
      "Epoch 46/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1889 - accuracy: 0.9441 - val_loss: 0.1305 - val_accuracy: 0.9618\n",
      "Epoch 47/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1939 - accuracy: 0.9420 - val_loss: 0.1288 - val_accuracy: 0.9617\n",
      "Epoch 48/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1860 - accuracy: 0.9463 - val_loss: 0.1277 - val_accuracy: 0.9617\n",
      "Epoch 49/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1872 - accuracy: 0.9448 - val_loss: 0.1271 - val_accuracy: 0.9622\n",
      "Epoch 50/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9451 - val_loss: 0.1255 - val_accuracy: 0.9624\n",
      "Epoch 51/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1869 - accuracy: 0.9449 - val_loss: 0.1249 - val_accuracy: 0.9625\n",
      "Epoch 52/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1767 - accuracy: 0.9475 - val_loss: 0.1232 - val_accuracy: 0.9636\n",
      "Epoch 53/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9494 - val_loss: 0.1220 - val_accuracy: 0.9643\n",
      "Epoch 54/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1711 - accuracy: 0.9495 - val_loss: 0.1210 - val_accuracy: 0.9633\n",
      "Epoch 55/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1741 - accuracy: 0.9494 - val_loss: 0.1206 - val_accuracy: 0.9642\n",
      "Epoch 56/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9494 - val_loss: 0.1193 - val_accuracy: 0.9648\n",
      "Epoch 57/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1740 - accuracy: 0.9496 - val_loss: 0.1193 - val_accuracy: 0.9643\n",
      "Epoch 58/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9516 - val_loss: 0.1176 - val_accuracy: 0.9645\n",
      "Epoch 59/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9503 - val_loss: 0.1161 - val_accuracy: 0.9654\n",
      "Epoch 60/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9506 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 61/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9519 - val_loss: 0.1152 - val_accuracy: 0.9658\n",
      "Epoch 62/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9532 - val_loss: 0.1139 - val_accuracy: 0.9664\n",
      "Epoch 63/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1580 - accuracy: 0.9531 - val_loss: 0.1136 - val_accuracy: 0.9661\n",
      "Epoch 64/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1565 - accuracy: 0.9536 - val_loss: 0.1131 - val_accuracy: 0.9666\n",
      "Epoch 65/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9545 - val_loss: 0.1119 - val_accuracy: 0.9668\n",
      "Epoch 66/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9557 - val_loss: 0.1110 - val_accuracy: 0.9676\n",
      "Epoch 67/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9559 - val_loss: 0.1108 - val_accuracy: 0.9676\n",
      "Epoch 68/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9553 - val_loss: 0.1097 - val_accuracy: 0.9673\n",
      "Epoch 69/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9572 - val_loss: 0.1091 - val_accuracy: 0.9682\n",
      "Epoch 70/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9562 - val_loss: 0.1078 - val_accuracy: 0.9681\n",
      "Epoch 71/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9559 - val_loss: 0.1075 - val_accuracy: 0.9685\n",
      "Epoch 72/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1518 - accuracy: 0.9560 - val_loss: 0.1080 - val_accuracy: 0.9680\n",
      "Epoch 73/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9582 - val_loss: 0.1077 - val_accuracy: 0.9680\n",
      "Epoch 74/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1473 - accuracy: 0.9565 - val_loss: 0.1063 - val_accuracy: 0.9682\n",
      "Epoch 75/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9578 - val_loss: 0.1058 - val_accuracy: 0.9684\n",
      "Epoch 76/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1425 - accuracy: 0.9572 - val_loss: 0.1050 - val_accuracy: 0.9685\n",
      "Epoch 77/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9582 - val_loss: 0.1044 - val_accuracy: 0.9694\n",
      "Epoch 78/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9588 - val_loss: 0.1037 - val_accuracy: 0.9694\n",
      "Epoch 79/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1360 - accuracy: 0.9599 - val_loss: 0.1043 - val_accuracy: 0.9694\n",
      "Epoch 80/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9589 - val_loss: 0.1029 - val_accuracy: 0.9694\n",
      "Epoch 81/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9609 - val_loss: 0.1032 - val_accuracy: 0.9697\n",
      "Epoch 82/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9590 - val_loss: 0.1025 - val_accuracy: 0.9693\n",
      "Epoch 83/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9598 - val_loss: 0.1019 - val_accuracy: 0.9698\n",
      "Epoch 84/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1289 - accuracy: 0.9626 - val_loss: 0.1017 - val_accuracy: 0.9704\n",
      "Epoch 85/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9615 - val_loss: 0.1012 - val_accuracy: 0.9704\n",
      "Epoch 86/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9624 - val_loss: 0.1005 - val_accuracy: 0.9704\n",
      "Epoch 87/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9615 - val_loss: 0.0998 - val_accuracy: 0.9707\n",
      "Epoch 88/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1294 - accuracy: 0.9614 - val_loss: 0.0997 - val_accuracy: 0.9707\n",
      "Epoch 89/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1322 - accuracy: 0.9609 - val_loss: 0.0992 - val_accuracy: 0.9703\n",
      "Epoch 90/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1243 - accuracy: 0.9643 - val_loss: 0.0987 - val_accuracy: 0.9707\n",
      "Epoch 91/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9614 - val_loss: 0.0981 - val_accuracy: 0.9705\n",
      "Epoch 92/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1244 - accuracy: 0.9632 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 93/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1294 - accuracy: 0.9612 - val_loss: 0.0976 - val_accuracy: 0.9708\n",
      "Epoch 94/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9621 - val_loss: 0.0969 - val_accuracy: 0.9711\n",
      "Epoch 95/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9636 - val_loss: 0.0963 - val_accuracy: 0.9718\n",
      "Epoch 96/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1225 - accuracy: 0.9640 - val_loss: 0.0967 - val_accuracy: 0.9714\n",
      "Epoch 97/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1219 - accuracy: 0.9651 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
      "Epoch 98/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1225 - accuracy: 0.9631 - val_loss: 0.0955 - val_accuracy: 0.9716\n",
      "Epoch 99/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9632 - val_loss: 0.0953 - val_accuracy: 0.9716\n",
      "Epoch 100/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9655 - val_loss: 0.0952 - val_accuracy: 0.9716\n",
      "Epoch 101/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1202 - accuracy: 0.9645 - val_loss: 0.0944 - val_accuracy: 0.9720\n",
      "Epoch 102/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1181 - accuracy: 0.9648 - val_loss: 0.0945 - val_accuracy: 0.9717\n",
      "Epoch 103/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1199 - accuracy: 0.9642 - val_loss: 0.0944 - val_accuracy: 0.9724\n",
      "Epoch 104/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9666 - val_loss: 0.0942 - val_accuracy: 0.9722\n",
      "Epoch 105/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1146 - accuracy: 0.9660 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
      "Epoch 106/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9675 - val_loss: 0.0936 - val_accuracy: 0.9719\n",
      "Epoch 107/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9647 - val_loss: 0.0929 - val_accuracy: 0.9726\n",
      "Epoch 108/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1109 - accuracy: 0.9665 - val_loss: 0.0928 - val_accuracy: 0.9724\n",
      "Epoch 109/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.0932 - val_accuracy: 0.9724\n",
      "Epoch 110/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9667 - val_loss: 0.0926 - val_accuracy: 0.9728\n",
      "Epoch 111/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9663 - val_loss: 0.0920 - val_accuracy: 0.9731\n",
      "Epoch 112/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.0914 - val_accuracy: 0.9727\n",
      "Epoch 113/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1101 - accuracy: 0.9666 - val_loss: 0.0913 - val_accuracy: 0.9730\n",
      "Epoch 114/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9663 - val_loss: 0.0912 - val_accuracy: 0.9728\n",
      "Epoch 115/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1085 - accuracy: 0.9682 - val_loss: 0.0914 - val_accuracy: 0.9731\n",
      "Epoch 116/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9654 - val_loss: 0.0907 - val_accuracy: 0.9730\n",
      "Epoch 117/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1097 - accuracy: 0.9664 - val_loss: 0.0908 - val_accuracy: 0.9728\n",
      "Epoch 118/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9668 - val_loss: 0.0905 - val_accuracy: 0.9728\n",
      "Epoch 119/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9678 - val_loss: 0.0904 - val_accuracy: 0.9732\n",
      "Epoch 120/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9676 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
      "Epoch 121/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1061 - accuracy: 0.9686 - val_loss: 0.0903 - val_accuracy: 0.9732\n",
      "Epoch 122/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9693 - val_loss: 0.0904 - val_accuracy: 0.9730\n",
      "Epoch 123/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9699 - val_loss: 0.0897 - val_accuracy: 0.9732\n",
      "Epoch 124/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9703 - val_loss: 0.0896 - val_accuracy: 0.9732\n",
      "Epoch 125/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9696 - val_loss: 0.0893 - val_accuracy: 0.9737\n",
      "Epoch 126/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1081 - accuracy: 0.9676 - val_loss: 0.0888 - val_accuracy: 0.9743\n",
      "Epoch 127/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9685 - val_loss: 0.0886 - val_accuracy: 0.9744\n",
      "Epoch 128/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9706 - val_loss: 0.0888 - val_accuracy: 0.9732\n",
      "Epoch 129/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9699 - val_loss: 0.0884 - val_accuracy: 0.9735\n",
      "Epoch 130/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9702 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
      "Epoch 131/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9696 - val_loss: 0.0890 - val_accuracy: 0.9732\n",
      "Epoch 132/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9697 - val_loss: 0.0878 - val_accuracy: 0.9742\n",
      "Epoch 133/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9702 - val_loss: 0.0881 - val_accuracy: 0.9737\n",
      "Epoch 134/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9701 - val_loss: 0.0879 - val_accuracy: 0.9743\n",
      "Epoch 135/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9698 - val_loss: 0.0877 - val_accuracy: 0.9743\n",
      "Epoch 136/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9704 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
      "Epoch 137/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9693 - val_loss: 0.0869 - val_accuracy: 0.9743\n",
      "Epoch 138/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9716 - val_loss: 0.0867 - val_accuracy: 0.9746\n",
      "Epoch 139/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9693 - val_loss: 0.0874 - val_accuracy: 0.9742\n",
      "Epoch 140/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9705 - val_loss: 0.0863 - val_accuracy: 0.9743\n",
      "Epoch 141/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9704 - val_loss: 0.0868 - val_accuracy: 0.9747\n",
      "Epoch 142/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9705 - val_loss: 0.0863 - val_accuracy: 0.9748\n",
      "Epoch 143/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9701 - val_loss: 0.0862 - val_accuracy: 0.9746\n",
      "Epoch 144/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.9733 - val_loss: 0.0856 - val_accuracy: 0.9748\n",
      "Epoch 145/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9715 - val_loss: 0.0863 - val_accuracy: 0.9753\n",
      "Epoch 146/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9704 - val_loss: 0.0858 - val_accuracy: 0.9751\n",
      "Epoch 147/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9712 - val_loss: 0.0859 - val_accuracy: 0.9750\n",
      "Epoch 148/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9715 - val_loss: 0.0855 - val_accuracy: 0.9753\n",
      "Epoch 149/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9718 - val_loss: 0.0848 - val_accuracy: 0.9754\n",
      "Epoch 150/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9725 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
      "Epoch 151/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9722 - val_loss: 0.0850 - val_accuracy: 0.9753\n",
      "Epoch 152/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9755\n",
      "Epoch 153/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9723 - val_loss: 0.0854 - val_accuracy: 0.9753\n",
      "Epoch 154/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9744 - val_loss: 0.0851 - val_accuracy: 0.9753\n",
      "Epoch 155/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9734 - val_loss: 0.0851 - val_accuracy: 0.9755\n",
      "Epoch 156/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9733 - val_loss: 0.0849 - val_accuracy: 0.9750\n",
      "Epoch 157/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9736 - val_loss: 0.0847 - val_accuracy: 0.9758\n",
      "Epoch 158/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9742 - val_loss: 0.0842 - val_accuracy: 0.9755\n",
      "Epoch 159/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9728 - val_loss: 0.0845 - val_accuracy: 0.9759\n",
      "Epoch 160/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9747 - val_loss: 0.0847 - val_accuracy: 0.9748\n",
      "Epoch 161/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9745 - val_loss: 0.0841 - val_accuracy: 0.9762\n",
      "Epoch 162/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9738 - val_loss: 0.0842 - val_accuracy: 0.9756\n",
      "Epoch 163/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9751 - val_loss: 0.0843 - val_accuracy: 0.9754\n",
      "Epoch 164/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9725 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
      "Epoch 165/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9749 - val_loss: 0.0843 - val_accuracy: 0.9753\n",
      "Epoch 166/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9739 - val_loss: 0.0841 - val_accuracy: 0.9759\n",
      "Epoch 167/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9734 - val_loss: 0.0842 - val_accuracy: 0.9753\n",
      "Epoch 168/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9744 - val_loss: 0.0839 - val_accuracy: 0.9764\n",
      "Epoch 169/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.9742 - val_loss: 0.0840 - val_accuracy: 0.9760\n",
      "Epoch 170/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9750 - val_loss: 0.0834 - val_accuracy: 0.9759\n",
      "Epoch 171/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.9741 - val_loss: 0.0837 - val_accuracy: 0.9761\n",
      "Epoch 172/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.9730 - val_loss: 0.0833 - val_accuracy: 0.9765\n",
      "Epoch 173/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9747 - val_loss: 0.0835 - val_accuracy: 0.9762\n",
      "Epoch 174/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9742 - val_loss: 0.0838 - val_accuracy: 0.9755\n",
      "Epoch 175/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9760 - val_loss: 0.0832 - val_accuracy: 0.9765\n",
      "Epoch 176/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9750 - val_loss: 0.0830 - val_accuracy: 0.9759\n",
      "Epoch 177/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0809 - accuracy: 0.9757 - val_loss: 0.0830 - val_accuracy: 0.9765\n",
      "Epoch 178/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9746 - val_loss: 0.0828 - val_accuracy: 0.9762\n",
      "Epoch 179/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
      "Epoch 180/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.0826 - val_accuracy: 0.9763\n",
      "Epoch 181/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0807 - accuracy: 0.9749 - val_loss: 0.0828 - val_accuracy: 0.9762\n",
      "Epoch 182/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9742 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
      "Epoch 183/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9751 - val_loss: 0.0825 - val_accuracy: 0.9761\n",
      "Epoch 184/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0824 - val_accuracy: 0.9766\n",
      "Epoch 185/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9756 - val_loss: 0.0824 - val_accuracy: 0.9766\n",
      "Epoch 186/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9747 - val_loss: 0.0830 - val_accuracy: 0.9765\n",
      "Epoch 187/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.9755 - val_loss: 0.0829 - val_accuracy: 0.9766\n",
      "Epoch 188/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9765 - val_loss: 0.0826 - val_accuracy: 0.9765\n",
      "Epoch 189/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.0823 - val_accuracy: 0.9761\n",
      "Epoch 190/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9752 - val_loss: 0.0829 - val_accuracy: 0.9759\n",
      "Epoch 191/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9753 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
      "Epoch 192/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9770 - val_loss: 0.0822 - val_accuracy: 0.9764\n",
      "Epoch 193/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9759 - val_loss: 0.0817 - val_accuracy: 0.9763\n",
      "Epoch 194/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9779 - val_loss: 0.0816 - val_accuracy: 0.9761\n",
      "Epoch 195/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0754 - accuracy: 0.9759 - val_loss: 0.0819 - val_accuracy: 0.9763\n",
      "Epoch 196/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9767 - val_loss: 0.0818 - val_accuracy: 0.9764\n",
      "Epoch 197/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9768 - val_loss: 0.0817 - val_accuracy: 0.9773\n",
      "Epoch 198/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.0812 - val_accuracy: 0.9768\n",
      "Epoch 199/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.0815 - val_accuracy: 0.9758\n",
      "Epoch 200/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.0816 - val_accuracy: 0.9767\n",
      "Epoch 201/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9777 - val_loss: 0.0812 - val_accuracy: 0.9767\n",
      "Epoch 202/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0742 - accuracy: 0.9773 - val_loss: 0.0814 - val_accuracy: 0.9759\n",
      "Epoch 203/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.0811 - val_accuracy: 0.9765\n",
      "Epoch 204/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.9770 - val_loss: 0.0813 - val_accuracy: 0.9769\n",
      "Epoch 205/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.0811 - val_accuracy: 0.9768\n",
      "Epoch 206/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9775 - val_loss: 0.0809 - val_accuracy: 0.9764\n",
      "Epoch 207/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.0810 - val_accuracy: 0.9763\n",
      "Epoch 208/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9774 - val_loss: 0.0814 - val_accuracy: 0.9763\n",
      "Epoch 209/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.9775 - val_loss: 0.0810 - val_accuracy: 0.9767\n",
      "Epoch 210/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9780 - val_loss: 0.0815 - val_accuracy: 0.9771\n",
      "Epoch 211/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0717 - accuracy: 0.9769 - val_loss: 0.0813 - val_accuracy: 0.9765\n",
      "Epoch 212/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.0813 - val_accuracy: 0.9775\n",
      "Epoch 213/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9783 - val_loss: 0.0808 - val_accuracy: 0.9769\n",
      "Epoch 214/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 0.0807 - val_accuracy: 0.9769\n",
      "Epoch 215/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.0813 - val_accuracy: 0.9771\n",
      "Epoch 216/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9788 - val_loss: 0.0807 - val_accuracy: 0.9768\n",
      "Epoch 217/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9782 - val_loss: 0.0813 - val_accuracy: 0.9769\n",
      "Epoch 218/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9778 - val_loss: 0.0804 - val_accuracy: 0.9774\n",
      "Epoch 219/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9803 - val_loss: 0.0809 - val_accuracy: 0.9774\n",
      "Epoch 220/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.9791 - val_loss: 0.0803 - val_accuracy: 0.9772\n",
      "Epoch 221/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9787 - val_loss: 0.0800 - val_accuracy: 0.9772\n",
      "Epoch 222/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.0799 - val_accuracy: 0.9772\n",
      "Epoch 223/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9801 - val_loss: 0.0803 - val_accuracy: 0.9768\n",
      "Epoch 224/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9776\n",
      "Epoch 225/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 0.0813 - val_accuracy: 0.9772\n",
      "Epoch 226/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9804 - val_loss: 0.0805 - val_accuracy: 0.9768\n",
      "Epoch 227/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.0816 - val_accuracy: 0.9767\n",
      "Epoch 228/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9788 - val_loss: 0.0810 - val_accuracy: 0.9766\n",
      "Epoch 229/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 0.0809 - val_accuracy: 0.9771\n",
      "Epoch 230/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.9785 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
      "Epoch 231/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9786 - val_loss: 0.0805 - val_accuracy: 0.9770\n",
      "Epoch 232/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9792 - val_loss: 0.0804 - val_accuracy: 0.9772\n",
      "Epoch 233/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9796 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
      "Epoch 234/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.0802 - val_accuracy: 0.9773\n",
      "Epoch 235/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.0802 - val_accuracy: 0.9768\n",
      "Epoch 236/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 237/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.0809 - val_accuracy: 0.9772\n",
      "Epoch 238/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9794 - val_loss: 0.0811 - val_accuracy: 0.9769\n",
      "Epoch 239/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9803 - val_loss: 0.0805 - val_accuracy: 0.9768\n",
      "Epoch 240/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9805 - val_loss: 0.0799 - val_accuracy: 0.9775\n",
      "Epoch 241/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 242/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0627 - accuracy: 0.9818 - val_loss: 0.0804 - val_accuracy: 0.9777\n",
      "Epoch 243/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9812 - val_loss: 0.0804 - val_accuracy: 0.9774\n",
      "Epoch 244/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.0795 - val_accuracy: 0.9773\n",
      "Epoch 245/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9797 - val_loss: 0.0800 - val_accuracy: 0.9772\n",
      "Epoch 246/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.0805 - val_accuracy: 0.9774\n",
      "Epoch 247/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0804 - val_accuracy: 0.9772\n",
      "Epoch 248/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9804 - val_loss: 0.0798 - val_accuracy: 0.9778\n",
      "Epoch 249/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0797 - val_accuracy: 0.9775\n",
      "Epoch 250/250\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.0802 - val_accuracy: 0.9773\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0702 - accuracy: 0.9791\n",
      "\n",
      "Test score: 0.07024134695529938\n",
      "Test accuracy: 0.9790999889373779\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 385.78125 277.314375\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T10:15:30.986231</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 277.314375 \r\nL 385.78125 277.314375 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\nL 43.78125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m45f3f15a18\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(55.818182 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"120.116628\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(113.754128 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"181.233824\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(171.690074 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"242.35102\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(232.80727 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"303.468216\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(293.924466 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.585412\" xlink:href=\"#m45f3f15a18\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 250 -->\r\n      <g transform=\"translate(355.041662 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Epoch -->\r\n     <g transform=\"translate(195.870313 268.034687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mba459b472b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"207.297191\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(20.878125 211.09641)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"170.882198\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(20.878125 174.681417)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"134.467206\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.7 -->\r\n      <g transform=\"translate(20.878125 138.266424)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"98.052213\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(20.878125 101.851432)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"61.63722\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.9 -->\r\n      <g transform=\"translate(20.878125 65.436439)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba459b472b\" y=\"25.222228\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(20.878125 29.021447)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Acurácia -->\r\n     <g transform=\"translate(14.798438 152.610781)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\nM 35.796875 79.984375 \r\nL 45.515625 79.984375 \r\nL 29.59375 61.625 \r\nL 22.125 61.625 \r\nz\r\n\" id=\"DejaVuSans-225\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"185.017578\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"226.130859\" xlink:href=\"#DejaVuSans-225\"/>\r\n      <use x=\"287.410156\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"370.173828\" xlink:href=\"#DejaVuSans-97\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p4df2283b03)\" d=\"M 58.999432 229.874489 \r\nL 60.221776 129.346343 \r\nL 61.44412 101.784757 \r\nL 62.666464 90.55679 \r\nL 63.888808 83.068968 \r\nL 65.111151 78.198447 \r\nL 66.333495 74.162462 \r\nL 67.555839 71.363056 \r\nL 68.778183 69.663683 \r\nL 70.000527 67.190504 \r\nL 71.222871 65.870469 \r\nL 72.445215 64.011781 \r\nL 73.667559 62.411035 \r\nL 74.889903 61.219972 \r\nL 78.556935 58.883339 \r\nL 79.779278 57.972965 \r\nL 81.001622 56.660505 \r\nL 82.223966 56.038417 \r\nL 83.44631 55.598391 \r\nL 84.668654 54.62733 \r\nL 85.890998 54.445268 \r\nL 88.335686 53.132809 \r\nL 89.55803 53.087293 \r\nL 90.780374 52.055523 \r\nL 92.002718 51.585175 \r\nL 93.225062 51.478951 \r\nL 94.447406 50.523061 \r\nL 95.669749 50.538233 \r\nL 96.892093 49.529232 \r\nL 98.114437 50.128573 \r\nL 100.559125 48.983003 \r\nL 101.781469 48.110569 \r\nL 105.448501 47.776768 \r\nL 106.670845 46.737423 \r\nL 109.115533 46.646392 \r\nL 110.337877 46.069819 \r\nL 111.56022 46.183597 \r\nL 112.782564 45.478075 \r\nL 114.004908 45.872564 \r\nL 115.227252 45.531166 \r\nL 116.449596 44.840816 \r\nL 117.67194 44.992534 \r\nL 118.894284 44.878734 \r\nL 120.116628 44.461477 \r\nL 121.338972 44.484245 \r\nL 122.561316 44.332506 \r\nL 123.78366 43.824217 \r\nL 125.006004 43.72559 \r\nL 126.228347 43.027643 \r\nL 127.450691 43.399385 \r\nL 128.673035 42.807641 \r\nL 129.895379 42.830388 \r\nL 131.117723 42.966956 \r\nL 132.340067 42.534526 \r\nL 133.562411 42.352443 \r\nL 134.784755 42.443495 \r\nL 136.007099 41.806214 \r\nL 137.229443 41.88967 \r\nL 138.451787 41.434494 \r\nL 139.674131 41.77587 \r\nL 140.896475 41.260007 \r\nL 142.118818 41.108267 \r\nL 143.341162 41.548293 \r\nL 144.563506 41.229642 \r\nL 145.78585 41.085499 \r\nL 147.008194 40.508948 \r\nL 148.230538 40.994468 \r\nL 151.89757 40.766869 \r\nL 153.119914 40.395149 \r\nL 155.564602 40.463411 \r\nL 156.786946 39.727524 \r\nL 158.009289 39.886839 \r\nL 160.453977 39.363378 \r\nL 161.676321 39.795808 \r\nL 162.898665 39.143376 \r\nL 164.121009 39.264751 \r\nL 165.343353 39.105436 \r\nL 166.565697 39.21166 \r\nL 169.010385 39.037174 \r\nL 170.232729 38.991636 \r\nL 171.455073 39.188892 \r\nL 173.89976 38.38472 \r\nL 175.122104 38.195062 \r\nL 176.344448 37.86126 \r\nL 177.566792 38.437833 \r\nL 178.789136 38.544035 \r\nL 180.01148 38.066091 \r\nL 182.456168 37.967485 \r\nL 184.900856 37.497115 \r\nL 187.345544 37.527459 \r\nL 188.567887 37.891604 \r\nL 189.790231 37.709542 \r\nL 191.012575 37.65643 \r\nL 192.234919 37.345375 \r\nL 193.457263 37.360569 \r\nL 194.679607 37.163313 \r\nL 195.901951 37.421256 \r\nL 197.124295 37.375741 \r\nL 198.346639 36.791571 \r\nL 199.568983 37.261941 \r\nL 200.791327 37.254344 \r\nL 202.013671 36.996402 \r\nL 203.236015 36.60951 \r\nL 204.458358 36.920543 \r\nL 206.903046 36.768825 \r\nL 208.12539 36.404658 \r\nL 213.014766 36.480538 \r\nL 214.23711 36.123968 \r\nL 215.459454 36.404658 \r\nL 216.681798 36.222596 \r\nL 217.904142 36.541226 \r\nL 219.126485 36.563973 \r\nL 220.348829 36.192252 \r\nL 221.571173 35.949482 \r\nL 225.238205 36.245343 \r\nL 226.460549 35.805338 \r\nL 227.682893 36.169484 \r\nL 228.905237 35.881198 \r\nL 230.127581 35.994997 \r\nL 231.349925 35.706711 \r\nL 232.572269 35.866026 \r\nL 235.016956 35.426021 \r\nL 236.2393 35.82051 \r\nL 237.461644 35.570165 \r\nL 241.128676 35.365312 \r\nL 242.35102 35.570165 \r\nL 243.573364 35.054279 \r\nL 244.795708 35.334969 \r\nL 246.018052 34.993592 \r\nL 248.46274 35.205998 \r\nL 249.685084 34.910136 \r\nL 252.129771 35.14531 \r\nL 254.574459 34.591507 \r\nL 255.796803 34.682537 \r\nL 257.019147 34.561163 \r\nL 258.241491 35.023936 \r\nL 259.463835 34.682537 \r\nL 260.686179 35.046683 \r\nL 261.908523 34.750821 \r\nL 263.130867 34.288049 \r\nL 264.353211 34.508051 \r\nL 266.797898 34.58391 \r\nL 269.242586 34.728053 \r\nL 270.46493 34.545991 \r\nL 271.687274 34.159077 \r\nL 272.909618 34.227361 \r\nL 275.354306 34.181824 \r\nL 276.57665 34.257705 \r\nL 277.798994 34.568738 \r\nL 279.021338 34.272877 \r\nL 280.243682 34.500454 \r\nL 282.688369 34.204593 \r\nL 283.910713 34.052853 \r\nL 285.133057 34.189421 \r\nL 286.355401 33.908732 \r\nL 288.800089 34.318392 \r\nL 290.022433 34.045278 \r\nL 292.467121 33.77976 \r\nL 293.689465 33.848023 \r\nL 294.911809 33.483877 \r\nL 296.134153 33.665961 \r\nL 297.356496 33.976994 \r\nL 298.57884 33.605252 \r\nL 299.801184 33.635617 \r\nL 301.023528 33.855619 \r\nL 302.245872 33.38525 \r\nL 304.69056 33.415593 \r\nL 305.912904 33.665961 \r\nL 307.135248 33.681133 \r\nL 308.357592 33.354906 \r\nL 312.024623 33.476302 \r\nL 313.246967 33.53699 \r\nL 314.469311 33.10456 \r\nL 316.913999 33.27145 \r\nL 318.136343 33.445937 \r\nL 319.358687 33.096963 \r\nL 320.581031 33.233532 \r\nL 323.025719 32.967992 \r\nL 324.248063 33.309391 \r\nL 325.470407 32.763162 \r\nL 326.692751 33.210763 \r\nL 327.915094 32.967992 \r\nL 329.137438 33.332159 \r\nL 330.359782 32.967992 \r\nL 332.80447 33.043873 \r\nL 334.026814 32.42936 \r\nL 335.249158 32.816274 \r\nL 336.471502 32.892133 \r\nL 338.91619 32.770759 \r\nL 340.138534 33.180419 \r\nL 341.360878 32.603847 \r\nL 342.583222 32.808677 \r\nL 343.805565 32.778334 \r\nL 345.027909 32.5811 \r\nL 346.250253 32.634191 \r\nL 347.472597 32.967992 \r\nL 351.139629 32.254874 \r\nL 352.361973 32.656959 \r\nL 353.584317 32.201761 \r\nL 354.806661 32.497644 \r\nL 358.473692 32.527988 \r\nL 359.696036 32.656959 \r\nL 362.140724 32.270045 \r\nL 363.363068 32.383845 \r\nL 363.363068 32.383845 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p4df2283b03)\" d=\"M 58.999432 94.987285 \r\nL 60.221776 72.379633 \r\nL 61.44412 65.521496 \r\nL 62.666464 62.031718 \r\nL 63.888808 59.634398 \r\nL 65.111151 57.601223 \r\nL 66.333495 56.235673 \r\nL 67.555839 54.596987 \r\nL 68.778183 53.838352 \r\nL 70.000527 52.503124 \r\nL 71.222871 51.532063 \r\nL 76.112247 48.588514 \r\nL 77.334591 48.072629 \r\nL 79.779278 46.828453 \r\nL 81.001622 46.646392 \r\nL 83.44631 45.159445 \r\nL 85.890998 44.340102 \r\nL 87.113342 44.552529 \r\nL 88.335686 43.793874 \r\nL 90.780374 43.460072 \r\nL 92.002718 43.004874 \r\nL 95.669749 42.185553 \r\nL 96.892093 41.548293 \r\nL 98.114437 41.426897 \r\nL 99.336781 41.548293 \r\nL 101.781469 40.607554 \r\nL 103.003813 40.57721 \r\nL 104.226157 40.33444 \r\nL 105.448501 40.273752 \r\nL 106.670845 40.091691 \r\nL 107.893189 40.030982 \r\nL 109.115533 39.788233 \r\nL 110.337877 39.818576 \r\nL 111.56022 39.424066 \r\nL 114.004908 39.120608 \r\nL 116.449596 39.150973 \r\nL 117.67194 38.96889 \r\nL 120.116628 38.877859 \r\nL 121.338972 38.483348 \r\nL 122.561316 38.240577 \r\nL 123.78366 38.574401 \r\nL 126.228347 38.028172 \r\nL 127.450691 38.240577 \r\nL 128.673035 38.149547 \r\nL 129.895379 37.815745 \r\nL 132.340067 37.664027 \r\nL 133.562411 37.4516 \r\nL 134.784755 37.572974 \r\nL 138.451787 37.026745 \r\nL 140.896475 37.117798 \r\nL 142.118818 36.81434 \r\nL 143.341162 36.844684 \r\nL 144.563506 36.692944 \r\nL 145.78585 36.875027 \r\nL 148.230538 36.81434 \r\nL 150.675226 36.692944 \r\nL 151.89757 36.359142 \r\nL 158.009289 36.419829 \r\nL 160.453977 35.994997 \r\nL 166.565697 36.055684 \r\nL 167.788041 35.873622 \r\nL 169.010385 35.964653 \r\nL 170.232729 35.752226 \r\nL 171.455073 35.843257 \r\nL 172.677416 35.752226 \r\nL 173.89976 35.509456 \r\nL 175.122104 35.630852 \r\nL 176.344448 35.509456 \r\nL 178.789136 35.570165 \r\nL 180.01148 35.570165 \r\nL 181.233824 35.418425 \r\nL 182.456168 35.539799 \r\nL 183.678512 35.266707 \r\nL 187.345544 35.448768 \r\nL 188.567887 35.205998 \r\nL 191.012575 35.266707 \r\nL 193.457263 35.023936 \r\nL 194.679607 35.175654 \r\nL 195.901951 35.054279 \r\nL 197.124295 35.114967 \r\nL 198.346639 35.023936 \r\nL 202.013671 35.114967 \r\nL 204.458358 34.90254 \r\nL 208.12539 34.993592 \r\nL 209.347734 34.993592 \r\nL 213.014766 34.538394 \r\nL 214.23711 34.963249 \r\nL 216.681798 34.750821 \r\nL 217.904142 34.993592 \r\nL 219.126485 34.629425 \r\nL 220.348829 34.781165 \r\nL 221.571173 34.599082 \r\nL 226.460549 34.477707 \r\nL 227.682893 34.629425 \r\nL 236.2393 34.295624 \r\nL 237.461644 34.325967 \r\nL 239.906332 34.174249 \r\nL 241.128676 34.447363 \r\nL 242.35102 34.234936 \r\nL 243.573364 34.143905 \r\nL 244.795708 34.234936 \r\nL 247.240396 34.143905 \r\nL 248.46274 34.325967 \r\nL 249.685084 34.052853 \r\nL 250.907427 34.143905 \r\nL 252.129771 33.992166 \r\nL 253.352115 34.386676 \r\nL 254.574459 33.870791 \r\nL 255.796803 34.113562 \r\nL 257.019147 34.174249 \r\nL 258.241491 34.052853 \r\nL 259.463835 34.204593 \r\nL 260.686179 33.992166 \r\nL 261.908523 34.204593 \r\nL 263.130867 33.810104 \r\nL 264.353211 33.961822 \r\nL 266.797898 33.931478 \r\nL 268.020242 33.77976 \r\nL 269.242586 33.901135 \r\nL 270.46493 34.143905 \r\nL 271.687274 33.77976 \r\nL 272.909618 33.992166 \r\nL 274.131962 33.77976 \r\nL 276.57665 33.961822 \r\nL 277.798994 33.840447 \r\nL 281.466025 33.931478 \r\nL 282.688369 33.749395 \r\nL 287.577745 33.77976 \r\nL 290.022433 33.992166 \r\nL 291.244777 33.719051 \r\nL 294.911809 33.931478 \r\nL 297.356496 33.810104 \r\nL 298.57884 33.476302 \r\nL 299.801184 33.658364 \r\nL 301.023528 34.052853 \r\nL 302.245872 33.719051 \r\nL 303.468216 33.719051 \r\nL 304.69056 33.992166 \r\nL 307.135248 33.62802 \r\nL 308.357592 33.658364 \r\nL 309.579936 33.810104 \r\nL 312.024623 33.840447 \r\nL 314.469311 33.567333 \r\nL 315.691655 33.77976 \r\nL 316.913999 33.415593 \r\nL 318.136343 33.62802 \r\nL 323.025719 33.62802 \r\nL 324.248063 33.445937 \r\nL 329.137438 33.506646 \r\nL 330.359782 33.688708 \r\nL 331.582126 33.38525 \r\nL 334.026814 33.658364 \r\nL 336.471502 33.749395 \r\nL 337.693846 33.567333 \r\nL 338.91619 33.506646 \r\nL 340.138534 33.597677 \r\nL 341.360878 33.506646 \r\nL 342.583222 33.597677 \r\nL 343.805565 33.476302 \r\nL 345.027909 33.688708 \r\nL 346.250253 33.324562 \r\nL 347.472597 33.53699 \r\nL 349.917285 33.658364 \r\nL 351.139629 33.415593 \r\nL 352.361973 33.294219 \r\nL 357.251349 33.53699 \r\nL 358.473692 33.445937 \r\nL 359.696036 33.506646 \r\nL 360.91838 33.294219 \r\nL 363.363068 33.476302 \r\nL 363.363068 33.476302 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 43.78125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 22.318125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_15\">\r\n    <!-- Acurácia do Modelo -->\r\n    <g transform=\"translate(152.312813 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"185.017578\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"226.130859\" xlink:href=\"#DejaVuSans-225\"/>\r\n     <use x=\"287.410156\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"370.173828\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"431.453125\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"463.240234\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"526.716797\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"587.898438\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"619.685547\" xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"705.964844\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"767.146484\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"830.623047\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"892.146484\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"919.929688\" xlink:href=\"#DejaVuSans-111\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 50.78125 59.674375 \r\nL 112.6875 59.674375 \r\nQ 114.6875 59.674375 114.6875 57.674375 \r\nL 114.6875 29.318125 \r\nQ 114.6875 27.318125 112.6875 27.318125 \r\nL 50.78125 27.318125 \r\nQ 48.78125 27.318125 48.78125 29.318125 \r\nL 48.78125 57.674375 \r\nQ 48.78125 59.674375 50.78125 59.674375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\">\r\n     <path d=\"M 52.78125 35.416562 \r\nL 72.78125 35.416562 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\"/>\r\n    <g id=\"text_16\">\r\n     <!-- Treino -->\r\n     <g transform=\"translate(80.78125 38.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"85.197266\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"146.720703\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"174.503906\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"237.882812\" xlink:href=\"#DejaVuSans-111\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 52.78125 50.094687 \r\nL 72.78125 50.094687 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_17\">\r\n     <!-- Teste -->\r\n     <g transform=\"translate(80.78125 53.594687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p4df2283b03\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T10:15:31.247665</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 277.314375 \r\nL 392.14375 277.314375 \r\nL 392.14375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 384.94375 239.758125 \r\nL 384.94375 22.318125 \r\nL 50.14375 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m3200393365\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.479128\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(120.116628 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.596324\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(178.052574 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.71352\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(239.16977 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.830716\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(300.286966 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.947912\" xlink:href=\"#m3200393365\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 250 -->\r\n      <g transform=\"translate(361.404162 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Epoch -->\r\n     <g transform=\"translate(202.232813 268.034687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m9281bc7445\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"236.961778\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(20.878125 240.760997)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"208.056839\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(20.878125 211.856058)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"179.151899\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.50 -->\r\n      <g transform=\"translate(20.878125 182.951118)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"150.24696\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.75 -->\r\n      <g transform=\"translate(20.878125 154.046179)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"121.342021\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.00 -->\r\n      <g transform=\"translate(20.878125 125.141239)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"92.437081\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.25 -->\r\n      <g transform=\"translate(20.878125 96.2363)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"63.532142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.50 -->\r\n      <g transform=\"translate(20.878125 67.33136)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9281bc7445\" y=\"34.627202\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 1.75 -->\r\n      <g transform=\"translate(20.878125 38.426421)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_16\">\r\n     <!-- Loss -->\r\n     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p0ab2da38b6)\" d=\"M 65.361932 32.201761 \r\nL 66.584276 127.675437 \r\nL 67.80662 156.18941 \r\nL 69.028964 167.744655 \r\nL 70.251308 174.840745 \r\nL 71.473651 180.111082 \r\nL 72.695995 183.83967 \r\nL 73.918339 186.809713 \r\nL 76.363027 191.178625 \r\nL 77.585371 193.039547 \r\nL 78.807715 194.274169 \r\nL 80.030059 196.239566 \r\nL 82.474747 198.86274 \r\nL 86.141778 201.447301 \r\nL 87.364122 202.526041 \r\nL 91.031154 204.775146 \r\nL 92.253498 205.044744 \r\nL 94.698186 206.800275 \r\nL 95.92053 206.963155 \r\nL 97.142874 207.918486 \r\nL 98.365218 208.29663 \r\nL 99.587562 208.486014 \r\nL 100.809906 209.072172 \r\nL 102.032249 209.364596 \r\nL 103.254593 210.062115 \r\nL 104.476937 210.256935 \r\nL 108.143969 211.928735 \r\nL 116.700377 214.10922 \r\nL 117.92272 214.167398 \r\nL 119.145064 214.810848 \r\nL 120.367408 214.825066 \r\nL 122.812096 215.452866 \r\nL 125.256784 215.90115 \r\nL 127.701472 216.170978 \r\nL 128.923816 216.630054 \r\nL 131.368504 216.988442 \r\nL 132.590847 217.42788 \r\nL 133.813191 217.346025 \r\nL 135.035535 217.899746 \r\nL 137.480223 217.855253 \r\nL 138.702567 218.219914 \r\nL 139.924911 218.406897 \r\nL 141.147255 218.453402 \r\nL 142.369599 219.192449 \r\nL 143.591943 218.816671 \r\nL 144.814287 219.247631 \r\nL 146.036631 219.008888 \r\nL 147.258975 219.524358 \r\nL 148.481318 219.661452 \r\nL 152.14835 219.82596 \r\nL 153.370694 220.495821 \r\nL 154.593038 219.781282 \r\nL 155.815382 220.521129 \r\nL 158.26007 220.523287 \r\nL 159.482414 220.982092 \r\nL 160.704758 220.735309 \r\nL 161.927102 220.815005 \r\nL 163.149446 221.261059 \r\nL 164.371789 221.222763 \r\nL 165.594133 221.361289 \r\nL 166.816477 221.714512 \r\nL 168.038821 221.318905 \r\nL 169.261165 221.872688 \r\nL 172.928197 222.057306 \r\nL 174.150541 222.079804 \r\nL 175.372885 222.385517 \r\nL 176.595229 222.211264 \r\nL 177.817573 222.201954 \r\nL 182.706948 223.0146 \r\nL 185.151636 222.991316 \r\nL 186.37398 223.254703 \r\nL 188.818668 223.219471 \r\nL 190.041012 223.574101 \r\nL 194.930387 223.597638 \r\nL 196.152731 223.878031 \r\nL 197.375075 223.707908 \r\nL 198.597419 224.119237 \r\nL 201.042107 224.002847 \r\nL 202.264451 223.982342 \r\nL 203.486795 224.116686 \r\nL 204.709139 224.367423 \r\nL 205.931483 224.159012 \r\nL 208.376171 224.301064 \r\nL 209.598515 224.744277 \r\nL 210.820858 224.547285 \r\nL 213.265546 224.607924 \r\nL 214.48789 225.267187 \r\nL 215.710234 224.903986 \r\nL 216.932578 225.160336 \r\nL 218.154922 224.893681 \r\nL 219.377266 225.162189 \r\nL 220.59961 225.221272 \r\nL 221.821954 225.134016 \r\nL 223.044298 225.425547 \r\nL 224.266642 225.129604 \r\nL 225.488985 225.145913 \r\nL 227.933673 225.90535 \r\nL 229.156017 225.737655 \r\nL 230.378361 225.715339 \r\nL 231.600705 225.410158 \r\nL 232.823049 225.957392 \r\nL 234.045393 225.76401 \r\nL 235.267737 225.747949 \r\nL 236.490081 225.545392 \r\nL 237.712425 225.891839 \r\nL 240.157113 226.193926 \r\nL 241.379456 226.352112 \r\nL 242.6018 225.878842 \r\nL 243.824144 226.077864 \r\nL 246.268832 226.133229 \r\nL 251.158208 226.49041 \r\nL 254.82524 226.722446 \r\nL 256.047584 226.953958 \r\nL 257.269927 226.724596 \r\nL 259.714615 226.682342 \r\nL 260.936959 226.900198 \r\nL 262.159303 226.801591 \r\nL 263.381647 227.152445 \r\nL 264.603991 226.905433 \r\nL 265.826335 226.868996 \r\nL 267.048679 227.136691 \r\nL 268.271023 227.18109 \r\nL 269.493367 227.482134 \r\nL 270.715711 227.141307 \r\nL 271.938054 227.440638 \r\nL 274.382742 227.339661 \r\nL 276.82743 227.230747 \r\nL 278.049774 227.453238 \r\nL 280.494462 227.492002 \r\nL 281.716806 227.772111 \r\nL 284.161494 227.565902 \r\nL 285.383838 227.683257 \r\nL 286.606182 227.420503 \r\nL 291.495557 227.94171 \r\nL 293.940245 228.004879 \r\nL 295.162589 227.838287 \r\nL 296.384933 228.052607 \r\nL 297.607277 227.978608 \r\nL 298.829621 228.156269 \r\nL 300.051965 228.090071 \r\nL 301.274309 228.389362 \r\nL 302.496653 228.304952 \r\nL 303.718996 228.061511 \r\nL 304.94134 228.255486 \r\nL 307.386028 228.29763 \r\nL 308.608372 228.51085 \r\nL 311.05306 228.402029 \r\nL 312.275404 228.241356 \r\nL 315.942436 228.627407 \r\nL 317.16478 228.447584 \r\nL 318.387123 228.594297 \r\nL 319.609467 228.489754 \r\nL 322.054155 228.965819 \r\nL 323.276499 228.708781 \r\nL 324.498843 228.691325 \r\nL 326.943531 229.013426 \r\nL 328.165875 228.897311 \r\nL 329.388219 228.978661 \r\nL 330.610563 228.844309 \r\nL 331.832907 229.154227 \r\nL 333.055251 228.88766 \r\nL 337.944626 229.106414 \r\nL 339.16697 228.980119 \r\nL 340.389314 229.341776 \r\nL 341.611658 229.186923 \r\nL 344.056346 229.134852 \r\nL 345.27869 229.267904 \r\nL 346.501034 229.090156 \r\nL 347.723378 229.255998 \r\nL 348.945722 229.125725 \r\nL 350.168065 229.42615 \r\nL 352.612753 229.349136 \r\nL 353.835097 229.476147 \r\nL 355.057441 229.344483 \r\nL 357.502129 229.585673 \r\nL 366.058536 229.482281 \r\nL 367.28088 229.79295 \r\nL 368.503224 229.874489 \r\nL 369.725568 229.712032 \r\nL 369.725568 229.712032 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p0ab2da38b6)\" d=\"M 65.361932 125.941535 \r\nL 66.584276 174.563432 \r\nL 67.80662 188.04347 \r\nL 69.028964 193.897757 \r\nL 70.251308 197.561444 \r\nL 71.473651 200.410472 \r\nL 72.695995 202.529949 \r\nL 73.918339 204.161881 \r\nL 77.585371 208.018112 \r\nL 82.474747 211.489026 \r\nL 84.919435 212.827078 \r\nL 86.141778 213.409084 \r\nL 88.586466 214.383394 \r\nL 89.80881 215.044513 \r\nL 93.475842 216.183007 \r\nL 94.698186 216.783913 \r\nL 102.032249 218.578241 \r\nL 103.254593 218.989345 \r\nL 105.699281 219.316826 \r\nL 106.921625 219.712733 \r\nL 117.92272 221.614211 \r\nL 126.479128 222.524741 \r\nL 128.923816 222.856241 \r\nL 132.590847 223.170382 \r\nL 133.813191 223.164793 \r\nL 136.257879 223.539093 \r\nL 138.702567 223.646602 \r\nL 139.924911 223.797175 \r\nL 142.369599 223.890637 \r\nL 144.814287 224.124063 \r\nL 147.258975 224.278672 \r\nL 152.14835 224.474979 \r\nL 153.370694 224.512271 \r\nL 155.815382 224.734279 \r\nL 159.482414 224.974928 \r\nL 160.704758 224.905115 \r\nL 161.927102 225.063667 \r\nL 163.149446 225.027301 \r\nL 169.261165 225.341112 \r\nL 175.372885 225.623658 \r\nL 176.595229 225.569763 \r\nL 180.26226 225.822641 \r\nL 182.706948 225.813463 \r\nL 185.151636 225.941949 \r\nL 192.4857 226.125813 \r\nL 198.597419 226.25154 \r\nL 202.264451 226.403311 \r\nL 258.492271 227.191203 \r\nL 263.381647 227.216651 \r\nL 274.382742 227.335084 \r\nL 278.049774 227.342105 \r\nL 281.716806 227.386752 \r\nL 282.93915 227.326698 \r\nL 284.161494 227.414569 \r\nL 287.828525 227.428877 \r\nL 304.94134 227.513965 \r\nL 307.386028 227.533984 \r\nL 314.720092 227.585896 \r\nL 319.609467 227.599837 \r\nL 322.054155 227.56284 \r\nL 329.388219 227.566417 \r\nL 330.610563 227.662745 \r\nL 331.832907 227.602593 \r\nL 335.499938 227.722846 \r\nL 339.16697 227.567467 \r\nL 340.389314 227.649677 \r\nL 341.611658 227.522441 \r\nL 344.056346 227.613211 \r\nL 351.390409 227.687968 \r\nL 355.057441 227.584584 \r\nL 358.724473 227.715645 \r\nL 361.169161 227.670773 \r\nL 362.391505 227.769059 \r\nL 366.058536 227.662159 \r\nL 368.503224 227.752245 \r\nL 369.725568 227.689315 \r\nL 369.725568 227.689315 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 50.14375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 384.94375 239.758125 \r\nL 384.94375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 384.94375 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 50.14375 22.318125 \r\nL 384.94375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_17\">\r\n    <!-- Perda do Modelo -->\r\n    <g transform=\"translate(167.622813 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-80\"/>\r\n     <use x=\"56.677734\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"118.201172\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"157.564453\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"221.041016\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"282.320312\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"314.107422\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"377.583984\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"438.765625\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"470.552734\" xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"556.832031\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"618.013672\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"681.490234\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"743.013672\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"770.796875\" xlink:href=\"#DejaVuSans-111\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 57.14375 59.674375 \r\nL 119.05 59.674375 \r\nQ 121.05 59.674375 121.05 57.674375 \r\nL 121.05 29.318125 \r\nQ 121.05 27.318125 119.05 27.318125 \r\nL 57.14375 27.318125 \r\nQ 55.14375 27.318125 55.14375 29.318125 \r\nL 55.14375 57.674375 \r\nQ 55.14375 59.674375 57.14375 59.674375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 59.14375 35.416562 \r\nL 79.14375 35.416562 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_18\">\r\n     <!-- Treino -->\r\n     <g transform=\"translate(87.14375 38.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"85.197266\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"146.720703\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"174.503906\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"237.882812\" xlink:href=\"#DejaVuSans-111\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 59.14375 50.094687 \r\nL 79.14375 50.094687 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_19\">\r\n     <!-- Teste -->\r\n     <g transform=\"translate(87.14375 53.594687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p0ab2da38b6\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvqUlEQVR4nO3deZxcdZ3v/9enTlX13umkOxsJWQhhCZAgxDgssqisAz8QLiPouP305sc4bnj1h15HB3S8OjorwjXDjAzDiDBXBUGNyKLsCCQIQkgIIQmkydKdtffqWj73j3O6u9Kp7nSSrq5O9/v5eNSjzl7f05X0u7/f7znfY+6OiIhIf7FSF0BEREYnBYSIiBSkgBARkYIUECIiUpACQkREClJAiIhIQQoIGdfM7FEz++RoO9ZwMLMbzOxHQ9x2VJVdRgcFhIx6ZrbRzDrNrM3MtpnZv5tZdanLNVzM7BwzczO7p9/yRdHyR0tUNBnnFBByuLjU3auBU4B3An91IDtbaDT/e28GTjez+rxlHwXWlqg8IgoIOby4+9vAr4ETAczsT8zsaTPbbWYvmdk5PdtGzSbfMrOngA7gKDM7z8zWmNkeM7sZsLzt55nZb81sh5ltN7M7zaxuoLLs51gxM/srM3vTzJrM7A4zmzDIqXUDPweujvYPgD8D7uz3maeb2fPRZz5vZqfnrZtrZo+ZWauZPQQ09Nt3wJ9Vv+0OtOwyRikg5LBiZkcCFwN/MLMZwK+AvwEmAV8EfmZmk/N2+TCwFKgB9gA/I6x9NABvAGfkHx74NnAEcDxwJHDDAOVo2M+xPha9zgWOAqqBm/dzencAH4mmLwBWAZvzPnNSdL43AfXAPwC/yqt1/BhYGZXnm4Q1kJ59h/KzOpSyyxikgJDDxc/NbDfwJPAY8L+APweWu/tyd8+5+0PACsIA6XG7u69y9wxwEfCqu//U3dPAPwFbezZ093Xu/pC7p9y9mfAX8NkDlOfiwY4FfAj4B3df7+5twFeAq80sPtAJuvvTwCQzO5YwKO7ot8mfAq+7+3+6e8bd7wLWAJea2SzCprevReV/HPhF3r5D+VkddNllbFJAyOHicnevc/fZ7v4pd+8EZgNXRU0mu6MAOROYnrffprzpI/LnPRypsnfezKaY2d1m9raZtQA/ol8zzVCPFa1/M2/+TSAOTN3Pef4n8GnCv97vLfCZb/Zb9iYwI1q3y93b+63rMZSf1aGWXcYY/UUgh7NNwH+6+38fZJv84Yq3EDYbAWHHdf48YfOSAwvdfYeZXc7ATSv7O9Zmwl/KPWYBGWDbIGWFMCDWAXe4e0d42AGP2XPcB6LyTDSzqryQmEXf+Q/lZ3WoZZcxRjUIOZz9iLB55QIzC8ysPLpkdOYA2/8KOMHMroiaSz4LTMtbXwO0AbujNvsvDfLZ+zvWXcB1UcdxNWGT2H9FTV0DcvcNhM1aXy2wejlwjJl90MziZvYBYAHwS3d/k7DJ6EYzS5rZmcClefseyM/qoMouY48CQg5b7r4JuAz4n4SXiW4i/KVe8N+1u28HrgK+A+wA5gNP5W1yI+FltHsIA+Ce/sc4gGPdRlgbeBzYAHQBnxnieT3p7psLLN8BXAL8j+gz/3/gkqgsAB8E3gXsBP6avD6MA/xZHXTZZWwxPTBIREQKUQ1CREQKUkCIiEhBCggRESlIASEiIgWNqfsgGhoafM6cOaUuhojIYWPlypXb3b3QkCtjKyDmzJnDihUrSl0MEZHDhpn1vzu/l5qYRESkIAWEiIgUpIAQEZGCxlQfRCHpdJrGxka6urpKXZSSKC8vZ+bMmSQSiVIXRUQOM2M+IBobG6mpqWHOnDn0GxlzzHN3duzYQWNjI3Pnzi11cUTkMDPmm5i6urqor68fd+EAYGbU19eP29qTiByaMR8QwLgMhx7j+dxF5NCMi4DYn20tXbR2pUtdDBGRUaVofRBmdhvh2PVN7n5igfVfInz2bU85jgcmu/tOM9sItAJZIOPui4tVToDm1hT1VUlqyoe3I3fHjh28973vBWDr1q0EQcDkyeENi8899xzJZHLAfZctW0ZlZSUf+chHBtxGRKSYitlJfTvh4xr7P3gdAHf/HvA9ADO7FLjO3XfmbXJu3oNQisrY+7mUw6W+vp4XX3wRgBtuuIHq6mq++MUv9q7PZDLE44W/gmuvvbYIJRIRGbqiNTG5++OET7YaimsIH3NYGlacgCjkYx/7GF/4whc499xzuf7663njjTe48MILOfXUU3n3u9/NmjVrgDBQ/u7v/g6Ac845h+uvv54lS5ZwzDHH8MQTTwBhB/zHP/5xTjrpJN7xjnfwu9/9boTOQkTGg5Jf5mpmlcCFwKfzFjvwoJk58C/ufusg+y8FlgLMmjVr0M+68RereHVzyz7LO7qzxGNGMn7gebngiFr++tITDmiftWvX8vDDDxMEAe9973tZtmwZ8+fP59lnn+VTn/oUv/3tb/fZJ5PJ8Nxzz7F8+XJuvPFGHn74YW655RYAXn75ZdasWcP555/P2rVrKS8vP+DzEBHpr+QBQfhg9af6NS+d4e6bzWwK8JCZrYlqJPuIwuNWgMWLFx90RWAkH7x61VVXEQQBbW1tPP3001x11VW961KpVMF9rrjiCgBOPfVUNm7cCMCTTz7JZz4TPir4uOOOY/bs2axdu5aFCxcW9wREZFwYDQFxNf2al3oe2O7uTWZ2L7CE8AHqh2Sgv/RXb2mhpizOzEmVh/oRQ1JVVQVALpejrq6ut59iMGVlZQAEQUAmkwHCG+FERIqlpJe5mtkE4GzgvrxlVWZW0zMNnA+8UtRyMLI1iB61tbXMnTuXn/zkJ0D4C/+ll14a8v5nnXUWd955JxA2W7311lsce+yxRSmriIw/RQsIM7sLeAY41swazewTZnatmeVfnvN+4EF3b89bNhV40sxeAp4DfuXuDxSrnGFhi3r0Qd1555388Ic/ZNGiRZxwwgncd999+98p8qlPfYpsNstJJ53EBz7wAW6//fbemoaIyKGysdRMsXjxYu//wKDVq1dz/PHHD7rfa1tbqUgEzKofmSamkTaUn4GIjE9mtnKge810J3XES9LIJCIyeikgAA1XJCKyLwVEZAy1tImIDAsFBCXtoxYRGbUUEIRNTKpAiIjsTQEBgOmmMxGRfkbDndQlV6wmpkMZ7hvg0UcfJZlMcvrppxephCIiA1NAQNFGc93fcN/78+ijj1JdXa2AEJGSUBMTUQ1ihFqYVq5cydlnn82pp57KBRdcwJYtWwC46aabWLBgAQsXLuTqq69m48aNLFu2jH/8x3/k5JNP5oknnqC5uZkrr7ySd77znbzzne/kqaeeGplCi8i4NL5qEL/+Mmx9eZ/F09PZcCIRHPgxp50EF31nSJu6O5/5zGe47777mDx5Mv/1X//FV7/6VW677Ta+853vsGHDBsrKyti9ezd1dXVce+21e9U6PvjBD3Lddddx5pln8tZbb3HBBRewevXqAy+ziMgQjK+AGFTxqxCpVIpXXnmF8847D4BsNsv06dMBWLhwIR/60Ie4/PLLufzyywvu//DDD/Pqq6/2zre0tNDa2kpNTU3Ryy4i48/4CogB/tLftr2ddDbH/KnF/UXr7pxwwgk888wz+6z71a9+xeOPP87999/PN7/5TVatWrXPNrlcjmeeeYaKioqillNEBNQH0WskuiDKyspobm7uDYh0Os2qVavI5XJs2rSJc889l+9+97vs3r2btrY2ampqaG1t7d3//PPP5+abb+6dH8pzJEREDpYCgpEbiykWi/HTn/6U66+/nkWLFnHyySfz9NNPk81m+fM///PeZ0tfd9111NXVcemll3Lvvff2dlLfdNNNrFixgoULF7JgwQKWLVs2MgUXkXFJw30Db+5opyud49hpY7MtX8N9i8hANNz3fljJniknIjJ6KSDQWEwiIoWMi4AYUjPaGE2IsdSEKCIja8wHRHl5OTt27Bj0F+VYbWByd3bs2EF5eXmpiyIih6Gi3QdhZrcBlwBN7n5igfXnAPcBG6JF97j7N6J1FwL/DATAv7n70G5VLmDmzJk0NjbS3Nw84Da7OrrpSudg99j7RVpeXs7MmTNLXQwROQwV80a524GbgTsG2eYJd78kf4GZBcAtwHlAI/C8md3v7q8WOsD+JBIJ5s6dO+g2f/Xzl1n+chMvfO28g/kIEZExqWhNTO7+OLDzIHZdAqxz9/Xu3g3cDVw2rIXrJx6Lkc2NxUYmEZGDV+o+iNPM7CUz+7WZnRAtmwFsytumMVpWNDEzBYSISD+lHIvpBWC2u7eZ2cXAz4H5FH5+z4C/vc1sKbAUYNasWQdVkCCGAkJEpJ+S1SDcvcXd26Lp5UDCzBoIawxH5m06E9g8yHFudffF7r6452ltByoWM7K6HFREZC8lCwgzm2YWjoJkZkuisuwAngfmm9lcM0sCVwP3F7Ms8ZiamERE+ivmZa53AecADWbWCPw1kABw92XAfwP+wswyQCdwtYc3K2TM7NPAbwgvc73N3fcd+3oYBeqDEBHZR9ECwt2v2c/6mwkvgy20bjmwvBjlKiQWC7s9cjnvnRYRGe9KfRXTqBCPQkH9ECIifRQQ9NUg1MwkItJHAUHYBwEKCBGRfAoIIFATk4jIPhQQ9AVETjUIEZFeCgj6AiKjgBAR6aWAIByLCVSDEBHJp4BAfRAiIoUoIMhrYsoqIEREeigg6LvMNacahIhILwUEeU1M6oMQEemlgCDvMlfVIEREeikg0GWuIiKFKCDou8xVTUwiIn0UEOTfSV3igoiIjCIKCDTct4hIIQoI8of7VhVCRKSHAoL84b5LXBARkVFEAQHEop+COqlFRPooIIB4lBAKCBGRPkULCDO7zcyazOyVAdZ/yMz+GL2eNrNFees2mtnLZvaima0oVhl7BD01CHVSi4j0KmYN4nbgwkHWbwDOdveFwDeBW/utP9fdT3b3xUUqXy8N9y0isq94sQ7s7o+b2ZxB1j+dN/t7YGaxyrI/amISEdnXaOmD+ATw67x5Bx40s5VmtnSwHc1sqZmtMLMVzc3NB/XhPZ3UGmpDRKRP0WoQQ2Vm5xIGxJl5i89w981mNgV4yMzWuPvjhfZ391uJmqcWL158UL/hNVifiMi+SlqDMLOFwL8Bl7n7jp7l7r45em8C7gWWFLMcgcZiEhHZR8kCwsxmAfcAH3b3tXnLq8yspmcaOB8oeCXUcFENQkRkX0VrYjKzu4BzgAYzawT+GkgAuPsy4OtAPfC/LfwLPhNdsTQVuDdaFgd+7O4PFKucoEeOiogUUsyrmK7Zz/pPAp8ssHw9sGjfPYqnd7hv1SBERHqNlquYSqpvuG8FhIhIDwUEfcN96zJXEZE+Cgj6hvtWJ7WISB8FBLrMVUSkEAUEEAQKCBGR/hQQqAYhIlKIAoK+q5h0mauISB8FBBruW0SkEAUEfZe56pnUIiJ9FBD0XeaazSkhRER6KCAiQczUByEikkcBEQnM1MQkIpJHAREJYqYmJhGRPAqISBgQpS6FiMjooYCIxExjMYmI5FNAROJBTHdSi4jkUUBEYmYa7ltEJI8CIhLEdCe1iEg+BUQkMN0HISKSTwERCQJTDUJEJE/RAsLMbjOzJjN7ZYD1ZmY3mdk6M/ujmZ2St+5CM3stWvflYpUxX6A+CBGRvRSzBnE7cOEg6y8C5kevpcAPAMwsAG6J1i8ArjGzBUUsJxCOx6QmJhGRPkULCHd/HNg5yCaXAXd46PdAnZlNB5YA69x9vbt3A3dH2xZVYGpiEhHJV8o+iBnAprz5xmjZQMsLMrOlZrbCzFY0NzcfdGGCmJqYRETylTIgrMAyH2R5Qe5+q7svdvfFkydPPujCBDHVIERE8g0pIMysysxi0fQxZvb/mFniED+7ETgyb34msHmQ5UWl4b5FRPY21BrE40C5mc0AHgE+TtgJfSjuBz4SXc30J8Aed98CPA/MN7O5ZpYEro62LapwsD4FhIhIj6EGhLl7B3AF8H13fz/hFUYD72B2F/AMcKyZNZrZJ8zsWjO7NtpkObAeWAf8K/ApAHfPAJ8GfgOsBv6Pu686wPM6MP9xKX/a+UsFhIhInvgQtzMzOw34EPCJoezr7tfsZ70DfznAuuWEATIy3n6BaYl6BYSISJ6h1iA+D3wFuNfdV5nZUcDvilaqkRYkSZJRQIiI5BlSDcLdHwMeA4g6q7e7+2eLWbARFSQpI0NXJlvqkoiIjBpDvYrpx2ZWa2ZVwKvAa2b2peIWbQTFk5RZlo5uBYSISI+hNjEtcPcW4HLCvoFZwIeLVagRFyQpswydCggRkV5DDYhEdN/D5cB97p5mkJvXDjtRQKgGISLSZ6gB8S/ARqAKeNzMZgMtxSrUiAuSJFWDEBHZy5ACwt1vcvcZ7n5xNLjem8C5RS7byImuYurO5shkc6UujYjIqDDUTuoJZvYPPYPimdnfE9YmxoZ4GQlPA9CRVi1CRASG3sR0G9AK/Fn0agH+vViFGnFBgjgZALrUzCQiAgz9Tup57n5l3vyNZvZiEcpTGkEZiSgg1FEtIhIaag2i08zO7JkxszOAzuIUqQSCBEFPE5MCQkQEGHoN4lrgDjObEM3vAj5anCKVQLyMIBcGRGc6U+LCiIiMDkMdauMlYJGZ1UbzLWb2eeCPRSzbyAmSqkGIiPRzQE+Uc/eW6I5qgC8UoTylESSI5RQQIiL5DuWRo4UeDXp4CsqI5boBdLOciEjkUAJiDA21kcCyYUCoBiEiEhq0D8LMWikcBAZUFKVEpRAvywsIdVKLiMD+nwpXM1IFKakgiXmWGDk1MYmIRA6liWnsCJIAVARZDbUhIhJRQEBvQExIuGoQIiKRogaEmV1oZq+Z2Toz+3KB9V8ysxej1ytmljWzSdG6jWb2crRuRTHLSbwMgNqEqw9CRCQy1DupD5iZBcAtwHlAI/C8md3v7q/2bOPu3wO+F21/KXCdu+/MO8y57r69WGXsFSQAqE3kdBWTiEikmDWIJcA6d1/v7t3A3cBlg2x/DXBXEcszsKiJqUZNTCIivYoZEDOATXnzjdGyfZhZJXAh8LO8xQ48aGYrzWzpQB9iZkt7nlPR3Nx8cCXtDYisahAiIpFiBkShO60HurnuUuCpfs1LZ7j7KcBFwF+a2VmFdnT3W919sbsvnjx58sGVNAqIqrjrKiYRkUgxA6IRODJvfiaweYBtr6Zf85K7b47em4B7CZusiiPqpK4JsnSqk1pEBChuQDwPzDezuWaWJAyB+/tvFA0hfjZwX96yKjOr6ZkGzgdeKVpJo07qyrg6qUVEehTtKiZ3z5jZp4HfAAFwm7uvMrNro/XLok3fDzzo7u15u08F7jWznjL+2N0fKFZZCcIaRGWgO6lFRHoULSAA3H05sLzfsmX95m8Hbu+3bD2wqJhl20tPH0SgTmoRkR66kxp6m5hqEjk601lSGYWEiIgCAno7qSeVhRdZNbWkSlkaEZFRQQEBvU1ME8vCK3O3tXSVsjQiIqOCAgJ6A6IuqkFsVUCIiCgggL7RXJNRQOxRQIiIKCAA4tHzIGIZyhMxNTGJiKCACEU1CMummVZbzlZ1UouIKCCA3hvlyKaZWlvO1j2dpS2PiMgooIAAiAWAQTbFtAnl6qQWEUEBETILm5my3UyrLWdbSwr3gQaeFREZHxQQPeJlkOlmam053ZkcuzrSpS6RiEhJKSB6BAnIdjN9QjkAW9QPISLjnAKiR1AG2RRzGqoAeKO5fT87iIiMbQqIHkECsmmOmlxFEDPWbm0tdYlEREpKAdEjXgaZFGXxgLkNVby2TQEhIuObAqJHkIRs2DF97NQa1iogRGScU0D0iDqpAY6ZWsNbOzvo0POpRWQcU0D0iDqpAY6dVo07rGtqK3GhRERKRwHRI56EdHgH9TFTawBYo45qERnHFBA9KuuhYwcAs+urqCmL8+Km3aUtk4hICRU1IMzsQjN7zczWmdmXC6w/x8z2mNmL0evrQ9132FVNgfZmAIKYccrsiazYuLPoHysiMloVLSDMLABuAS4CFgDXmNmCAps+4e4nR69vHOC+w6d6MqRaepuZFs+eyNptbezRkBsiMk4VswaxBFjn7uvdvRu4G7hsBPY9ONVTw/f2JgAWz5kEwMq3VIsQkfGpmAExA9iUN98YLevvNDN7ycx+bWYnHOC+mNlSM1thZiuam5sPvrRVU8L3tvAYJx9ZRzxmPL9x18EfU0TkMFbMgLACy/qPof0CMNvdFwHfB35+APuGC91vdffF7r548uTJB1vWsIkJoG0bABXJgEVH1vHYa4cQOiIih7FiBkQjcGTe/Exgc/4G7t7i7m3R9HIgYWYNQ9l32PXUIKImJoCLTpzGq1ta2LhdA/eJyPhTzIB4HphvZnPNLAlcDdyfv4GZTTMzi6aXROXZMZR9h1313k1MABeeOA2AX7+ytagfLSIyGhUtINw9A3wa+A2wGvg/7r7KzK41s2ujzf4b8IqZvQTcBFztoYL7FqusQDhYX/mEvWoQMydWsmjmBJa/vKWoHy0iMhrFi3nwqNloeb9ly/KmbwZuHuq+RVc1Bdqa9lp02ckz+MYvX+WVt/dw4owJI1ocEZFS0p3U+ar3DYgrT51JeSLGj37/ZokKJSJSGgqIfNVT9mpiAphQkeCyRTO478XN7GzvLlHBRERGngIiX9WUvTqpe3zy3XNJZbL888NrS1AoEZHSUEDkmzgbUnv2aWaaP7WGa5bM4s5n3+KNZg0BLiLjgwIi3xGnhO9vv7DPquvOO4byRMC3l68Z4UKJiJSGAiLf9IVgMXh75T6rGqrL+Itz5vHw6m08/cb2EhRORGRkKSDyJatgygLYvG8NAuATZ85l5sQK/ureV+hKZ0e4cCIiI0sB0d8R7wibmHzfoZ/KEwHfvuIk1m9v57sPvFaCwomIjBwFRH8zToHOnbBrQ8HV754/mY+eNpvbntrA9x95fYQLJyIychQQ/c09O3x/7YEBN/n6pSfw/nfM4O8fWstzG/S8CBEZmxQQ/dXPg6knwas/H3CTIGb8r/efxMyJFfzPe18mlVF/hIiMPQqIQk64DDY9C3veHnCTimTA31x+Iuua2vjcXS+SyeZGsIAiIsWngChkwfvD95d/Muhm5xw7ha9fsoAHVm3lK/e8TC5X8JlGIiKHJQVEIQ1Hw+wz4PkfQm7w5qP/98y5fO698/nJyka+9NM/0tGdGaFCiogUlwJiIO/6/2DPW/Dar/e76effN5/Pvudo7vlDI39605O8tGl38csnIlJkCoiBHPunMOFIePx7kBu8f8HM+ML5x3LnJ99FVzrLlT94mu8/8jpZNTmJyGFMATGQIA7v+RpseRFeumtIu5w+r4EHPncWF500nb9/aC3X/mglnd26wklEDk8KiMGcdBXMfCc89HVoGdpjRydUJvj+Ne/ghksX8PDqbVz0z4/zxOv7DiEuIjLaKSAGE4vBZbdAugN+9knIpoe868fOmMuPPvEuAD78w+f4zF1/oKmlq1glFREZdgqI/Zl8LFzyT/Dmk3DP0v1e1ZTvjKMbeODzZ/H5983nN6u2cvb3HuXDP3yWp9dpNFgRGf2KGhBmdqGZvWZm68zsywXWf8jM/hi9njazRXnrNprZy2b2opmtKGY592vRB+C8b8Cqe+AXn91vp3W+8kTA5993DA9+/iyuPHUG65vb+dAPn+U7v15Dd0Y314nI6BUv1oHNLABuAc4DGoHnzex+d381b7MNwNnuvsvMLgJuBd6Vt/5cdx8df26f8TnobofH/haS1XDhd8BsyLvPaajiby4/iY7uDN/85WqWPfYG9/6hkUUz6/jaJQs4clJlEQsvInLgihYQwBJgnbuvBzCzu4HLgN6AcPen87b/PTCziOU5dOd8BVJt8PtbAIPzvwlB4oAOUZmM8+0rTuI9x03hFy9t5nevNXHpzU/yZ4uP5JRZEzlldh1TasqLU34RkQNQzICYAWzKm29k79pBf58A8u9Kc+BBM3PgX9z91kI7mdlSYCnArFmzDqnA+2UGF3wLPAvP/iAcr+nKfwsH+DtA5y2YynkLprJxezs3/mIV//7UBm59fD3JIMYli6Zz9jGTuejE6STj6iYSkdIwL/BgnGE5sNlVwAXu/slo/sPAEnf/TIFtzwX+N3Cmu++Ilh3h7pvNbArwEPAZd398sM9cvHixr1gxQt0Vr94H9382vLLpou/AOz58QE1O/bWnMqzd1spPVzZy/0ubae3KcFRDFRecOI13z2/gtKPqsUM4vohIIWa20t0XF1xXxIA4DbjB3S+I5r8C4O7f7rfdQuBe4CJ3XzvAsW4A2tz97wb7zBENCAhHe/35tbDhcTjuErj0JqiqP+TDZnPOo6818c+PvM7qLS2ks86JM2pZetY8Lj5xGvFAtQoRGR6lCog4sBZ4L/A28DzwQXdflbfNLOC3wEfy+yPMrAqIuXtrNP0Q8A13H/gpPpQgICC8oun3t8DDN0KyEt79RViyFBLD04/Qlc7y8z+8za1PrGd9czsz6io4b8FUTptXz5/MrWdC5YH1gYiI5CtJQEQffDHwT0AA3Obu3zKzawHcfZmZ/RtwJfBmtEvG3Reb2VGEtQoI+0l+7O7f2t/nlSQgejSthge/BusegtqZ4VVPJ38QyqqH5fC5nPPImiZ+9Ps3eXbDDrrSOcxgwfRaTjuqntPm1bNk7iRqyhUYIjJ0JQuIkVbSgOix/jH43bfCDuxkDSy8Ct7532HqgmH7iFQmy0ub9vDMGzt4Zv12XnhrN92ZHEHMOHHGBE48opZpteVc865ZNFSXDdvnisjYo4AYae6w6TlYeXt4c10mBSdeASdcAfPeEzZFDaOudJYX3tzFM+t38MwbO1i/vZ1dHd0kgxiTqpLMm1zNafPqedfcSRw3vZbqsmJevCYihxMFRCl17IQn/xFe+A/o2gPxCph3Liy6JuzYjhWnw/mN5jZ+/Oxb7O5Is2rzHtZsbe1dN7u+klmTKpk+oZxjp9VyycLpTK3VvRci45ECYjTIpuHNp2DNcljzS2h5G+pmwdyzYPaZMPt0mDi7aB+/oy3FC2/tZvWWFtZsbeHtXZ1s3tNFc2sKgImVCeY2VHH6vAZOnFFLRTLOmUc3EMR0aa3IWKaAGG1yWXjlHlh1bxgaXbvD5ROODINi9hkw58yDugHvQK1rauN3a5pYv72ddU2trHxzFz3POZpaW0ZteYJszplVX8kZ8xqYVV9JXUWCU2dP1OW2ImOAAmI0y+WgeTVsfCoMizefgvbo+RGTj4cZp8DEuTD1hLBpKlFR1OI0t6Zoau1i4/YOlr+8hZw7sZix6u09bNzR0bvdcdNqqCmPYxgLZ06guS3F+QumsXjORCZWJnUHuMhhQgFxOHGH7a/D+t+FTVHbX4fW6GFFQRIajg2viJpyPExZEL4mzDyku7iHamd7N427OljX1MbNv11HRTIgk3XeaG6jtiLBzvbu3m3jMaMyGVBbkeD975jBK2/vIetw7dlHMaEiQcyMo6dUk1AtRKSkFBCHu+6O8LLZN34b3m/RtBpaGvvWJ2uiwDg+rGlMOR4mHweVDUXrBM+XyzkO/H79DtY3t7GnM017d5bO7iwbtrfz2Npm6irDUMgPkfqqJFVlcba3pZhaW877jp9CXWWS2vI4x04LL9V9dcseTj+6gVrd3yFSFAqIsahzNzSvgaZXw8DY9io0rYLOXX3bxBJQOx1qjuj3Ph1qZ0DdkeGyIofIhu3tTKpKgsNzG3eSc6ezO8sja5rI5nJMq63gjeY2nly3nWxu33+P1WVx5jRUUpWMU10WpyIZUJ4IOOGIWgB2daQpT8SYN7maY6bWMGtSpTrXRYZIATFeuENbUxga218Pr5Rq3QItm8NX65bw8an5gmTYOV49FaoawleyKrwct34e1B8NlZMgUQUVdRAv3o13qUz4tL7dHWn+8NYutuzp4ugp1Sx/eQtb93TR3p2lPZWhoztLWyrTewVWf8l4GBbTJ5Tj7pgZ86dUU1eZJJvLUV0WZ8nceqrL4pgRvYyKRBAGmcg4ooCQkHt4xVRLFBp73oKdG2D3W9CxI+wcb2uCdCdkU+AFnnhXWR8GSKISKiZBzVSomgzldVBeG62rCjvTE5XRe3m4vnrqsA09ArB5dydl8fBmwPbuLOua2li7rbX3fXtbipgZ6azzRlMb3dn9P8FvSk0ZrV0Z5jZUccIRtXSkw6aydDbXe9PhhIoEW/Z0UZkMqCmPc8qsiRw1uYqm1hSJWIyyRIwpNWUafVcOCwoIOXCZbti1AXa8Ed7g190WNl+1bgkDpLs9vAmwbWsYLF0thI/w2I94FBYVdeE7DhYLw8NzYaAkq8MgSdZE79F8oioMoGRVuCxZCbkMWBAeL1E5YGd9Opsjm3OCmNHUmmLFxp2ks4674w6Os6czzZotrdRWJHj57T28vauTqrKAymScWMzY2Z6icVcn7pAIwuAZyCmz6pg5sZLtbSmmTShn4/Z2ZtdXMaOugpw7ZnBUQzVrm1pJpXMcNbmK9x0/lSPqwqvUsjlnzdYWKhIBR00OQ9XdaWpNUVUW193wMmwUEFJ8uRx0t4Yd6umeVxQkmRR07gxrJx3bw/6Trt3hu8XC+0LatkEsiPZpC5/cly3chDSgIBmGTiwI52PxvnCJl4dP/wvKwvd4Wbh9kAznY4lofc90PNwnURm+kpUQS9CRhVTWqKsqJ0uMlm5YuamF3V056msqyXqMHZ1ZfvKHLXRnjYbaKra0ppkxqZo3d6Vobs+Qs4AsMVK5GEEQpywR0NqVAWBGXQU727vpymTp+a85b3IVza0pujI5ujM54jHjhCNqOXJSJTMnVjKttoxnN+xke1uKmRMrKYvHSAQxasrjTKxMUleZ6H2fUJGgtiJ8L4vHems57k4m5wRmxNR/M64oIOTwlOmOwqI1DJp0Rzjf3d73igVhwPQETtfucN4MspkwtFKt4bGy3WHoZNPhdCZvPpeJ1qcZUk1oOFkMtzgZYmSIgQW4BcSCOBmP0ZU1LIhDLCAI4nTnYrRnIJWFzoyRJkYsFpBMJunMQNpjpD1Gd85Ie4wcMTIEZD1GlhhZwoCKBXEqysvY05WlM2vkiBHEjOryBJksNNRWkM5BSyqHxQKm1FZQlkwyubaSzozTnoZpdZXkiJHKQirrpLM5wJhSW04iHicWxJlYXUFdeUBXVydtVFJRnmR7W5quTI6JlWVMrC4jGQ+Ang6hWN/0gMtiYORNF3rZ3u/5+0M47R5+94WaU/Mlq8M/HrLd4R8X8fLw5bm+f5vpzrB2290G6a6wNhwvD/9QsVh4MYgF0XT0nsuEf0BlUpBLh3/AJCrCVywe/nv0bHic/PJmu6M/duLhskzqoB8xMFhAqJ4qo1c8CfFJYSf5SMplw/+Yma69a0K5dFhTymXC/7S5TPTqvywbvfa3LNd7DPMsiVyGRN6ynu2q91nWdyzPZehOp0lYjpjnb5fGc1ly2Uzvy7Ph9n3lyEF3hngsSyyWxdwxHOuOAnJXv59Lxz4/qQNSEb0Ahq8napwIkmGgZFLs9QdMLBH+m6ieCv9jzbB/rAJCpL9YEL4S5WHfxihmwEDXlRnhg1iCgzmwe/TKRa8wlLLZDK9va6EyDpMqAzY0t1IWMyriUJ4wyhMx0pkcjTvbSWcyZLMZGne0sb09zYSqSibGU3R2pZhYlaC2PGBHW4pdbSl2tXexs72bzlSGTC5HjBx1FQl2tqdwd7rTWdq6ugGnszsDOMkYVCRidKTSGE4M732PkQvDrnfeiVlfLcHyfsnG40nqqsppakuRzuQoi8eory6jpjxOZ3eWZACx7jYq4k51ZSW7W9uosDRVsTRBPI7HK0kHFbRmAubWAskqdmeSxDKdBLkuqpMxOlPdBOQoC4xMNsO0miSJmJPxGBYvJ15WTlvaqIlnqY1nSHoKz6bJWRwnBqkW3HPkYkmysTIsSNBQAYlcF1hAunwixbhTSAEhIvvquf6Xve+RCYDj5tb1zp80wBN2J83sm14yjMVydzbt7MQMptaWk4zH6OjOkM443dkcb+3soLUrTWUyTlVZwPQJFXR0Z9jW0sXWPSlau9JMm1DOns408ViMtlSaVZtbeGVHB0cdV8XEyiS7O7t5fWcH29u6mTApQVc6S9XEOLs7utm8q4v5U8P6T0d02XVnR5ZM1qlMBqxb3YZ7eKl1MholoC2VoTIZkM2FZUzEYkO6om5/kvEYU2vLaE9lqUgEPHXGIR9yHwoIETlsmBmz6vd+nkplMg7R7SuTa/atT02qSjJz4vA+g2UgezrSxGLs9WTHrnSWsngMd8hGfb6vb2vDccriAV3pMGgmViXZ3ZFmW0sXqUyOIAYxM4KYEY9Z73QsZqTSWf7w1m6aWlOUJ2LMqa8qyvkoIEREhkmhZ8SXJ8JGPjOIRR3kC6JRAA7FhSdOP+Rj7I9GShMRkYIUECIiUlBRA8LMLjSz18xsnZl9ucB6M7ObovV/NLNThrqviIgUV9ECwswC4BbgImABcI2ZLei32UXA/Oi1FPjBAewrIiJFVMwaxBJgnbuvd/du4G7gsn7bXAbc4aHfA3VmNn2I+4qISBEVMyBmAJvy5hujZUPZZij7AmBmS81shZmtaG5uPuRCi4hIqJgBUWjEr/6D3Ay0zVD2DRe63+rui9198eTJkw+wiCIiMpBi3gfRCByZNz8T2DzEbZJD2FdERIqomAHxPDDfzOYCbwNXAx/st839wKfN7G7gXcAed99iZs1D2HcfK1eu3G5mbx5keRuA7Qe57+FK5zw+6JzHh4M959kDrShaQLh7xsw+DfyGcAiX29x9lZldG61fBiwHLgbWEY4V+fHB9h3CZx50G5OZrRhoyNuxSuc8Puicx4dinHNRh9pw9+WEIZC/bFnetAN/OdR9RURk5OhOahERKUgB0efWUhegBHTO44POeXwY9nMeU48cFRGR4aMahIiIFKSAEBGRgsZ9QIyXUWPNbKOZvWxmL5rZimjZJDN7yMxej94nlrqch8rMbjOzJjN7JW/ZgOdpZl+JvvvXzOyC0pT60AxwzjeY2dvR9/2imV2ct+6wPmczO9LMfmdmq81slZl9Llo+1r/ngc67eN+1u4/bF+E9Fm8ARxHevf0SsKDU5SrSuW4EGvot+y7w5Wj6y8Dflrqcw3CeZwGnAK/s7zwJRwp+CSgD5kb/FoJSn8MwnfMNwBcLbHvYnzMwHTglmq4B1kbnNda/54HOu2jf9XivQYz3UWMvA/4jmv4P4PLSFWV4uPvjwM5+iwc6z8uAu9095e4bCG/YXDIS5RxOA5zzQA77c3b3Le7+QjTdCqwmHMxzrH/PA533QA75vMd7QAx51NgxwIEHzWylmS2Nlk119y0Q/uMDppSsdMU10HmO9e//09GDuG7La24ZU+dsZnOAdwDPMo6+537nDUX6rsd7QAx51Ngx4Ax3P4XwIUx/aWZnlbpAo8BY/v5/AMwDTga2AH8fLR8z52xm1cDPgM+7e8tgmxZYdlieMxQ876J91+M9IIYy4uyY4O6bo/cm4F7Cqua26AFNRO9NpSthUQ10nmP2+3f3be6edfcc8K/0NS2MiXM2swThL8k73f2eaPGY/54LnXcxv+vxHhC9I86aWZJw1Nj7S1ymYWdmVWZW0zMNnA+8QniuH402+yhwX2lKWHQDnef9wNVmVhaNHDwfeK4E5Rt2Pb8oI+8n/L5hDJyzmRnwQ2C1u/9D3qox/T0PdN5F/a5L3TNf6hfhaLJrCXv4v1rq8hTpHI8ivJrhJWBVz3kC9cAjwOvR+6RSl3UYzvUuwmp2mvAvqE8Mdp7AV6Pv/jXgolKXfxjP+T+Bl4E/Rr8opo+VcwbOJGwq+SPwYvS6eBx8zwOdd9G+aw21ISIiBY33JiYRERmAAkJERApSQIiISEEKCBERKUgBISIiBSkgRA6AmWXzRs18cThHADazOfkjsoqUWrzUBRA5zHS6+8mlLoTISFANQmQYRM/b+Fszey56HR0tn21mj0QDqT1iZrOi5VPN7F4zeyl6nR4dKjCzf43G+3/QzCpKdlIy7ikgRA5MRb8mpg/krWtx9yXAzcA/RctuBu5w94XAncBN0fKbgMfcfRHhsxxWRcvnA7e4+wnAbuDKop6NyCB0J7XIATCzNnevLrB8I/Aed18fDai21d3rzWw74dAH6Wj5FndvMLNmYKa7p/KOMQd4yN3nR/PXAwl3/5sRODWRfagGITJ8fIDpgbYpJJU3nUX9hFJCCgiR4fOBvPdnoumnCUcJBvgQ8GQ0/QjwFwBmFphZ7UgVUmSo9NeJyIGpMLMX8+YfcPeeS13LzOxZwj+8romWfRa4zcy+BDQDH4+Wfw641cw+QVhT+AvCEVlFRg31QYgMg6gPYrG7by91WUSGi5qYRESkINUgRESkINUgRESkIAWEiIgUpIAQEZGCFBAiIlKQAkJERAr6vwucHLnZerE4AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "modelo_v3.history"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [1.7709777355194092,\n",
       "  0.945222020149231,\n",
       "  0.6986035108566284,\n",
       "  0.5986617207527161,\n",
       "  0.5372873544692993,\n",
       "  0.49170398712158203,\n",
       "  0.459455281496048,\n",
       "  0.43376725912094116,\n",
       "  0.4148152768611908,\n",
       "  0.3959803581237793,\n",
       "  0.37988516688346863,\n",
       "  0.36920687556266785,\n",
       "  0.35220807790756226,\n",
       "  0.34061968326568604,\n",
       "  0.3295201361179352,\n",
       "  0.32219505310058594,\n",
       "  0.314069002866745,\n",
       "  0.3071661591529846,\n",
       "  0.2978360950946808,\n",
       "  0.2913559377193451,\n",
       "  0.28589439392089844,\n",
       "  0.2783834934234619,\n",
       "  0.27605172991752625,\n",
       "  0.26824918389320374,\n",
       "  0.2608680725097656,\n",
       "  0.25945931673049927,\n",
       "  0.25119662284851074,\n",
       "  0.2479260414838791,\n",
       "  0.24628804624080658,\n",
       "  0.24121834337711334,\n",
       "  0.23868915438652039,\n",
       "  0.23265628516674042,\n",
       "  0.23097127676010132,\n",
       "  0.22603513300418854,\n",
       "  0.2213960587978363,\n",
       "  0.2165118157863617,\n",
       "  0.21375297009944916,\n",
       "  0.21098479628562927,\n",
       "  0.2091909945011139,\n",
       "  0.20490260422229767,\n",
       "  0.20258371531963348,\n",
       "  0.19998471438884735,\n",
       "  0.19765271246433258,\n",
       "  0.19714953005313873,\n",
       "  0.19158430397510529,\n",
       "  0.19146132469177246,\n",
       "  0.18857918679714203,\n",
       "  0.18603146076202393,\n",
       "  0.18395830690860748,\n",
       "  0.18215423822402954,\n",
       "  0.18086151778697968,\n",
       "  0.1798204779624939,\n",
       "  0.17584991455078125,\n",
       "  0.17458675801753998,\n",
       "  0.17275020480155945,\n",
       "  0.16894948482513428,\n",
       "  0.16965745389461517,\n",
       "  0.1648682951927185,\n",
       "  0.16497935354709625,\n",
       "  0.16525311768054962,\n",
       "  0.16209915280342102,\n",
       "  0.16048192977905273,\n",
       "  0.1600797027349472,\n",
       "  0.15368765592575073,\n",
       "  0.15693777799606323,\n",
       "  0.15321038663387299,\n",
       "  0.15527528524398804,\n",
       "  0.15081696212291718,\n",
       "  0.14963123202323914,\n",
       "  0.14942285418510437,\n",
       "  0.150114968419075,\n",
       "  0.1482083946466446,\n",
       "  0.14241473376750946,\n",
       "  0.14859481155872345,\n",
       "  0.14219585061073303,\n",
       "  0.1419609934091568,\n",
       "  0.14217717945575714,\n",
       "  0.13820895552635193,\n",
       "  0.14034339785575867,\n",
       "  0.13965409994125366,\n",
       "  0.13579615950584412,\n",
       "  0.13612738251686096,\n",
       "  0.13492926955223083,\n",
       "  0.1318742334842682,\n",
       "  0.13529585301876068,\n",
       "  0.13050615787506104,\n",
       "  0.129667729139328,\n",
       "  0.12844966351985931,\n",
       "  0.1289093941450119,\n",
       "  0.12871479988098145,\n",
       "  0.12607067823410034,\n",
       "  0.1275777965784073,\n",
       "  0.12765832245349884,\n",
       "  0.12568652629852295,\n",
       "  0.12291909009218216,\n",
       "  0.12121035903692245,\n",
       "  0.12062971293926239,\n",
       "  0.12065965682268143,\n",
       "  0.12083110213279724,\n",
       "  0.1185530573129654,\n",
       "  0.11915228515863419,\n",
       "  0.11885777860879898,\n",
       "  0.11579056829214096,\n",
       "  0.11577428132295609,\n",
       "  0.1150665357708931,\n",
       "  0.11665230989456177,\n",
       "  0.11558699607849121,\n",
       "  0.11316186189651489,\n",
       "  0.11463326215744019,\n",
       "  0.11107566207647324,\n",
       "  0.11187370866537094,\n",
       "  0.11208232492208481,\n",
       "  0.11225967109203339,\n",
       "  0.11109773069620132,\n",
       "  0.1089290902018547,\n",
       "  0.11073164641857147,\n",
       "  0.11036660522222519,\n",
       "  0.10950303822755814,\n",
       "  0.10566966980695724,\n",
       "  0.10737346112728119,\n",
       "  0.10758833587169647,\n",
       "  0.10684899240732193,\n",
       "  0.10114699602127075,\n",
       "  0.10428833961486816,\n",
       "  0.10207115858793259,\n",
       "  0.10437746345996857,\n",
       "  0.1020551323890686,\n",
       "  0.10154411941766739,\n",
       "  0.1022987961769104,\n",
       "  0.09977733343839645,\n",
       "  0.10233695805072784,\n",
       "  0.10219590365886688,\n",
       "  0.09855028241872787,\n",
       "  0.09562750160694122,\n",
       "  0.09707789868116379,\n",
       "  0.0972709134221077,\n",
       "  0.0999104380607605,\n",
       "  0.09517738968133926,\n",
       "  0.0968499556183815,\n",
       "  0.09698887169361115,\n",
       "  0.09874079376459122,\n",
       "  0.09574435651302338,\n",
       "  0.09480760991573334,\n",
       "  0.09313159435987473,\n",
       "  0.091763436794281,\n",
       "  0.09585677087306976,\n",
       "  0.09413541853427887,\n",
       "  0.09402846544981003,\n",
       "  0.09365656226873398,\n",
       "  0.0926695317029953,\n",
       "  0.09141068160533905,\n",
       "  0.08977222442626953,\n",
       "  0.09056729078292847,\n",
       "  0.09006614983081818,\n",
       "  0.0892975702881813,\n",
       "  0.08856040239334106,\n",
       "  0.08655805140733719,\n",
       "  0.08854180574417114,\n",
       "  0.08884225785732269,\n",
       "  0.08890726417303085,\n",
       "  0.08702301979064941,\n",
       "  0.08787587285041809,\n",
       "  0.08484132587909698,\n",
       "  0.08697774261236191,\n",
       "  0.08729288727045059,\n",
       "  0.08497758209705353,\n",
       "  0.08459357172250748,\n",
       "  0.0819898322224617,\n",
       "  0.08493765443563461,\n",
       "  0.08234873414039612,\n",
       "  0.08325669169425964,\n",
       "  0.08322208374738693,\n",
       "  0.08333070576190948,\n",
       "  0.0841640904545784,\n",
       "  0.08223975449800491,\n",
       "  0.08167380094528198,\n",
       "  0.08190447837114334,\n",
       "  0.0794818103313446,\n",
       "  0.08061928302049637,\n",
       "  0.08126531541347504,\n",
       "  0.08025030791759491,\n",
       "  0.08252287656068802,\n",
       "  0.08119300752878189,\n",
       "  0.08026360720396042,\n",
       "  0.0780501738190651,\n",
       "  0.07801494002342224,\n",
       "  0.07761747390031815,\n",
       "  0.07746858894824982,\n",
       "  0.07890944927930832,\n",
       "  0.07705578953027725,\n",
       "  0.0776958093047142,\n",
       "  0.07615920901298523,\n",
       "  0.07673176378011703,\n",
       "  0.0741431787610054,\n",
       "  0.07487324625253677,\n",
       "  0.07697877287864685,\n",
       "  0.07530108094215393,\n",
       "  0.07489582896232605,\n",
       "  0.07493657618761063,\n",
       "  0.07309242337942123,\n",
       "  0.07345942407846451,\n",
       "  0.07403361797332764,\n",
       "  0.07542329281568527,\n",
       "  0.07437357306480408,\n",
       "  0.0726180300116539,\n",
       "  0.07208432257175446,\n",
       "  0.07363961637020111,\n",
       "  0.07237068563699722,\n",
       "  0.0732748880982399,\n",
       "  0.07122284173965454,\n",
       "  0.06915737688541412,\n",
       "  0.07138051092624664,\n",
       "  0.07153148949146271,\n",
       "  0.0698787122964859,\n",
       "  0.06874562799930573,\n",
       "  0.06974990665912628,\n",
       "  0.06904631108045578,\n",
       "  0.07020832598209381,\n",
       "  0.06752783060073853,\n",
       "  0.06983338296413422,\n",
       "  0.06942421197891235,\n",
       "  0.0681200698018074,\n",
       "  0.06780867278575897,\n",
       "  0.06794136762619019,\n",
       "  0.06903369724750519,\n",
       "  0.06590571254491806,\n",
       "  0.06724504381418228,\n",
       "  0.06758079677820206,\n",
       "  0.06769540905952454,\n",
       "  0.06654463708400726,\n",
       "  0.06808198243379593,\n",
       "  0.06664761155843735,\n",
       "  0.06777434796094894,\n",
       "  0.06517595797777176,\n",
       "  0.0653843879699707,\n",
       "  0.06584205478429794,\n",
       "  0.0647435337305069,\n",
       "  0.06588229537010193,\n",
       "  0.06465507298707962,\n",
       "  0.06379623711109161,\n",
       "  0.06382714956998825,\n",
       "  0.06301333755254745,\n",
       "  0.06334920972585678,\n",
       "  0.06424971669912338,\n",
       "  0.06413283944129944,\n",
       "  0.0635124146938324,\n",
       "  0.0646904781460762,\n",
       "  0.0620034895837307,\n",
       "  0.06129825860261917,\n",
       "  0.06270335614681244],\n",
       " 'accuracy': [0.43799999356269836,\n",
       "  0.714062511920929,\n",
       "  0.7897499799728394,\n",
       "  0.8205833435058594,\n",
       "  0.8411458134651184,\n",
       "  0.854520857334137,\n",
       "  0.8656041622161865,\n",
       "  0.8732916712760925,\n",
       "  0.877958357334137,\n",
       "  0.8847500085830688,\n",
       "  0.8883749842643738,\n",
       "  0.8934791684150696,\n",
       "  0.8978750109672546,\n",
       "  0.9011458158493042,\n",
       "  0.903249979019165,\n",
       "  0.9056458473205566,\n",
       "  0.9075624942779541,\n",
       "  0.9100624918937683,\n",
       "  0.9136666655540466,\n",
       "  0.9153749942779541,\n",
       "  0.9165833592414856,\n",
       "  0.9192500114440918,\n",
       "  0.9197499752044678,\n",
       "  0.921625018119812,\n",
       "  0.9233541488647461,\n",
       "  0.9234791398048401,\n",
       "  0.9263125061988831,\n",
       "  0.9276041388511658,\n",
       "  0.9278958439826965,\n",
       "  0.9305208325386047,\n",
       "  0.9304791688919067,\n",
       "  0.9332500100135803,\n",
       "  0.9316041469573975,\n",
       "  0.9331250190734863,\n",
       "  0.9347500205039978,\n",
       "  0.9371458292007446,\n",
       "  0.9375208616256714,\n",
       "  0.9378125071525574,\n",
       "  0.9380624890327454,\n",
       "  0.9409166574478149,\n",
       "  0.9411249756813049,\n",
       "  0.9411666393280029,\n",
       "  0.9427499771118164,\n",
       "  0.9424375295639038,\n",
       "  0.9443749785423279,\n",
       "  0.9432916641235352,\n",
       "  0.9442291855812073,\n",
       "  0.9461249709129333,\n",
       "  0.9457083344459534,\n",
       "  0.9460208415985107,\n",
       "  0.9471666812896729,\n",
       "  0.9471041560173035,\n",
       "  0.9475208520889282,\n",
       "  0.9489166736602783,\n",
       "  0.9491875171661377,\n",
       "  0.9511041641235352,\n",
       "  0.950083315372467,\n",
       "  0.9517083168029785,\n",
       "  0.9516458511352539,\n",
       "  0.9512708187103271,\n",
       "  0.9524583220481873,\n",
       "  0.952958345413208,\n",
       "  0.9527083039283752,\n",
       "  0.9544583559036255,\n",
       "  0.9542291760444641,\n",
       "  0.9554791450500488,\n",
       "  0.9545416831970215,\n",
       "  0.9559583067893982,\n",
       "  0.956375002861023,\n",
       "  0.9551666378974915,\n",
       "  0.956041693687439,\n",
       "  0.9564375281333923,\n",
       "  0.958020806312561,\n",
       "  0.9566875100135803,\n",
       "  0.9568750262260437,\n",
       "  0.9572708606719971,\n",
       "  0.9573125243186951,\n",
       "  0.9583333134651184,\n",
       "  0.9581249952316284,\n",
       "  0.9581458568572998,\n",
       "  0.9601666927337646,\n",
       "  0.9597291946411133,\n",
       "  0.9605000019073486,\n",
       "  0.9611666798591614,\n",
       "  0.9599791765213013,\n",
       "  0.9617708325386047,\n",
       "  0.9614375233650208,\n",
       "  0.9618750214576721,\n",
       "  0.9615833163261414,\n",
       "  0.9619374871253967,\n",
       "  0.9620624780654907,\n",
       "  0.9621875286102295,\n",
       "  0.9616458415985107,\n",
       "  0.9627500176429749,\n",
       "  0.963854193687439,\n",
       "  0.9643750190734863,\n",
       "  0.9652916789054871,\n",
       "  0.9637083411216736,\n",
       "  0.9634166955947876,\n",
       "  0.9647291898727417,\n",
       "  0.9648749828338623,\n",
       "  0.9649999737739563,\n",
       "  0.965791642665863,\n",
       "  0.9662916660308838,\n",
       "  0.9661458134651184,\n",
       "  0.9662083387374878,\n",
       "  0.9652083516120911,\n",
       "  0.965708315372467,\n",
       "  0.9658541679382324,\n",
       "  0.9667083621025085,\n",
       "  0.9666666388511658,\n",
       "  0.9672083258628845,\n",
       "  0.9664999842643738,\n",
       "  0.9666249752044678,\n",
       "  0.9682291746139526,\n",
       "  0.9669374823570251,\n",
       "  0.9669583439826965,\n",
       "  0.9676666855812073,\n",
       "  0.9687291383743286,\n",
       "  0.9678750038146973,\n",
       "  0.9681041836738586,\n",
       "  0.9682916402816772,\n",
       "  0.9692916870117188,\n",
       "  0.9691874980926514,\n",
       "  0.968999981880188,\n",
       "  0.9688541889190674,\n",
       "  0.969083309173584,\n",
       "  0.9700624942779541,\n",
       "  0.9692916870117188,\n",
       "  0.9697916507720947,\n",
       "  0.968916654586792,\n",
       "  0.9688541889190674,\n",
       "  0.9698749780654907,\n",
       "  0.9705416560173035,\n",
       "  0.9703541398048401,\n",
       "  0.9704166650772095,\n",
       "  0.9697291851043701,\n",
       "  0.9709374904632568,\n",
       "  0.9699375033378601,\n",
       "  0.9707291722297668,\n",
       "  0.9704166650772095,\n",
       "  0.9712083339691162,\n",
       "  0.9707708358764648,\n",
       "  0.9714375138282776,\n",
       "  0.9719791412353516,\n",
       "  0.9708958268165588,\n",
       "  0.9715833067893982,\n",
       "  0.9717291593551636,\n",
       "  0.971791684627533,\n",
       "  0.9721458554267883,\n",
       "  0.9715833067893982,\n",
       "  0.9729999899864197,\n",
       "  0.9722291827201843,\n",
       "  0.9731666445732117,\n",
       "  0.9729791879653931,\n",
       "  0.9725833535194397,\n",
       "  0.973395824432373,\n",
       "  0.9729375243186951,\n",
       "  0.9727500081062317,\n",
       "  0.9735833406448364,\n",
       "  0.9742708206176758,\n",
       "  0.9740208387374878,\n",
       "  0.9743541479110718,\n",
       "  0.9730833172798157,\n",
       "  0.9740208387374878,\n",
       "  0.9730208516120911,\n",
       "  0.9738333225250244,\n",
       "  0.9751041531562805,\n",
       "  0.9745000004768372,\n",
       "  0.9744791388511658,\n",
       "  0.9742916822433472,\n",
       "  0.9739583134651184,\n",
       "  0.9738958477973938,\n",
       "  0.9743958115577698,\n",
       "  0.9754583239555359,\n",
       "  0.9752708077430725,\n",
       "  0.9753958582878113,\n",
       "  0.9753958582878113,\n",
       "  0.9751874804496765,\n",
       "  0.9743333458900452,\n",
       "  0.9751458168029785,\n",
       "  0.9745208621025085,\n",
       "  0.9750624895095825,\n",
       "  0.9753333330154419,\n",
       "  0.9757500290870667,\n",
       "  0.9753749966621399,\n",
       "  0.9761458039283752,\n",
       "  0.9755625128746033,\n",
       "  0.9750208258628845,\n",
       "  0.9757708311080933,\n",
       "  0.9760833382606506,\n",
       "  0.9764999747276306,\n",
       "  0.976312518119812,\n",
       "  0.9773125052452087,\n",
       "  0.976812481880188,\n",
       "  0.9759583473205566,\n",
       "  0.9769791960716248,\n",
       "  0.976895809173584,\n",
       "  0.9762916564941406,\n",
       "  0.9775833487510681,\n",
       "  0.9775208234786987,\n",
       "  0.9775000214576721,\n",
       "  0.976812481880188,\n",
       "  0.97677081823349,\n",
       "  0.9776666760444641,\n",
       "  0.9776458144187927,\n",
       "  0.9776458144187927,\n",
       "  0.9773333072662354,\n",
       "  0.9771666526794434,\n",
       "  0.9783541560173035,\n",
       "  0.9782083630561829,\n",
       "  0.9778958559036255,\n",
       "  0.9774166941642761,\n",
       "  0.9783750176429749,\n",
       "  0.9779999852180481,\n",
       "  0.9785000085830688,\n",
       "  0.9787291884422302,\n",
       "  0.9777916669845581,\n",
       "  0.9792916774749756,\n",
       "  0.9780625104904175,\n",
       "  0.9787291884422302,\n",
       "  0.9777291417121887,\n",
       "  0.9787291884422302,\n",
       "  0.9786458611488342,\n",
       "  0.9785208106040955,\n",
       "  0.9802083373069763,\n",
       "  0.9791458249092102,\n",
       "  0.9789375066757202,\n",
       "  0.9791250228881836,\n",
       "  0.9792708158493042,\n",
       "  0.9781458377838135,\n",
       "  0.979729175567627,\n",
       "  0.9791666865348816,\n",
       "  0.9792500138282776,\n",
       "  0.9797916412353516,\n",
       "  0.979645848274231,\n",
       "  0.9787291884422302,\n",
       "  0.9793541431427002,\n",
       "  0.9799374938011169,\n",
       "  0.9806874990463257,\n",
       "  0.9795833230018616,\n",
       "  0.9808333516120911,\n",
       "  0.9800208210945129,\n",
       "  0.9800000190734863,\n",
       "  0.979854166507721,\n",
       "  0.9799374938011169,\n",
       "  0.9795833230018616,\n",
       "  0.9801874756813049,\n",
       "  0.9806458353996277,\n",
       "  0.9803333282470703],\n",
       " 'val_loss': [0.960218608379364,\n",
       "  0.539685845375061,\n",
       "  0.4230964481830597,\n",
       "  0.3724624812602997,\n",
       "  0.34077510237693787,\n",
       "  0.3161337375640869,\n",
       "  0.29780229926109314,\n",
       "  0.28368765115737915,\n",
       "  0.2722730338573456,\n",
       "  0.2601819932460785,\n",
       "  0.2503349483013153,\n",
       "  0.24260610342025757,\n",
       "  0.23509186506271362,\n",
       "  0.2276860624551773,\n",
       "  0.2203148752450943,\n",
       "  0.21440094709396362,\n",
       "  0.20874200761318207,\n",
       "  0.203708216547966,\n",
       "  0.19974616169929504,\n",
       "  0.19528137147426605,\n",
       "  0.1895633190870285,\n",
       "  0.1863289177417755,\n",
       "  0.18259423971176147,\n",
       "  0.17971643805503845,\n",
       "  0.17451918125152588,\n",
       "  0.1719791442155838,\n",
       "  0.16970349848270416,\n",
       "  0.16641344130039215,\n",
       "  0.16397324204444885,\n",
       "  0.1619415432214737,\n",
       "  0.158999964594841,\n",
       "  0.15544430911540985,\n",
       "  0.15392827987670898,\n",
       "  0.15261191129684448,\n",
       "  0.14918769896030426,\n",
       "  0.14732353389263153,\n",
       "  0.145255908370018,\n",
       "  0.14326722919940948,\n",
       "  0.1416442096233368,\n",
       "  0.1392943263053894,\n",
       "  0.13859017193317413,\n",
       "  0.13615132868289948,\n",
       "  0.1350373476743698,\n",
       "  0.13274173438549042,\n",
       "  0.13167080283164978,\n",
       "  0.13046717643737793,\n",
       "  0.12880919873714447,\n",
       "  0.12772522866725922,\n",
       "  0.12710054218769073,\n",
       "  0.1255415678024292,\n",
       "  0.12486652284860611,\n",
       "  0.12318196892738342,\n",
       "  0.12199936807155609,\n",
       "  0.12095923721790314,\n",
       "  0.12062922865152359,\n",
       "  0.11928234994411469,\n",
       "  0.11933068931102753,\n",
       "  0.11755914986133575,\n",
       "  0.11609335243701935,\n",
       "  0.11606670171022415,\n",
       "  0.11516350507736206,\n",
       "  0.11386118829250336,\n",
       "  0.11363183706998825,\n",
       "  0.1130528375506401,\n",
       "  0.11187265813350677,\n",
       "  0.11103392392396927,\n",
       "  0.11076539009809494,\n",
       "  0.10969670861959457,\n",
       "  0.10907842218875885,\n",
       "  0.10784190893173218,\n",
       "  0.1074690893292427,\n",
       "  0.10799884051084518,\n",
       "  0.10767629742622375,\n",
       "  0.10630597919225693,\n",
       "  0.10575614124536514,\n",
       "  0.10502199083566666,\n",
       "  0.10443662852048874,\n",
       "  0.1036747619509697,\n",
       "  0.1042785719037056,\n",
       "  0.10290724784135818,\n",
       "  0.10322178155183792,\n",
       "  0.10249005258083344,\n",
       "  0.101903535425663,\n",
       "  0.10165547579526901,\n",
       "  0.10116200894117355,\n",
       "  0.10050761699676514,\n",
       "  0.09983190149068832,\n",
       "  0.09965203702449799,\n",
       "  0.09920075535774231,\n",
       "  0.0986747145652771,\n",
       "  0.0980638638138771,\n",
       "  0.09853000193834305,\n",
       "  0.09763438999652863,\n",
       "  0.09687936305999756,\n",
       "  0.09634285420179367,\n",
       "  0.09674598276615143,\n",
       "  0.0964222326874733,\n",
       "  0.09545972943305969,\n",
       "  0.09531095623970032,\n",
       "  0.09520329535007477,\n",
       "  0.09442570060491562,\n",
       "  0.0944744348526001,\n",
       "  0.09438104182481766,\n",
       "  0.09420868009328842,\n",
       "  0.0937207043170929,\n",
       "  0.09359368681907654,\n",
       "  0.09294793009757996,\n",
       "  0.09281149506568909,\n",
       "  0.09321491420269012,\n",
       "  0.09263329207897186,\n",
       "  0.09196700900793076,\n",
       "  0.09142624586820602,\n",
       "  0.09132061898708344,\n",
       "  0.09115611761808395,\n",
       "  0.0914403572678566,\n",
       "  0.09072073549032211,\n",
       "  0.09076108783483505,\n",
       "  0.09049384295940399,\n",
       "  0.09043095260858536,\n",
       "  0.09045546501874924,\n",
       "  0.09030240029096603,\n",
       "  0.090421162545681,\n",
       "  0.08973130583763123,\n",
       "  0.08962012082338333,\n",
       "  0.08925536274909973,\n",
       "  0.08879157155752182,\n",
       "  0.0885859876871109,\n",
       "  0.08881403505802155,\n",
       "  0.08841384202241898,\n",
       "  0.08833512663841248,\n",
       "  0.08904419839382172,\n",
       "  0.08784974366426468,\n",
       "  0.08814464509487152,\n",
       "  0.08789904415607452,\n",
       "  0.08773913234472275,\n",
       "  0.08719293028116226,\n",
       "  0.08687525242567062,\n",
       "  0.08666955679655075,\n",
       "  0.08739130944013596,\n",
       "  0.08625461161136627,\n",
       "  0.08675635606050491,\n",
       "  0.08625434339046478,\n",
       "  0.08617857098579407,\n",
       "  0.0856412872672081,\n",
       "  0.0863494947552681,\n",
       "  0.08581200987100601,\n",
       "  0.08593867719173431,\n",
       "  0.08551803231239319,\n",
       "  0.08475981652736664,\n",
       "  0.08569271862506866,\n",
       "  0.08503193408250809,\n",
       "  0.0856487900018692,\n",
       "  0.08544589579105377,\n",
       "  0.08510850369930267,\n",
       "  0.0850725844502449,\n",
       "  0.08494044840335846,\n",
       "  0.08468399196863174,\n",
       "  0.08418401330709457,\n",
       "  0.08450610190629959,\n",
       "  0.08468665927648544,\n",
       "  0.08405692130327225,\n",
       "  0.08424752205610275,\n",
       "  0.08428600430488586,\n",
       "  0.08409801870584488,\n",
       "  0.08426843583583832,\n",
       "  0.0840514525771141,\n",
       "  0.0842144638299942,\n",
       "  0.08391378819942474,\n",
       "  0.08396879583597183,\n",
       "  0.08344876766204834,\n",
       "  0.08370029181241989,\n",
       "  0.08326167613267899,\n",
       "  0.08345231413841248,\n",
       "  0.08376149833202362,\n",
       "  0.08320094645023346,\n",
       "  0.08297678828239441,\n",
       "  0.0830083042383194,\n",
       "  0.0828147903084755,\n",
       "  0.08333420008420944,\n",
       "  0.08257420361042023,\n",
       "  0.08283837139606476,\n",
       "  0.08223847299814224,\n",
       "  0.08245045691728592,\n",
       "  0.08244285732507706,\n",
       "  0.08241646736860275,\n",
       "  0.08298409730195999,\n",
       "  0.08289395272731781,\n",
       "  0.08257205784320831,\n",
       "  0.08230415731668472,\n",
       "  0.08289457112550735,\n",
       "  0.08255097270011902,\n",
       "  0.08222141861915588,\n",
       "  0.0817323625087738,\n",
       "  0.08157548308372498,\n",
       "  0.08188512921333313,\n",
       "  0.0817738026380539,\n",
       "  0.08171452581882477,\n",
       "  0.08118726313114166,\n",
       "  0.08154138177633286,\n",
       "  0.08160363882780075,\n",
       "  0.08119786530733109,\n",
       "  0.08143582940101624,\n",
       "  0.08109623938798904,\n",
       "  0.08127332478761673,\n",
       "  0.08109238743782043,\n",
       "  0.08090316504240036,\n",
       "  0.08095566183328629,\n",
       "  0.08136294037103653,\n",
       "  0.08097181469202042,\n",
       "  0.08154863119125366,\n",
       "  0.0812918022274971,\n",
       "  0.08130954951047897,\n",
       "  0.0807633027434349,\n",
       "  0.08065546303987503,\n",
       "  0.08130071312189102,\n",
       "  0.0807209461927414,\n",
       "  0.08126086741685867,\n",
       "  0.08042772114276886,\n",
       "  0.08094797283411026,\n",
       "  0.08030538260936737,\n",
       "  0.08000945299863815,\n",
       "  0.07990790158510208,\n",
       "  0.08032359182834625,\n",
       "  0.08002165704965591,\n",
       "  0.08125178515911102,\n",
       "  0.0805407464504242,\n",
       "  0.08164121210575104,\n",
       "  0.08095381408929825,\n",
       "  0.08085614442825317,\n",
       "  0.08066502213478088,\n",
       "  0.0805218294262886,\n",
       "  0.08039313554763794,\n",
       "  0.07978792488574982,\n",
       "  0.08016373962163925,\n",
       "  0.08020956069231033,\n",
       "  0.08067380636930466,\n",
       "  0.0808982327580452,\n",
       "  0.08110373467206955,\n",
       "  0.08048149943351746,\n",
       "  0.07990257441997528,\n",
       "  0.07997018098831177,\n",
       "  0.08037974685430527,\n",
       "  0.08035828918218613,\n",
       "  0.0795082077383995,\n",
       "  0.08001141995191574,\n",
       "  0.08047007024288177,\n",
       "  0.08043278753757477,\n",
       "  0.0798235610127449,\n",
       "  0.07965362817049026,\n",
       "  0.08019791543483734],\n",
       " 'val_accuracy': [0.8084166646003723,\n",
       "  0.8705000281333923,\n",
       "  0.8893333077430725,\n",
       "  0.8989166617393494,\n",
       "  0.9054999947547913,\n",
       "  0.9110833406448364,\n",
       "  0.9148333072662354,\n",
       "  0.9193333387374878,\n",
       "  0.9214166402816772,\n",
       "  0.925083339214325,\n",
       "  0.9277499914169312,\n",
       "  0.9298333525657654,\n",
       "  0.9320833086967468,\n",
       "  0.934333324432373,\n",
       "  0.9358333349227905,\n",
       "  0.937250018119812,\n",
       "  0.9390833377838135,\n",
       "  0.940666675567627,\n",
       "  0.9411666393280029,\n",
       "  0.9432500004768372,\n",
       "  0.9452499747276306,\n",
       "  0.9462500214576721,\n",
       "  0.9474999904632568,\n",
       "  0.9469166398048401,\n",
       "  0.9490000009536743,\n",
       "  0.9493333101272583,\n",
       "  0.949916660785675,\n",
       "  0.9511666893959045,\n",
       "  0.9520000219345093,\n",
       "  0.952833354473114,\n",
       "  0.953416645526886,\n",
       "  0.9551666378974915,\n",
       "  0.9555000066757202,\n",
       "  0.9551666378974915,\n",
       "  0.9565833210945129,\n",
       "  0.9577500224113464,\n",
       "  0.9578333497047424,\n",
       "  0.9585000276565552,\n",
       "  0.9586666822433472,\n",
       "  0.9591666460037231,\n",
       "  0.9593333601951599,\n",
       "  0.9599999785423279,\n",
       "  0.9599166512489319,\n",
       "  0.9610000252723694,\n",
       "  0.9613333344459534,\n",
       "  0.9618333578109741,\n",
       "  0.9616666436195374,\n",
       "  0.9617499709129333,\n",
       "  0.9622499942779541,\n",
       "  0.9624166488647461,\n",
       "  0.9624999761581421,\n",
       "  0.9635833501815796,\n",
       "  0.9642500281333923,\n",
       "  0.9633333086967468,\n",
       "  0.9641666412353516,\n",
       "  0.9648333191871643,\n",
       "  0.9642500281333923,\n",
       "  0.9645000100135803,\n",
       "  0.965416669845581,\n",
       "  0.965499997138977,\n",
       "  0.965833306312561,\n",
       "  0.9664166569709778,\n",
       "  0.9660833477973938,\n",
       "  0.9665833115577698,\n",
       "  0.9668333530426025,\n",
       "  0.9675833582878113,\n",
       "  0.9675833582878113,\n",
       "  0.9673333168029785,\n",
       "  0.9681666493415833,\n",
       "  0.9680833220481873,\n",
       "  0.968500018119812,\n",
       "  0.9679999947547913,\n",
       "  0.9679999947547913,\n",
       "  0.9681666493415833,\n",
       "  0.968416690826416,\n",
       "  0.968500018119812,\n",
       "  0.9694166779518127,\n",
       "  0.9694166779518127,\n",
       "  0.9694166779518127,\n",
       "  0.9694166779518127,\n",
       "  0.9696666598320007,\n",
       "  0.9692500233650208,\n",
       "  0.9698333144187927,\n",
       "  0.9704166650772095,\n",
       "  0.9704166650772095,\n",
       "  0.9704166650772095,\n",
       "  0.9706666469573975,\n",
       "  0.9706666469573975,\n",
       "  0.9702500104904175,\n",
       "  0.9707499742507935,\n",
       "  0.9704999923706055,\n",
       "  0.9710833430290222,\n",
       "  0.9708333611488342,\n",
       "  0.9710833430290222,\n",
       "  0.971750020980835,\n",
       "  0.9714166522026062,\n",
       "  0.971750020980835,\n",
       "  0.9715833067893982,\n",
       "  0.9715833067893982,\n",
       "  0.9715833067893982,\n",
       "  0.972000002861023,\n",
       "  0.971666693687439,\n",
       "  0.9724166393280029,\n",
       "  0.9722499847412109,\n",
       "  0.9722499847412109,\n",
       "  0.971916675567627,\n",
       "  0.9725833535194397,\n",
       "  0.9724166393280029,\n",
       "  0.9724166393280029,\n",
       "  0.9727500081062317,\n",
       "  0.9730833172798157,\n",
       "  0.9726666808128357,\n",
       "  0.9729999899864197,\n",
       "  0.9728333353996277,\n",
       "  0.9730833172798157,\n",
       "  0.9729999899864197,\n",
       "  0.9728333353996277,\n",
       "  0.9728333353996277,\n",
       "  0.9731666445732117,\n",
       "  0.9734166860580444,\n",
       "  0.9732499718666077,\n",
       "  0.9729999899864197,\n",
       "  0.9731666445732117,\n",
       "  0.9731666445732117,\n",
       "  0.9736666679382324,\n",
       "  0.9742500185966492,\n",
       "  0.9744166731834412,\n",
       "  0.9732499718666077,\n",
       "  0.9735000133514404,\n",
       "  0.9738333225250244,\n",
       "  0.9731666445732117,\n",
       "  0.9741666913032532,\n",
       "  0.9737499952316284,\n",
       "  0.9742500185966492,\n",
       "  0.9743333458900452,\n",
       "  0.9743333458900452,\n",
       "  0.9742500185966492,\n",
       "  0.9745833277702332,\n",
       "  0.9741666913032532,\n",
       "  0.9743333458900452,\n",
       "  0.9747499823570251,\n",
       "  0.9748333096504211,\n",
       "  0.9745833277702332,\n",
       "  0.9748333096504211,\n",
       "  0.9753333330154419,\n",
       "  0.9750833511352539,\n",
       "  0.9750000238418579,\n",
       "  0.9753333330154419,\n",
       "  0.9754166603088379,\n",
       "  0.9746666550636292,\n",
       "  0.9752500057220459,\n",
       "  0.9754999876022339,\n",
       "  0.9752500057220459,\n",
       "  0.9753333330154419,\n",
       "  0.9754999876022339,\n",
       "  0.9750000238418579,\n",
       "  0.9757500290870667,\n",
       "  0.9754999876022339,\n",
       "  0.9759166836738586,\n",
       "  0.9748333096504211,\n",
       "  0.9762499928474426,\n",
       "  0.9755833148956299,\n",
       "  0.9754166603088379,\n",
       "  0.9757500290870667,\n",
       "  0.9753333330154419,\n",
       "  0.9759166836738586,\n",
       "  0.9753333330154419,\n",
       "  0.9764166474342346,\n",
       "  0.9760000109672546,\n",
       "  0.9759166836738586,\n",
       "  0.9760833382606506,\n",
       "  0.9764999747276306,\n",
       "  0.9761666655540466,\n",
       "  0.9754999876022339,\n",
       "  0.9764999747276306,\n",
       "  0.9759166836738586,\n",
       "  0.9764999747276306,\n",
       "  0.9762499928474426,\n",
       "  0.9760000109672546,\n",
       "  0.9763333201408386,\n",
       "  0.9761666655540466,\n",
       "  0.9761666655540466,\n",
       "  0.9760833382606506,\n",
       "  0.9765833616256714,\n",
       "  0.9765833616256714,\n",
       "  0.9764999747276306,\n",
       "  0.9765833616256714,\n",
       "  0.9764999747276306,\n",
       "  0.9760833382606506,\n",
       "  0.9759166836738586,\n",
       "  0.9766666889190674,\n",
       "  0.9764166474342346,\n",
       "  0.9763333201408386,\n",
       "  0.9760833382606506,\n",
       "  0.9763333201408386,\n",
       "  0.9764166474342346,\n",
       "  0.9773333072662354,\n",
       "  0.9768333435058594,\n",
       "  0.9757500290870667,\n",
       "  0.9766666889190674,\n",
       "  0.9766666889190674,\n",
       "  0.9759166836738586,\n",
       "  0.9764999747276306,\n",
       "  0.9769166707992554,\n",
       "  0.9768333435058594,\n",
       "  0.9764166474342346,\n",
       "  0.9763333201408386,\n",
       "  0.9763333201408386,\n",
       "  0.9766666889190674,\n",
       "  0.9770833253860474,\n",
       "  0.9764999747276306,\n",
       "  0.9775000214576721,\n",
       "  0.9769166707992554,\n",
       "  0.9769166707992554,\n",
       "  0.9770833253860474,\n",
       "  0.9767500162124634,\n",
       "  0.9769166707992554,\n",
       "  0.9774166941642761,\n",
       "  0.9774166941642761,\n",
       "  0.9771666526794434,\n",
       "  0.9772499799728394,\n",
       "  0.9772499799728394,\n",
       "  0.9767500162124634,\n",
       "  0.9775833487510681,\n",
       "  0.9771666526794434,\n",
       "  0.9768333435058594,\n",
       "  0.9766666889190674,\n",
       "  0.9765833616256714,\n",
       "  0.9770833253860474,\n",
       "  0.9772499799728394,\n",
       "  0.9769999980926514,\n",
       "  0.9772499799728394,\n",
       "  0.9769999980926514,\n",
       "  0.9773333072662354,\n",
       "  0.9767500162124634,\n",
       "  0.9777500033378601,\n",
       "  0.9771666526794434,\n",
       "  0.9769166707992554,\n",
       "  0.9768333435058594,\n",
       "  0.9775000214576721,\n",
       "  0.9778333306312561,\n",
       "  0.9776666760444641,\n",
       "  0.9774166941642761,\n",
       "  0.9773333072662354,\n",
       "  0.9771666526794434,\n",
       "  0.9774166941642761,\n",
       "  0.9772499799728394,\n",
       "  0.9778333306312561,\n",
       "  0.9775000214576721,\n",
       "  0.9773333072662354]}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer Perceptron - Versão 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testando outros otimizadores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://keras.io/optimizers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uma rede neural é essencialmente uma composição de múltiplas funções com milhares, e às vezes milhões, de parâmetros. Cada camada de rede calcula uma função cujo erro deve ser minimizado para melhorar a precisão observada durante a fase de aprendizagem. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keras implementa uma variante rápida de descida de gradiente conhecida como descida de gradiente estocástica (SGD) e duas técnicas de otimização mais avançadas conhecidas como RMSprop e Adam. RMSprop e Adam incluem o conceito de momentum (uma componente de velocidade) além da componente de aceleração que tem SGD. Isso permite uma convergência mais rápida ao custo de mais computação. SGD foi nossa escolha padrão até agora. Então vamos tentar os outros dois. É muito simples, só precisamos mudar algumas linhas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Import dos pacotes e funções\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.core import Dense, Dropout, Activation\r\n",
    "from keras.optimizers import RMSprop, Adam\r\n",
    "from keras.utils import np_utils\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Garantindo que o resultado pode ser reproduzido\r\n",
    "np.random.seed(1671)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Parâmetros da rede e do treinamento\r\n",
    "NB_EPOCH = 20\r\n",
    "BATCH_SIZE = 128\r\n",
    "VERBOSE = 1\r\n",
    "NB_CLASSES = 10   # número de outputs = número de dígitos\r\n",
    "#OPTIMIZER = RMSprop() # otimizador\r\n",
    "OPTIMIZER = Adam() # otimizador\r\n",
    "N_HIDDEN = 128\r\n",
    "VALIDATION_SPLIT=0.2 # quanto é reservado para validação\r\n",
    "DROPOUT = 0.3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Gerando datasets de treino e teste\r\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# X_train possui 60000 linhas de valores 28x28 --> reshape para 60000 x 784\r\n",
    "RESHAPED = 784\r\n",
    "X_train = X_train.reshape(60000, RESHAPED)\r\n",
    "X_test = X_test.reshape(10000, RESHAPED)\r\n",
    "X_train = X_train.astype('float32')\r\n",
    "X_test = X_test.astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Normalizando os dados\r\n",
    "# Tipicamente, os valores associados a cada pixel são normalizados na faixa [0, 1] \r\n",
    "# (o que significa que a intensidade de cada pixel é dividida por 255, o valor de intensidade máxima). \r\n",
    "# A saída é 10 classes, uma para cada dígito.\r\n",
    "X_train /= 255\r\n",
    "X_test /= 255\r\n",
    "print(X_train.shape[0], 'exemplos de treinamento')\r\n",
    "print(X_test.shape[0], 'exemplos de teste')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000 exemplos de treinamento\n",
      "10000 exemplos de teste\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Converte os vetores da class para matrizes binárias das classes\r\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\r\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Cria as camadas \r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(Dropout(DROPOUT))\r\n",
    "model.add(Dense(N_HIDDEN))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(Dropout(DROPOUT))\r\n",
    "model.add(Dense(NB_CLASSES))\r\n",
    "model.add(Activation('softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Sumário da rede\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Compila o modelo\r\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = OPTIMIZER, metrics = ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Treinamento do modelo\r\n",
    "modelo_v4 = model.fit(X_train, Y_train,\r\n",
    "                      batch_size = BATCH_SIZE, \r\n",
    "                      epochs = NB_EPOCH,\r\n",
    "                      verbose = VERBOSE, \r\n",
    "                      validation_split = VALIDATION_SPLIT)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8634 - accuracy: 0.7276 - val_loss: 0.1849 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2505 - accuracy: 0.9256 - val_loss: 0.1351 - val_accuracy: 0.9609\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9469 - val_loss: 0.1110 - val_accuracy: 0.9662\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1518 - accuracy: 0.9542 - val_loss: 0.1006 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9615 - val_loss: 0.0940 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1169 - accuracy: 0.9647 - val_loss: 0.0908 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9673 - val_loss: 0.0896 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9699 - val_loss: 0.0887 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9730 - val_loss: 0.0854 - val_accuracy: 0.9757\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9759 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9759 - val_loss: 0.0825 - val_accuracy: 0.9759\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9776 - val_loss: 0.0829 - val_accuracy: 0.9753\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0856 - val_accuracy: 0.9748\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9807 - val_loss: 0.0821 - val_accuracy: 0.9775\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 0.0816 - val_accuracy: 0.9791\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9802 - val_loss: 0.0801 - val_accuracy: 0.9791\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0800 - val_accuracy: 0.9784\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9828 - val_loss: 0.0826 - val_accuracy: 0.9788\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0825 - val_accuracy: 0.9781\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Testa o modelo e imprime o score\r\n",
    "score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\r\n",
    "print(\"\\nTest score:\", score[0])\r\n",
    "print('Test accuracy:', score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9784\n",
      "\n",
      "Test score: 0.07748832553625107\n",
      "Test accuracy: 0.9783999919891357\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Imprime os dados no modelo\r\n",
    "print(modelo_v4.history.keys())\r\n",
    "\r\n",
    "# Sumariza o modelo para acurácia\r\n",
    "plt.plot(modelo_v4.history['accuracy'])\r\n",
    "plt.plot(modelo_v4.history['val_accuracy'])\r\n",
    "plt.title('Acurácia do Modelo')\r\n",
    "plt.ylabel('Acurácia')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend(['Treino', 'Teste'], loc = 'lower right')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T10:32:24.863354</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 277.314375 \r\nL 392.14375 277.314375 \r\nL 392.14375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 384.94375 239.758125 \r\nL 384.94375 22.318125 \r\nL 50.14375 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m4bc2a083ae\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(57.410369 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"105.409779\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(97.458216 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.457626\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(137.506063 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"185.505472\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <g transform=\"translate(177.55391 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.553319\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <g transform=\"translate(214.420507 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.601166\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g transform=\"translate(254.468354 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.649013\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g transform=\"translate(294.516201 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"345.69686\" xlink:href=\"#m4bc2a083ae\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g transform=\"translate(334.564048 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_9\">\r\n     <!-- Epoch -->\r\n     <g transform=\"translate(202.232813 268.034687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mad6f23328f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"235.116383\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.84 -->\r\n      <g transform=\"translate(20.878125 238.915602)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"206.52428\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.86 -->\r\n      <g transform=\"translate(20.878125 210.323498)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"177.932177\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.88 -->\r\n      <g transform=\"translate(20.878125 181.731395)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"149.340073\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.90 -->\r\n      <g transform=\"translate(20.878125 153.139292)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"120.74797\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.92 -->\r\n      <g transform=\"translate(20.878125 124.547189)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"92.155867\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.94 -->\r\n      <g transform=\"translate(20.878125 95.955086)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"63.563764\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 0.96 -->\r\n      <g transform=\"translate(20.878125 67.362983)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mad6f23328f\" y=\"34.971661\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0.98 -->\r\n      <g transform=\"translate(20.878125 38.77088)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_18\">\r\n     <!-- Acurácia -->\r\n     <g transform=\"translate(14.798438 152.610781)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\nM 35.796875 79.984375 \r\nL 45.515625 79.984375 \r\nL 29.59375 61.625 \r\nL 22.125 61.625 \r\nz\r\n\" id=\"DejaVuSans-225\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"185.017578\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"226.130859\" xlink:href=\"#DejaVuSans-225\"/>\r\n      <use x=\"287.410156\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"370.173828\" xlink:href=\"#DejaVuSans-97\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p93716e11d5)\" d=\"M 65.361932 229.874489 \r\nL 81.381071 104.426611 \r\nL 97.400209 80.033994 \r\nL 113.419348 71.367002 \r\nL 129.438487 60.883224 \r\nL 145.457626 56.832714 \r\nL 161.476764 52.633255 \r\nL 177.495903 49.446444 \r\nL 193.515042 46.646748 \r\nL 209.534181 43.102563 \r\nL 225.553319 41.255953 \r\nL 241.572458 40.95814 \r\nL 257.591597 39.171093 \r\nL 273.610736 37.413869 \r\nL 289.629874 36.460868 \r\nL 305.649013 35.120583 \r\nL 321.668152 34.673821 \r\nL 337.687291 33.899422 \r\nL 353.706429 32.201761 \r\nL 369.725568 32.678347 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p93716e11d5)\" d=\"M 65.361932 82.625179 \r\nL 81.381071 62.253333 \r\nL 97.400209 54.747854 \r\nL 113.419348 50.101633 \r\nL 129.438487 45.217162 \r\nL 145.457626 46.527623 \r\nL 161.476764 43.66845 \r\nL 177.495903 44.025825 \r\nL 193.515042 41.166652 \r\nL 209.534181 39.856105 \r\nL 225.553319 40.809191 \r\nL 241.572458 41.762277 \r\nL 257.591597 42.357988 \r\nL 273.610736 38.069143 \r\nL 289.629874 38.545643 \r\nL 305.649013 36.282095 \r\nL 321.668152 36.282095 \r\nL 337.687291 37.235181 \r\nL 353.706429 36.639556 \r\nL 369.725568 37.711767 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 50.14375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 384.94375 239.758125 \r\nL 384.94375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 50.14375 239.758125 \r\nL 384.94375 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 50.14375 22.318125 \r\nL 384.94375 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_19\">\r\n    <!-- Acurácia do Modelo -->\r\n    <g transform=\"translate(158.675313 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"185.017578\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"226.130859\" xlink:href=\"#DejaVuSans-225\"/>\r\n     <use x=\"287.410156\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"370.173828\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"431.453125\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"463.240234\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"526.716797\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"587.898438\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"619.685547\" xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"705.964844\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"767.146484\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"830.623047\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"892.146484\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"919.929688\" xlink:href=\"#DejaVuSans-111\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 316.0375 234.758125 \r\nL 377.94375 234.758125 \r\nQ 379.94375 234.758125 379.94375 232.758125 \r\nL 379.94375 204.401875 \r\nQ 379.94375 202.401875 377.94375 202.401875 \r\nL 316.0375 202.401875 \r\nQ 314.0375 202.401875 314.0375 204.401875 \r\nL 314.0375 232.758125 \r\nQ 314.0375 234.758125 316.0375 234.758125 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 318.0375 210.500312 \r\nL 338.0375 210.500312 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_20\">\r\n     <!-- Treino -->\r\n     <g transform=\"translate(346.0375 214.000312)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"85.197266\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"146.720703\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"174.503906\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"237.882812\" xlink:href=\"#DejaVuSans-111\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_21\">\r\n     <path d=\"M 318.0375 225.178437 \r\nL 338.0375 225.178437 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_22\"/>\r\n    <g id=\"text_21\">\r\n     <!-- Teste -->\r\n     <g transform=\"translate(346.0375 228.678437)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p93716e11d5\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Imprime a evolução de erro do modelo\r\n",
    "plt.plot(modelo_v4.history['loss'])\r\n",
    "plt.plot(modelo_v4.history['val_loss'])\r\n",
    "plt.title('Model Loss')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend(['Treino', 'Teste'], loc='upper right')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 385.78125 277.314375\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T10:32:26.389378</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 277.314375 \r\nL 385.78125 277.314375 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\nL 43.78125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m23190bcb08\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(51.047869 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.047279\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(91.095716 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"139.095126\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(131.143563 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"179.142972\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <g transform=\"translate(171.19141 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.190819\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <g transform=\"translate(208.058007 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.238666\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g transform=\"translate(248.105854 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.286513\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g transform=\"translate(288.153701 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"339.33436\" xlink:href=\"#m23190bcb08\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g transform=\"translate(328.201548 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_9\">\r\n     <!-- Epoch -->\r\n     <g transform=\"translate(195.870313 268.034687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mb48dfdea32\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mb48dfdea32\" y=\"210.506151\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.1 -->\r\n      <g transform=\"translate(20.878125 214.30537)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mb48dfdea32\" y=\"167.466538\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(20.878125 171.265757)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mb48dfdea32\" y=\"124.426925\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.3 -->\r\n      <g transform=\"translate(20.878125 128.226144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mb48dfdea32\" y=\"81.387312\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(20.878125 85.186531)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mb48dfdea32\" y=\"38.347699\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(20.878125 42.146918)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- Loss -->\r\n     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p9012e586dc)\" d=\"M 58.999432 32.201761 \r\nL 75.018571 155.014141 \r\nL 91.037709 178.241841 \r\nL 107.056848 189.330415 \r\nL 123.075987 198.720046 \r\nL 139.095126 204.042214 \r\nL 155.114264 207.544105 \r\nL 171.133403 211.820215 \r\nL 187.152542 215.450213 \r\nL 203.171681 217.698999 \r\nL 219.190819 220.586476 \r\nL 235.209958 221.081344 \r\nL 251.229097 222.466398 \r\nL 267.248236 224.424186 \r\nL 283.267374 226.058288 \r\nL 299.286513 226.552556 \r\nL 315.305652 227.781882 \r\nL 331.324791 228.256331 \r\nL 347.343929 229.874489 \r\nL 363.363068 228.968368 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p9012e586dc)\" d=\"M 58.999432 173.947754 \r\nL 75.018571 195.415303 \r\nL 91.037709 205.759781 \r\nL 107.056848 210.2276 \r\nL 123.075987 213.087057 \r\nL 139.095126 214.475521 \r\nL 155.114264 214.991966 \r\nL 171.133403 215.389802 \r\nL 187.152542 216.787443 \r\nL 203.171681 218.734725 \r\nL 219.190819 218.016616 \r\nL 235.209958 217.886367 \r\nL 251.229097 216.693894 \r\nL 267.248236 218.249432 \r\nL 283.267374 218.205885 \r\nL 299.286513 218.409633 \r\nL 315.305652 219.063691 \r\nL 331.324791 219.126045 \r\nL 347.343929 218.010389 \r\nL 363.363068 218.026038 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 43.78125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 22.318125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_16\">\r\n    <!-- Model Loss -->\r\n    <g transform=\"translate(178.097813 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"147.460938\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"210.9375\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"272.460938\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"300.244141\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"332.03125\" xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"385.994141\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"447.175781\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"499.275391\" xlink:href=\"#DejaVuSans-115\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 309.675 59.674375 \r\nL 371.58125 59.674375 \r\nQ 373.58125 59.674375 373.58125 57.674375 \r\nL 373.58125 29.318125 \r\nQ 373.58125 27.318125 371.58125 27.318125 \r\nL 309.675 27.318125 \r\nQ 307.675 27.318125 307.675 29.318125 \r\nL 307.675 57.674375 \r\nQ 307.675 59.674375 309.675 59.674375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 311.675 35.416562 \r\nL 331.675 35.416562 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_17\">\r\n     <!-- Treino -->\r\n     <g transform=\"translate(339.675 38.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"85.197266\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"146.720703\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"174.503906\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"237.882812\" xlink:href=\"#DejaVuSans-111\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 311.675 50.094687 \r\nL 331.675 50.094687 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_18\">\r\n     <!-- Teste -->\r\n     <g transform=\"translate(339.675 53.594687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p9012e586dc\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fim"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "2757f2c2fa6babad547f4a3642c7cf29f9f98149abb7990afbb40d637e41adc8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}